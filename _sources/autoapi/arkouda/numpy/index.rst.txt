arkouda.numpy
=============

.. py:module:: arkouda.numpy


Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/arkouda/numpy/char/index
   /autoapi/arkouda/numpy/ctypeslib/index
   /autoapi/arkouda/numpy/dtypes/index
   /autoapi/arkouda/numpy/exceptions/index
   /autoapi/arkouda/numpy/fft/index
   /autoapi/arkouda/numpy/lib/index
   /autoapi/arkouda/numpy/linalg/index
   /autoapi/arkouda/numpy/ma/index
   /autoapi/arkouda/numpy/pdarrayclass/index
   /autoapi/arkouda/numpy/pdarraycreation/index
   /autoapi/arkouda/numpy/pdarraymanipulation/index
   /autoapi/arkouda/numpy/pdarraysetops/index
   /autoapi/arkouda/numpy/polynomial/index
   /autoapi/arkouda/numpy/random/index
   /autoapi/arkouda/numpy/rec/index
   /autoapi/arkouda/numpy/segarray/index
   /autoapi/arkouda/numpy/sorting/index
   /autoapi/arkouda/numpy/strings/index
   /autoapi/arkouda/numpy/timeclass/index
   /autoapi/arkouda/numpy/util/index


Attributes
----------

.. autoapisummary::

   arkouda.numpy.ARKOUDA_SUPPORTED_DTYPES
   arkouda.numpy.ARKOUDA_SUPPORTED_INTS
   arkouda.numpy.DTypeObjects
   arkouda.numpy.DTypes
   arkouda.numpy.LEN_SUFFIX
   arkouda.numpy.NUMBER_FORMAT_STRINGS
   arkouda.numpy.NumericDTypes
   arkouda.numpy.SEG_SUFFIX
   arkouda.numpy.ScalarDTypes
   arkouda.numpy.SeriesDTypes
   arkouda.numpy.SortingAlgorithm
   arkouda.numpy.VAL_SUFFIX
   arkouda.numpy.all_scalars
   arkouda.numpy.bitType
   arkouda.numpy.bool_scalars
   arkouda.numpy.float_scalars
   arkouda.numpy.intTypes
   arkouda.numpy.intTypes
   arkouda.numpy.int_scalars
   arkouda.numpy.int_scalars
   arkouda.numpy.int_scalars
   arkouda.numpy.numeric_and_bool_scalars
   arkouda.numpy.numeric_scalars
   arkouda.numpy.numpy_scalars
   arkouda.numpy.str_scalars


Exceptions
----------

.. autoapisummary::

   arkouda.numpy.RegistrationError
   arkouda.numpy.RegistrationError
   arkouda.numpy.RegistrationError


Classes
-------

.. autoapisummary::

   arkouda.numpy.Categorical
   arkouda.numpy.DType
   arkouda.numpy.Datetime
   arkouda.numpy.GroupBy
   arkouda.numpy.Iterable
   arkouda.numpy.Optional
   arkouda.numpy.SegArray
   arkouda.numpy.Strings
   arkouda.numpy.Strings
   arkouda.numpy.Strings
   arkouda.numpy.Strings
   arkouda.numpy.Timedelta
   arkouda.numpy.Tuple
   arkouda.numpy.Tuple
   arkouda.numpy.Union
   arkouda.numpy.Union
   arkouda.numpy.all_scalars
   arkouda.numpy.bigint
   arkouda.numpy.bool_scalars
   arkouda.numpy.ndarray
   arkouda.numpy.numeric_scalars
   arkouda.numpy.pdarray
   arkouda.numpy.pdarray
   arkouda.numpy.pdarray
   arkouda.numpy.pdarray
   arkouda.numpy.pdarray


Functions
---------

.. autoapisummary::

   arkouda.numpy.ak_array
   arkouda.numpy.arange
   arkouda.numpy.arange
   arkouda.numpy.argmaxk
   arkouda.numpy.argmink
   arkouda.numpy.argsort
   arkouda.numpy.array
   arkouda.numpy.array
   arkouda.numpy.attach
   arkouda.numpy.attach_all
   arkouda.numpy.attach_pdarray
   arkouda.numpy.bigint_from_uint_arrays
   arkouda.numpy.broadcast
   arkouda.numpy.broadcast_dims
   arkouda.numpy.broadcast_to_shape
   arkouda.numpy.can_cast
   arkouda.numpy.cast
   arkouda.numpy.clear
   arkouda.numpy.clz
   arkouda.numpy.coargsort
   arkouda.numpy.concatenate
   arkouda.numpy.concatenate
   arkouda.numpy.corr
   arkouda.numpy.cov
   arkouda.numpy.create_pdarray
   arkouda.numpy.create_pdarray
   arkouda.numpy.create_pdarray
   arkouda.numpy.ctz
   arkouda.numpy.date_range
   arkouda.numpy.delete
   arkouda.numpy.divmod
   arkouda.numpy.dot
   arkouda.numpy.dtype
   arkouda.numpy.flip
   arkouda.numpy.fmod
   arkouda.numpy.from_series
   arkouda.numpy.from_series
   arkouda.numpy.full
   arkouda.numpy.full_like
   arkouda.numpy.generic_msg
   arkouda.numpy.getArkoudaLogger
   arkouda.numpy.get_byteorder
   arkouda.numpy.get_server_byteorder
   arkouda.numpy.in1d
   arkouda.numpy.indexof1d
   arkouda.numpy.intersect1d
   arkouda.numpy.isSupportedBool
   arkouda.numpy.isSupportedDType
   arkouda.numpy.isSupportedDType
   arkouda.numpy.isSupportedFloat
   arkouda.numpy.isSupportedInt
   arkouda.numpy.isSupportedInt
   arkouda.numpy.isSupportedInt
   arkouda.numpy.isSupportedNumber
   arkouda.numpy.is_registered
   arkouda.numpy.linspace
   arkouda.numpy.maxk
   arkouda.numpy.mean
   arkouda.numpy.mink
   arkouda.numpy.mod
   arkouda.numpy.ones
   arkouda.numpy.ones
   arkouda.numpy.ones_like
   arkouda.numpy.parity
   arkouda.numpy.popcount
   arkouda.numpy.power
   arkouda.numpy.promote_to_common_dtype
   arkouda.numpy.randint
   arkouda.numpy.random_strings_lognormal
   arkouda.numpy.random_strings_uniform
   arkouda.numpy.register_all
   arkouda.numpy.resolve_scalar_dtype
   arkouda.numpy.rotl
   arkouda.numpy.rotr
   arkouda.numpy.scalar_array
   arkouda.numpy.segarray
   arkouda.numpy.setdiff1d
   arkouda.numpy.setxor1d
   arkouda.numpy.shape
   arkouda.numpy.sort
   arkouda.numpy.sqrt
   arkouda.numpy.squeeze
   arkouda.numpy.standard_normal
   arkouda.numpy.std
   arkouda.numpy.tile
   arkouda.numpy.timedelta_range
   arkouda.numpy.typechecked
   arkouda.numpy.uniform
   arkouda.numpy.union1d
   arkouda.numpy.unregister
   arkouda.numpy.unregister_all
   arkouda.numpy.unregister_pdarray_by_name
   arkouda.numpy.var
   arkouda.numpy.vstack
   arkouda.numpy.zeros
   arkouda.numpy.zeros
   arkouda.numpy.zeros_like


Package Contents
----------------

.. py:data:: ARKOUDA_SUPPORTED_DTYPES

.. py:data:: ARKOUDA_SUPPORTED_INTS

.. py:class:: Categorical

   Represents an array of values belonging to named categories. Converting a
   Strings object to Categorical often saves memory and speeds up operations,
   especially if there are many repeated values, at the cost of some one-time
   work in initialization.

   :param values: Values to convert to categories
   :type values: Strings, Categorical, pd.Categorical
   :param NAvalue: The value to use to represent missing/null data
   :type NAvalue: str scalar

   .. attribute:: categories

      The set of category labels (determined automatically)

      :type: Strings

   .. attribute:: codes

      The category indices of the values or -1 for N/A

      :type: pdarray, int64

   .. attribute:: permutation

      The permutation that groups the values in the same order as categories

      :type: pdarray, int64

   .. attribute:: segments

      When values are grouped, the starting offset of each group

      :type: pdarray, int64

   .. attribute:: size

      The number of items in the array

      :type: Union[int,np.int64]

   .. attribute:: nlevels

      The number of distinct categories

      :type: Union[int,np.int64]

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: Union[int,np.int64]

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple


   .. py:method:: BinOps(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: RegisterablePieces(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: RequiredPieces(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: argsort()


   .. py:method:: attach(user_defined_name: str) -> Categorical

      DEPRECATED
      Function to return a Categorical object attached to the registered name in the
      arkouda server which was registered using register()

      :param user_defined_name: user defined name which Categorical object was registered under
      :type user_defined_name: str

      :returns: The Categorical object created by re-attaching to the corresponding server components
      :rtype: Categorical

      :raises TypeError: if user_defined_name is not a string

      .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_categorical_by_name`



   .. py:method:: concatenate(others: Sequence[Categorical], ordered: bool = True) -> Categorical

      Merge this Categorical with other Categorical objects in the array,
      concatenating the arrays and synchronizing the categories.

      :param others: The Categorical arrays to concatenate and merge with this one
      :type others: Sequence[Categorical]
      :param ordered: If True (default), the arrays will be appended in the
                      order given. If False, array data may be interleaved
                      in blocks, which can greatly improve performance but
                      results in non-deterministic ordering of elements.
      :type ordered: bool

      :returns: The merged Categorical object
      :rtype: Categorical

      :raises TypeError: Raised if any others array objects are not Categorical objects

      .. rubric:: Notes

      This operation can be expensive -- slower than concatenating Strings.



   .. py:method:: contains(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element contains the given substring.

      :param substr: The substring to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.endswith`

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.



   .. py:method:: dtype(*args, **kwargs)

      DType class corresponding to the scalar type and dtype of the same name.

      Please see `numpy.dtype` for the typical way to create
      dtype instances and :ref:`arrays.dtypes` for additional
      information.




   .. py:method:: endswith(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element ends with the given substring.

      :param substr: The substring to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.contains`

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.



   .. py:method:: equals(other) -> bool_scalars

      Whether Categoricals are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the Categoricals are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> c = Categorical(ak.array(["a", "b", "c"]))
      >>> c_cpy = Categorical(ak.array(["a", "b", "c"]))
      >>> c.equals(c_cpy)
      True
      >>> c2 = Categorical(ak.array(["a", "x", "c"]))
      >>> c.equals(c2)
      False



   .. py:method:: from_codes(codes: pdarray, categories: Strings, permutation=None, segments=None, **kwargs) -> Categorical

      Make a Categorical from codes and categories arrays. If codes and
      categories have already been pre-computed, this constructor saves
      time. If not, please use the normal constructor.

      :param codes: Category indices of each value
      :type codes: pdarray, int64
      :param categories: Unique category labels
      :type categories: Strings
      :param permutation: The permutation that groups the values in the same order
                          as categories
      :type permutation: pdarray, int64
      :param segments: When values are grouped, the starting offset of each group
      :type segments: pdarray, int64

      :returns: The Categorical object created from the input parameters
      :rtype: Categorical

      :raises TypeError: Raised if codes is not a pdarray of int64 objects or if
          categories is not a Strings object



   .. py:method:: from_return_msg(rep_msg) -> Categorical

      Create categorical from return message from server

      .. rubric:: Notes

      This is currently only used when reading a Categorical from HDF5 files.



   .. py:method:: group() -> pdarray

      Return the permutation that groups the array, placing equivalent
      categories together. All instances of the same category are guaranteed
      to lie in one contiguous block of the permuted array, but the blocks
      are not necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      This method is faster than the corresponding Strings method. If the
      Categorical was created from a Strings object, then this function
      simply returns the cached permutation. Even if the Categorical was
      created using from_codes(), this function will be faster than
      Strings.group() because it sorts dense integer values, rather than
      128-bit hash values.



   .. py:method:: hash() -> Tuple[pdarray, pdarray]

      Compute a 128-bit hash of each element of the Categorical.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:method:: in1d(test: Union[Strings, Categorical]) -> pdarray

      Test whether each element of the Categorical object is
      also present in the test Strings or Categorical object.

      Returns a boolean array the same length as `self` that is True
      where an element of `self` is in `test` and False otherwise.

      :param test: The values against which to test each value of 'self`.
      :type test: Union[Strings,Categorical]

      :returns: The values `self[in1d]` are in the `test` Strings or Categorical object.
      :rtype: pdarray, bool

      :raises TypeError: Raised if test is not a Strings or Categorical object

      .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

      .. rubric:: Notes

      `in1d` can be considered as an element-wise function version of the
      python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
      equivalent to ``ak.array([item in b for item in a])``, but is much
      faster and scales to arbitrarily large ``a``.

      .. rubric:: Examples

      >>> strings = ak.array([f'String {i}' for i in range(0,5)])
      >>> cat = ak.Categorical(strings)
      >>> ak.in1d(cat,strings)
      array([True True True True True])
      >>> strings = ak.array([f'String {i}' for i in range(5,9)])
      >>> catTwo = ak.Categorical(strings)
      >>> ak.in1d(cat,catTwo)
      array([False False False False False])



   .. py:property:: inferred_type
      :type: pdarray


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> np.bool_

      Return True iff the object is contained in the registry or is a component of a
      registered object.

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_categorical_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: isna()

      Find where values are missing or null (as defined by self.NAvalue)




   .. py:property:: nbytes

      The size of the Categorical in bytes.

      :returns: The size of the Categorical in bytes.
      :rtype: int


   .. py:method:: objType(*args, **kwargs)

      str(object='') -> str
      str(bytes_or_buffer[, encoding[, errors]]) -> str

      Create a new string object from the given object. If encoding or
      errors is specified, then the object must expose a data buffer
      that will be decoded using the given encoding and error handler.
      Otherwise, returns the result of object.__str__() (if defined)
      or repr(object).
      encoding defaults to sys.getdefaultencoding().
      errors defaults to 'strict'.




   .. py:method:: parse_hdf_categoricals(d: Mapping[str, Union[pdarray, Strings]]) -> Tuple[List[str], Dict[str, Categorical]]

      This function should be used in conjunction with the load_all function which reads hdf5 files
      and reconstitutes Categorical objects.
      Categorical objects use a naming convention and HDF5 structure so they can be identified and
      constructed for the user.

      In general you should not call this method directly

      :param d:
      :type d: Dictionary of String to either Pdarray or Strings object

      :returns: * *2-Tuple of List of strings containing key names which should be removed and Dictionary of*
                * *base name to Categorical object*

      .. seealso:: :obj:`Categorical.save`, :obj:`load_all`



   .. py:method:: permutation(*args, **kwargs)


   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: register(user_defined_name: str) -> Categorical

      Register this Categorical object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Categorical is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Categorical which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different Categoricals with the same name.
      :rtype: Categorical

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Categorical with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: reset_categories() -> Categorical

      Recompute the category labels, discarding any unused labels. This
      method is often useful after slicing or indexing a Categorical array,
      when the resulting array only contains a subset of the original
      categories. In this case, eliminating unused categories can speed up
      other operations.

      :returns: A Categorical object generated from the current instance
      :rtype: Categorical



   .. py:method:: save(prefix_path: str, dataset: str = 'categorical_array', file_format: str = 'HDF5', mode: str = 'truncate', file_type: str = 'distribute', compression: Optional[str] = None) -> str

      DEPRECATED
      Save the Categorical object to HDF5 or Parquet. The result is a collection of HDF5/Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path and dataset. Each locale saves its chunk of the Strings array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param file_format: The format to save the file to.
      :type file_format: str {'HDF5 | 'Parquet'}
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")
      :param compression: {None | 'snappy' | 'gzip' | 'brotli' | 'zstd' | 'lz4'}
                          The compression type to use when writing.
                          This is only supported for Parquet files and will not be used with HDF5.
      :type compression: str (Optional)

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.

      .. seealso:: :obj:`-`, :obj:`-`



   .. py:method:: segments(*args, **kwargs)


   .. py:method:: set_categories(new_categories, NAvalue=None)

      Set categories to user-defined values.

      :param new_categories: The array of new categories to use. Must be unique.
      :type new_categories: Strings
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A new Categorical with the user-defined categories. Old values present
                in new categories will appear unchanged. Old values not present will
                be assigned the NA value.
      :rtype: Categorical



   .. py:method:: sort_values()


   .. py:method:: standardize_categories(arrays, NAvalue='N/A')

      Standardize an array of Categoricals so that they share the same categories.

      :param arrays: The Categoricals to standardize
      :type arrays: sequence of Categoricals
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A list of the original Categoricals remapped to the shared categories.
      :rtype: List of Categoricals



   .. py:method:: startswith(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element starts with the given substring.

      :param substr: The substring to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Categorical.contains`, :obj:`Categorical.endswith`

      .. rubric:: Notes

      This method can be significantly faster than the corresponding
      method on Strings objects, because it searches the unique category
      labels instead of the full array.



   .. py:method:: to_hdf(prefix_path, dataset='categorical_array', mode='truncate', file_type='distribute')

      Save the Categorical to HDF5. The result is a collection of HDF5 files, one file
      per locale of the arkouda server, where each filename starts with prefix_path.

      :param prefix_path: Directory and filename prefix that all output files will share
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 file
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', add data as a new column to existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
      :type file_type: str ("single" | "distribute")

      :rtype: None

      .. seealso:: :obj:`load`



   .. py:method:: to_list() -> List

      Convert the Categorical to a list, transferring data from
      the arkouda server to Python. This conversion discards category
      information and produces a list of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A list of strings corresponding to the values in
                this Categorical
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the Categorical cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.



   .. py:method:: to_ndarray() -> np.ndarray

      Convert the array to a np.ndarray, transferring array data from
      the arkouda server to Python. This conversion discards category
      information and produces an ndarray of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A numpy ndarray of strings corresponding to the values in
                this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.



   .. py:method:: to_pandas() -> pd_Categorical

      Return the equivalent Pandas Categorical.




   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'categorical_array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      This functionality is currently not supported and will also raise a RuntimeError.
      Support is in development.
      Save the Categorical to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: Default None
                          Provide the compression type to use when writing the file.
                          Supported values: snappy, gzip, brotli, zstd, lz4
      :type compression: str (Optional)

      :rtype: String message indicating result of save operation

      :raises RuntimeError: On run due to compatability issues of Categorical with Parquet.

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_strings() -> List

      Convert the Categorical to Strings.

      :returns: A Strings object corresponding to the values in
                this Categorical.
      :rtype: arkouda.numpy.strings.Strings

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> a = ak.array(["a","b","c"])
      >>> a
      array(['a', 'b', 'c'])
      >>> c = ak.Categorical(a)
      >>> c.to_strings()
      array(['a', 'b', 'c'])

      >>> isinstance(c.to_strings(), ak.Strings)
      True



   .. py:method:: transfer(hostname: str, port: int_scalars)

      Sends a Categorical object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Categorical is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unique() -> Categorical


   .. py:method:: unregister() -> None

      Unregister this Categorical object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_categorical_by_name(user_defined_name: str) -> None

      Function to unregister Categorical object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the Categorical object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path, dataset='categorical_array', repack=True)

      Overwrite the dataset with the name provided with this Categorical object. If
      the dataset does not exist it is added.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: None

      :raises RuntimeError: Raised if a server-side error is thrown saving the Categorical

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added
      - Because HDF5 deletes do not release memory, the repack option allows for
        automatic creation of a file without the inaccessible data.



.. py:class:: DType

   Bases: :py:obj:`enum.Enum`


   Generic enumeration.

   Derive from this class to define new enumerations.


   .. py:attribute:: BIGINT
      :value: 'bigint'



   .. py:attribute:: BOOL
      :value: 'bool'



   .. py:attribute:: COMPLEX128
      :value: 'complex128'



   .. py:attribute:: COMPLEX64
      :value: 'complex64'



   .. py:attribute:: FLOAT
      :value: 'float'



   .. py:attribute:: FLOAT32
      :value: 'float32'



   .. py:attribute:: FLOAT64
      :value: 'float64'



   .. py:attribute:: INT
      :value: 'int'



   .. py:attribute:: INT16
      :value: 'int16'



   .. py:attribute:: INT32
      :value: 'int32'



   .. py:attribute:: INT64
      :value: 'int64'



   .. py:attribute:: INT8
      :value: 'int8'



   .. py:attribute:: STR
      :value: 'str'



   .. py:attribute:: UINT
      :value: 'uint'



   .. py:attribute:: UINT16
      :value: 'uint16'



   .. py:attribute:: UINT32
      :value: 'uint32'



   .. py:attribute:: UINT64
      :value: 'uint64'



   .. py:attribute:: UINT8
      :value: 'uint8'



.. py:data:: DTypeObjects

.. py:data:: DTypes

.. py:class:: Datetime(pda, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`


   Represents a date and/or time.

   Datetime is the Arkouda analog to pandas DatetimeIndex and
   other timeseries data types.

   :param pda:
   :type pda: int64 pdarray, pd.DatetimeIndex, pd.Series, or np.datetime64 array
   :param unit: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type unit: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.


   .. py:property:: date


   .. py:property:: day


   .. py:property:: day_of_week


   .. py:property:: day_of_year


   .. py:property:: dayofweek


   .. py:property:: dayofyear


   .. py:property:: hour


   .. py:property:: is_leap_year


   .. py:method:: is_registered() -> numpy.bool_

       Return True iff the object is contained in the registry or is a component of a
       registered object.

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: isocalendar()


   .. py:property:: microsecond


   .. py:property:: millisecond


   .. py:property:: minute


   .. py:property:: month


   .. py:property:: nanosecond


   .. py:method:: register(user_defined_name)

      Register this Datetime object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Datetime is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Datetime which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different Datetimes with the same name.
      :rtype: Datetime

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Datetimes with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: second


   .. py:attribute:: special_objType
      :value: 'Datetime'



   .. py:method:: sum()

      Return sum of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.sum(ak.array([1,2,3,4,5]))
      15
      >>> ak.sum(ak.array([5.5,4.5,3.5,2.5,1.5]))
      17.5
      >>> ak.array([[1,2,3],[5,4,3]]).sum(axis=1)
      array([6 12])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.sum()) or a standalone function (e.g. ak.sum(a))



   .. py:attribute:: supported_opeq


   .. py:attribute:: supported_with_datetime


   .. py:attribute:: supported_with_pdarray


   .. py:attribute:: supported_with_r_datetime


   .. py:attribute:: supported_with_r_pdarray


   .. py:attribute:: supported_with_r_timedelta


   .. py:attribute:: supported_with_timedelta


   .. py:method:: to_pandas()

      Convert array to a pandas DatetimeIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`



   .. py:method:: unregister()

      Unregister this Datetime object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: week


   .. py:property:: weekday


   .. py:property:: weekofyear


   .. py:property:: year


.. py:class:: GroupBy

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. attribute:: dropna

      If True, and the groupby keys contain NaN values,
      the NaN values together with the corresponding row will be dropped.
      Otherwise, the rows corresponding to NaN values will be kept.

      :type: bool (default=True)

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Integral pdarrays, Strings, and Categoricals are natively supported, but
   float64 and bool arrays are not.

   For a user-defined class to be groupable, it must inherit from pdarray
   and define or overload the grouping API:
     1) a ._get_grouping_keys() method that returns a list of pdarrays
        that can be (co)argsorted.
     2) (Optional) a .group() method that returns the permutation that
        groups the array
   If the input is a single array with a .group() method defined, method 2
   will be used; otherwise, method 1 will be used.


   .. py:method:: AND(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: OR(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: Reductions(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: XOR(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: aggregate(values: groupable, operator: str, skipna: bool = True, ddof: int_scalars = 1) -> Tuple[groupable, groupable]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool
      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))



   .. py:method:: all(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: any(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array



   .. py:method:: argmax(values: pdarray) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))



   .. py:method:: argmin(values: pdarray) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))



   .. py:method:: attach(user_defined_name: str) -> GroupBy

      Function to return a GroupBy object attached to the registered name in the
      arkouda server which was registered using register()

      :param user_defined_name: user defined name which GroupBy object was registered under
      :type user_defined_name: str

      :returns: The GroupBy object created by re-attaching to the corresponding server components
      :rtype: GroupBy

      :raises RegistrationError: if user_defined_name is not registered

      .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_groupby_by_name`



   .. py:method:: broadcast(values: Union[pdarray, Strings], permute: bool = True) -> Union[pdarray, Strings]

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray, Strings
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcasted values
      :rtype: pdarray, Strings

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])
      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]
      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.size()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



   .. py:method:: build_from_components(user_defined_name: Optional[str] = None, **kwargs) -> GroupBy

      function to build a new GroupBy object from component keys and permutation.

      :param user_defined_name: and assign it the given name
      :type user_defined_name: str (Optional) Passing a name will init the new GroupBy
      :param kwargs: Expected keys are "orig_keys", "permutation", "unique_keys", and "segments"
      :type kwargs: dict Dictionary of components required for rebuilding the GroupBy.

      :returns: The GroupBy object created by using the given components
      :rtype: GroupBy



   .. py:method:: count(values: pdarray) -> Tuple[groupable, pdarray]

      Count the number of elements in each group.  NaN values will be excluded from the total.

      :param values: The values to be count by group (excluding NaN values).
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears (excluding NaN values).

      .. rubric:: Examples

      >>> a = ak.array([1, 0, -1, 1, 0, -1])
      >>> a
      array([1 0 -1 1 0 -1])
      >>> b = ak.array([1, np.nan, -1, np.nan, np.nan, -1], dtype = "float64")
      >>> b
      array([1.00000000000000000 nan -1.00000000000000000 nan nan -1.00000000000000000])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count(b)
      >>> keys
      array([-1 0 1])
      >>> counts
      array([2 0 1])



   .. py:method:: first(values: groupable_element_type) -> Tuple[groupable, groupable_element_type]

      First value in each group.

      :param values: The values from which to take the first of each group
      :type values: pdarray-like

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*pdarray-like*) -- The first value of each group



   .. py:method:: from_return_msg(rep_msg)


   .. py:method:: head(values: groupable_element_type, n: int = 5, return_indices: bool = True) -> Tuple[groupable, groupable_element_type]

      Return the first n values from each group.

      :param values: The values from which to select, according to their group membership.
      :type values: (list of) pdarray-like
      :param n: Maximum number of items to return for each group.
                If the number of values in a group is less than n,
                all the values from that group will be returned.
      :type n: int, optional, default = 5
      :param return_indices: If True, return the indices of the sampled values.
                             Otherwise, return the selected values.
      :type return_indices: bool, default False

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*pdarray-like*) -- The first n items of each group.
                  If return_indices is True, the result are indices.
                  O.W. the result are values.

      .. rubric:: Examples

      >>> a = ak.arange(10) %3
      >>> a
      array([0 1 2 0 1 2 0 1 2 0])
      >>> v = ak.arange(10)
      >>> v
      array([0 1 2 3 4 5 6 7 8 9])
      >>> g = GroupBy(a)
      >>> unique_keys, idx = g.head(v, 2, return_indices=True)
      >>> _, values = g.head(v, 2, return_indices=False)
      >>> unique_keys
      array([0 1 2])
      >>> idx
      array([0 3 1 4 2 5])
      >>> values
      array([0 3 1 4 2 5])

      >>> v2 =  -2 * ak.arange(10)
      >>> v2
      array([0 -2 -4 -6 -8 -10 -12 -14 -16 -18])
      >>> _, idx2 = g.head(v2, 2, return_indices=True)
      >>> _, values2 = g.head(v2, 2, return_indices=False)
      >>> idx2
      array([0 3 1 4 2 5])
      >>> values2
      array([0 -6 -2 -8 -4 -10])



   .. py:method:: is_registered() -> bool

      Return True if the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RegistrationError: Raised if there's a server-side error or a mismatch of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_groupby_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: max(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))



   .. py:method:: mean(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))



   .. py:method:: median(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the median of each group's
      values.

      :param values: The values to group and find median
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_medians** (*pdarray, float64*) -- One median value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,9)
      >>> a
      array([4 1 4 3 2 2 2 3 3])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([4 1 4 3 2 2 2 3 3])
      >>> b = ak.linspace(-5,5,9)
      >>> b
      array([-5 -3.75 -2.5 -1.25 0 1.25 2.5 3.75 5])
      >>> g.median(b)
      (array([1 2 3 4]), array([-3.75 1.25 3.75 -3.75]))



   .. py:method:: min(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))



   .. py:method:: mode(values: groupable) -> Tuple[groupable, groupable]

      Most common value in each group. If a group is multi-modal, return the
      modal value that occurs first.

      :param values: The values from which to take the mode of each group
      :type values: (list of) pdarray-like

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*(list of) pdarray-like*) -- The most common value of each group



   .. py:method:: most_common(values)

      (Deprecated) See `GroupBy.mode()`.




   .. py:method:: nunique(values: groupable) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value



   .. py:method:: objType(*args, **kwargs)

      str(object='') -> str
      str(bytes_or_buffer[, encoding[, errors]]) -> str

      Create a new string object from the given object. If encoding or
      errors is specified, then the object must expose a data buffer
      that will be decoded using the given encoding and error handler.
      Otherwise, returns the result of object.__str__() (if defined)
      or repr(object).
      encoding defaults to sys.getdefaultencoding().
      errors defaults to 'strict'.




   .. py:method:: prod(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))



   .. py:method:: register(user_defined_name: str) -> GroupBy

      Register this GroupBy object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the GroupBy is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same GroupBy which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different GroupBys with the same name.
      :rtype: GroupBy

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the GroupBy with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_groupby_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: sample(values: groupable, n=None, frac=None, replace=False, weights=None, random_state=None, return_indices=False, permute_samples=False)

      Return a random sample from each group. You can either specify the number of elements
      or the fraction of elements to be sampled. random_state can be used for reproducibility

      :param values: The values from which to sample, according to their group membership.
      :type values: (list of) pdarray-like
      :param n: Number of items to return for each group.
                Cannot be used with frac and must be no larger than
                the smallest group unless replace is True.
                Default is one if frac is None.
      :type n: int, optional
      :param frac: Fraction of items to return. Cannot be used with n.
      :type frac: float, optional
      :param replace: Allow or disallow sampling of the value more than once.
      :type replace: bool, default False
      :param weights: Default None results in equal probability weighting.
                      If passed a pdarray, then values must have the same length as the groupby keys
                      and will be used as sampling probabilities after normalization within each group.
                      Weights must be non-negative with at least one positive element within each group.
      :type weights: pdarray, optional
      :param random_state: If int, seed for random number generator.
                           If ak.random.Generator, use as given.
      :type random_state: int or ak.random.Generator, optional
      :param return_indices: if True, return the indices of the sampled values.
                             Otherwise, return the sample values.
      :type return_indices: bool, default False
      :param permute_samples: if True, return permute the samples according to group
                              Otherwise, keep samples in original order.
      :type permute_samples: bool, default False

      :returns: if return_indices is True, return the indices of the sampled values.
                Otherwise, return the sample values.
      :rtype: pdarray



   .. py:method:: size() -> Tuple[groupable, pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.  This counts the total number of rows (including NaN values).

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. seealso:: :obj:`count`

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.size()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])



   .. py:method:: std(values: pdarray, skipna: bool = True, ddof: int_scalars = 1) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the standard deviation of
      each group's values.

      :param values: The values to group and find standard deviation
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool
      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_stds** (*pdarray, float64*) -- One std value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      The standard deviation is the square root of the average of the squared
      deviations from the mean, i.e., ``std = sqrt(mean((x - x.mean())**2))``.

      The average squared deviation is normally calculated as
      ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is specified,
      the divisor ``N - ddof`` is used instead. In standard statistical
      practice, ``ddof=1`` provides an unbiased estimator of the variance
      of the infinite population. ``ddof=0`` provides a maximum likelihood
      estimate of the variance for normally distributed variables. The
      standard deviation computed in this function is the square root of
      the estimated variance, so even with ``ddof=1``, it will not be an
      unbiased estimate of the standard deviation per se.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.std(b)
      (array([2 3 4]), array([1.5275252316519465 1.0954451150103321 0]))



   .. py:method:: sum(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))



   .. py:method:: tail(values: groupable_element_type, n: int = 5, return_indices: bool = True) -> Tuple[groupable, groupable_element_type]

      Return the last n values from each group.

      :param values: The values from which to select, according to their group membership.
      :type values: (list of) pdarray-like
      :param n: Maximum number of items to return for each group.
                If the number of values in a group is less than n,
                all the values from that group will be returned.
      :type n: int, optional, default = 5
      :param return_indices: If True, return the indices of the sampled values.
                             Otherwise, return the selected values.
      :type return_indices: bool, default False

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*pdarray-like*) -- The last n items of each group.
                  If return_indices is True, the result are indices.
                  O.W. the result are values.

      .. rubric:: Examples

      >>> a = ak.arange(10) %3
      >>> a
      array([0 1 2 0 1 2 0 1 2 0])
      >>> v = ak.arange(10)
      >>> v
      array([0 1 2 3 4 5 6 7 8 9])
      >>> g = GroupBy(a)
      >>> unique_keys, idx = g.tail(v, 2, return_indices=True)
      >>> _, values = g.tail(v, 2, return_indices=False)
      >>> unique_keys
      array([0 1 2])
      >>> idx
      array([6 9 4 7 5 8])
      >>> values
      array([6 9 4 7 5 8])

      >>> v2 =  -2 * ak.arange(10)
      >>> v2
      array([0 -2 -4 -6 -8 -10 -12 -14 -16 -18])
      >>> _, idx2 = g.tail(v2, 2, return_indices=True)
      >>> _, values2 = g.tail(v2, 2, return_indices=False)
      >>> idx2
      array([6 9 4 7 5 8])
      >>> values2
      array([-12 -18 -8 -14 -10 -16])



   .. py:method:: to_hdf(prefix_path, dataset='groupby', mode='truncate', file_type='distribute')

      Save the GroupBy to HDF5. The result is a collection of HDF5 files, one file
      per locale of the arkouda server, where each filename starts with prefix_path.

      :param prefix_path: Directory and filename prefix that all output files will share
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 file
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', add data as a new column to existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :returns: * *None*
                * *GroupBy is not currently supported by Parquet*



   .. py:method:: unique(values: groupable)

      Return the set of unique values in each group, as a SegArray.

      :param values: The values to unique
      :type values: (list of) pdarray-like

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*(list of) SegArray*) -- The unique values of each group

      :raises TypeError: Raised if values is or contains Strings or Categorical



   .. py:method:: unregister()

      Unregister this GroupBy object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_groupby_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_groupby_by_name(user_defined_name: str) -> None

      Function to unregister GroupBy object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the GroupBy object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'groupby', repack: bool = True)


   .. py:method:: var(values: pdarray, skipna: bool = True, ddof: int_scalars = 1) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the variance of
      each group's values.

      :param values: The values to group and find variance
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool
      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_vars** (*pdarray, float64*) -- One var value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      The variance is the average of the squared deviations from the mean,
      i.e.,  ``var = mean((x - x.mean())**2)``.

      The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
      If, however, `ddof` is specified, the divisor ``N - ddof`` is used
      instead.  In standard statistical practice, ``ddof=1`` provides an
      unbiased estimator of the variance of a hypothetical infinite population.
      ``ddof=0`` provides a maximum likelihood estimate of the variance for
      normally distributed variables.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.var(b)
      (array([2 3 4]), array([2.333333333333333 1.2 0]))



.. py:class:: Iterable(origin, *, inst=True, name=None)

   Bases: :py:obj:`_BaseGenericAlias`


   A generic version of collections.abc.Iterable.



   .. py:method:: copy_with(params)


.. py:data:: LEN_SUFFIX
   :value: '_lengths'


.. py:data:: NUMBER_FORMAT_STRINGS

.. py:data:: NumericDTypes

.. py:class:: Optional

   Bases: :py:obj:`_Final`


   Optional type.

       Optional[X] is equivalent to Union[X, None].




.. py:exception:: RegistrationError

   Bases: :py:obj:`Exception`


   Error/Exception used when the Arkouda Server cannot register an object


.. py:exception:: RegistrationError

   Bases: :py:obj:`Exception`


   Error/Exception used when the Arkouda Server cannot register an object


.. py:exception:: RegistrationError

   Bases: :py:obj:`Exception`


   Error/Exception used when the Arkouda Server cannot register an object


.. py:data:: SEG_SUFFIX
   :value: '_segments'


.. py:data:: ScalarDTypes

.. py:class:: SegArray(segments, values, lengths=None, grouping=None)

   .. py:method:: AND(x=None)


   .. py:method:: OR(x=None)


   .. py:method:: XOR(x=None)


   .. py:method:: aggregate(op, x=None)


   .. py:method:: all(x=None)


   .. py:method:: any(x=None)


   .. py:method:: append(other, axis=0)

      Append other to self, either vertically (axis=0, length of resulting SegArray
      increases), or horizontally (axis=1, each sub-array of other appends to the
      corresponding sub-array of self).

      :param other: Array of sub-arrays to append
      :type other: SegArray
      :param axis: Whether to append vertically (0) or horizontally (1). If axis=1, other
                   must be same size as self.
      :type axis: 0 or 1

      :returns: axis=0: New SegArray containing all sub-arrays
                axis=1: New SegArray of same length, with pairs of sub-arrays concatenated
      :rtype: SegArray



   .. py:method:: append_single(x, prepend=False)

      Append a single value to each sub-array.

      :param x: Single value to append to each sub-array
      :type x: pdarray or scalar

      :returns: Copy of original SegArray with values from x appended to each sub-array
      :rtype: SegArray



   .. py:method:: argmax(x=None)


   .. py:method:: argmin(x=None)


   .. py:method:: attach(user_defined_name)
      :classmethod:


      Using the defined name, attach to a SegArray that has been registered to the Symbol Table

      :param user_defined_name: user defined name which the SegArray object was registered under
      :type user_defined_name: str

      :returns: The resulting SegArray
      :rtype: SegArray

      :raises RuntimeError: Raised if the server could not attach to the SegArray object

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`



   .. py:method:: concat(x, axis=0, ordered=True)
      :classmethod:


      Concatenate a sequence of SegArrays

      :param x: The SegArrays to concatenate
      :type x: sequence of SegArray
      :param axis: Select vertical (0) or horizontal (1) concatenation. If axis=1, all
                   SegArrays must have same size.
      :type axis: 0 or 1
      :param ordered: Must be True. This option is present for compatibility only, because unordered
                      concatenation is not yet supported.
      :type ordered: bool

      :returns: The input arrays joined into one SegArray
      :rtype: SegArray



   .. py:method:: copy()

      Return a deep copy.



   .. py:attribute:: dtype


   .. py:method:: filter(filter, discard_empty: bool = False)

      Filter values out of the SegArray object

      :param filter: The value/s to be filtered out of the SegArray
      :type filter: pdarray, list, or value
      :param discard_empty: Defaults to False. When True, empty segments are removed from
                            the return SegArray
      :type discard_empty: bool

      :rtype: SegArray



   .. py:method:: from_multi_array(m)
      :classmethod:


      Construct a SegArray from a list of columns. This essentially transposes the input,
      resulting in an array of rows.

      :param m: List of columns, the rows of which will form the sub-arrays of the output
      :type m: list of pdarray or Strings

      :returns: Array of rows of input
      :rtype: SegArray



   .. py:method:: from_parts(segments, values, lengths=None, grouping=None) -> SegArray
      :classmethod:


      DEPRECATED
      Construct a SegArray object from its parts

      :param segments: Start index of each sub-array in the flattened values array
      :type segments: pdarray, int64
      :param values: The flattened values of all sub-arrays
      :type values: pdarray
      :param lengths: The length of each segment
      :type lengths: pdarray
      :param grouping: grouping of segments
      :type grouping: GroupBy

      :returns: Data structure representing an array whose elements are variable-length arrays.
      :rtype: SegArray

      .. rubric:: Notes

      Keyword args 'lengths' and 'grouping' are not user-facing. They are used by the
      attach method.



   .. py:method:: from_return_msg(rep_msg) -> SegArray
      :classmethod:



   .. py:method:: get_jth(j, return_origins=True, compressed=False, default=0)

      Select the j-th element of each sub-array, where possible.

      :param j: The index of the value to get from each sub-array. If j is negative,
                it counts backwards from the end of each sub-array.
      :type j: int
      :param return_origins: If True, return a logical index indicating where j is in bounds
      :type return_origins: bool
      :param compressed: If False, return array is same size as self, with default value
                         where j is out of bounds. If True, the return array only contains
                         values where j is in bounds.
      :type compressed: bool
      :param default: When compressed=False, the value to return when j is out of bounds
                      for the sub-array
      :type default: scalar

      :returns: * **val** (*pdarray*) -- compressed=False: The j-th value of each sub-array where j is in
                  bounds and the default value where j is out of bounds.
                  compressed=True: The j-th values of only the sub-arrays where j is
                  in bounds
                * **origin_indices** (*pdarray, bool*) -- A Boolean array that is True where j is in bounds for the sub-array.

      .. rubric:: Notes

      If values are Strings, only the compressed format is supported.



   .. py:method:: get_length_n(n, return_origins=True)

      Return all sub-arrays of length n, as a list of columns.

      :param n: Length of sub-arrays to select
      :type n: int
      :param return_origins: Return a logical index indicating which sub-arrays are length n
      :type return_origins: bool

      :returns: * **columns** (*list of pdarray*) -- An n-long list of pdarray, where each row is one of the n-long
                  sub-arrays from the SegArray. The number of rows is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Array of bool for each element of the SegArray, True where sub-array
                  has length n.



   .. py:method:: get_ngrams(n, return_origins=True)

      Return all n-grams from all sub-arrays.

      :param n: Length of n-gram
      :type n: int
      :param return_origins: If True, return an int64 array indicating which sub-array
                             each returned n-gram came from.
      :type return_origins: bool

      :returns: * **ngrams** (*list of pdarray*) -- An n-long list of pdarrays, essentially a table where each row is an n-gram.
                * **origin_indices** (*pdarray, int*) -- The index of the sub-array from which the corresponding n-gram originated



   .. py:method:: get_prefixes(n, return_origins=True, proper=True)

      Return all sub-array prefixes of length n (for sub-arrays that are at least n+1 long)

      :param n: Length of suffix
      :type n: int
      :param return_origins: If True, return a logical index indicating which sub-arrays
                             were long enough to return an n-prefix
      :type return_origins: bool
      :param proper: If True, only return proper prefixes, i.e. from sub-arrays
                     that are at least n+1 long. If False, allow the entire
                     sub-array to be returned as a prefix.
      :type proper: bool

      :returns: * **prefixes** (*list of pdarray*) -- An n-long list of pdarrays, essentially a table where each row is an n-prefix.
                  The number of rows is the number of True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the sub-array was long enough to return
                  an n-suffix, False otherwise.



   .. py:method:: get_suffixes(n, return_origins=True, proper=True)

      Return the n-long suffix of each sub-array, where possible

      :param n: Length of suffix
      :type n: int
      :param return_origins: If True, return a logical index indicating which sub-arrays
                             were long enough to return an n-suffix
      :type return_origins: bool
      :param proper: If True, only return proper suffixes, i.e. from sub-arrays
                     that are at least n+1 long. If False, allow the entire
                     sub-array to be returned as a suffix.
      :type proper: bool

      :returns: * **suffixes** (*list of pdarray*) -- An n-long list of pdarrays, essentially a table where each row is an n-suffix.
                  The number of rows is the number of True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the sub-array was long enough to return
                  an n-suffix, False otherwise.



   .. py:property:: grouping


   .. py:method:: hash() -> Tuple[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.pdarrayclass.pdarray]

      Compute a 128-bit hash of each segment.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]



   .. py:method:: intersect(other)

      Computes the intersection of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d intersections of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.intersect1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.intersect(seg_b)
      SegArray([
      [1, 3],
      [4]
      ])



   .. py:method:: is_registered() -> bool

      Checks if the name of the SegArray object is registered in the Symbol Table

      :returns: True if SegArray is registered, false if not
      :rtype: bool

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`



   .. py:method:: load(prefix_path, dataset='segarray', segment_name='segments', value_name='values')
      :classmethod:



   .. py:attribute:: logger


   .. py:method:: max(x=None)


   .. py:method:: mean(x=None)


   .. py:method:: min(x=None)


   .. py:property:: nbytes

      The size of the segarray in bytes.

      :returns: The size of the segarray in bytes.
      :rtype: int


   .. py:property:: non_empty


   .. py:method:: nunique(x=None)


   .. py:attribute:: objType
      :value: 'SegArray'



   .. py:method:: prepend_single(x)


   .. py:method:: prod(x=None)


   .. py:method:: read_hdf(prefix_path, dataset='segarray')
      :classmethod:


      Load a saved SegArray from HDF5. All arguments must match what
      was supplied to SegArray.save()

      :param prefix_path: Directory and filename prefix
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 files
      :type dataset: str

      :rtype: SegArray



   .. py:method:: register(user_defined_name)

      Register this SegArray object and underlying components with the Arkouda server

      :param user_defined_name: user defined name which this SegArray object will be registered under
      :type user_defined_name: str

      :returns: The same SegArray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different SegArrays with the same name.
      :rtype: SegArray

      :raises RegistrationError: Raised if the server could not register the SegArray object

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:attribute:: registered_name
      :type:  Optional[str]
      :value: None



   .. py:method:: remove_repeats(return_multiplicity=False)

      Condense sequences of repeated values within a sub-array to a single value.

      :param return_multiplicity: If True, also return the number of times each value was repeated.
      :type return_multiplicity: bool

      :returns: * **norepeats** (*SegArray*) -- Sub-arrays with runs of repeated values replaced with single value
                * **multiplicity** (*SegArray*) -- If return_multiplicity=True, this array contains the number of times
                  each value in the returned SegArray was repeated in the original SegArray.



   .. py:method:: save(prefix_path, dataset='segarray', mode='truncate', file_type='distribute')

      DEPRECATED
      Save the SegArray to HDF5.
      The object can be saved to a collection of files or single file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. seealso:: :obj:`to_hdf`, :obj:`load`



   .. py:attribute:: segments


   .. py:method:: set_jth(i, j, v)

      Set the j-th element of each sub-array in a subset.

      :param i: Indices of sub-arrays to set j-th element
      :type i: pdarray, int
      :param j: Index of value to set in each sub-array. If j is negative, it counts
                backwards from the end of the sub-array.
      :type j: int
      :param v: The value(s) to set. If v is a pdarray, it must have same length as i.
      :type v: pdarray or scalar

      :raises ValueError: If j is out of bounds in any of the sub-arrays specified by i.



   .. py:method:: setdiff(other)

      Computes the set difference of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d set difference of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.setdiff1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.setdiff(seg_b)
      SegArray([
      [2, 4],
      [1, 3, 5]
      ])



   .. py:method:: setxor(other)

      Computes the symmetric difference of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d symmetric difference of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.setxor1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.setxor(seg_b)
      SegArray([
      [2, 4, 5],
      [1, 3, 5, 2]
      ])



   .. py:attribute:: size


   .. py:method:: sum(x=None)


   .. py:method:: to_hdf(prefix_path, dataset='segarray', mode='truncate', file_type='distribute')

      Save the SegArray to HDF5. The result is a collection of HDF5 files, one file
      per locale of the arkouda server, where each filename starts with prefix_path.

      :param prefix_path: Directory and filename prefix that all output files will share
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 file
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', add data as a new column to existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: None

      .. seealso:: :obj:`load`



   .. py:method:: to_list()

      Convert the segarray into a list containing sub-arrays

      :returns: A list with the same sub-arrays (also list) as this segarray
      :rtype: list

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> segarr = ak.SegArray(ak.array([0, 4, 7]), ak.arange(12))
      >>> segarr.to_list()
      [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9, 10, 11]]
      >>> type(segarr.to_list())
      list



   .. py:method:: to_ndarray()

      Convert the array into a numpy.ndarray containing sub-arrays

      :returns: A numpy ndarray with the same sub-arrays (also numpy.ndarray) as this array
      :rtype: np.ndarray

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> segarr = ak.SegArray(ak.array([0, 4, 7]), ak.arange(12))
      >>> segarr.to_ndarray()
      array([array([1, 2, 3, 4]), array([5, 6, 7]), array([8, 9, 10, 11, 12])])
      >>> type(segarr.to_ndarray())
      numpy.ndarray



   .. py:method:: to_parquet(prefix_path, dataset='segarray', mode: str = 'truncate', compression: Optional[str] = None)

      Save the SegArray object to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the object to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: Deprecated.
                   Parameter kept to maintain functionality of other calls. Only Truncate
                   supported.
                   By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: If write mode is not Truncate.

      .. rubric:: Notes

      - Append mode for Parquet has been deprecated. It was not implemented for SegArray.
      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.



   .. py:method:: transfer(hostname: str, port: arkouda.numpy.dtypes.int_scalars)

      Sends a Segmented Array to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Segmented Array is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: union(other)

      Computes the union of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d union of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.union1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.union(seg_b)
      SegArray([
      [1, 2, 3, 4, 5],
      [1, 2, 3, 4, 5]
      ])



   .. py:method:: unique(x=None)

      Return sub-arrays of unique values.

      :param x: The values to unique, per group. By default, the values of this
                SegArray's sub-arrays.
      :type x: pdarray

      :returns: Same number of sub-arrays as original SegArray, but elements in sub-array
                are unique and in sorted order.
      :rtype: SegArray



   .. py:method:: unregister()

      Unregister this SegArray object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :rtype: None

      :raises RuntimeError: Raised if the server could not unregister the SegArray object from the Symbol Table

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: unregister_segarray_by_name(user_defined_name)
      :staticmethod:


      Using the defined name, remove the registered SegArray object from the Symbol Table

      :param user_defined_name: user defined name which the SegArray object was registered under
      :type user_defined_name: str

      :rtype: None

      :raises RuntimeError: Raised if the server could not unregister the SegArray object from the Symbol Table

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'segarray', repack: bool = True)

      Overwrite the dataset with the name provided with this SegArray object. If
      the dataset does not exist it is added.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: None

      :raises RuntimeError: Raised if a server-side error is thrown saving the SegArray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added
      - Because HDF5 deletes do not release memory, this will create a copy of the
        file with the new data



   .. py:attribute:: valsize


   .. py:attribute:: values


.. py:data:: SeriesDTypes

.. py:data:: SortingAlgorithm

.. py:class:: Strings

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.


   .. py:method:: BinOps(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: astype(dtype: Union[np.dtype, str]) -> pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> Strings

      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: cached_regex_patterns() -> List

      Returns the regex patterns for which Match objects have been cached




   .. py:method:: capitalize() -> Strings

      Returns a new Strings from the original replaced with the first letter capitilzed
      and the remaining letters lowercase.

      :returns: Strings from the original replaced with the capitalized equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`, :obj:`String.title`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS aRe Here {i}' for i in range(5)])
      >>> strings
      array(['StrINgS aRe Here 0', 'StrINgS aRe Here 1', 'StrINgS aRe Here 2', 'StrINgS aRe Here 3', 'StrINgS aRe Here 4'])
      >>> strings.title()
      array(['Strings Are Here 0', 'Strings Are Here 1', 'Strings Are Here 2', 'Strings Are Here 3', 'Strings Are Here 4'])



   .. py:method:: contains(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True True True True True])
      >>> strings.contains('string \d', regex=True)
      array([True True True True True])



   .. py:method:: decode(fromEncoding: str, toEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `fromEncoding`, expecting that the
      current Strings is encoded in `toEncoding`

      :param fromEncoding: The current encoding of the strings object
      :type fromEncoding: str
      :param toEncoding: The encoding that the strings will be converted to,
                         default to UTF-8
      :type toEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: encode(toEncoding: str, fromEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `toEncoding`, expecting that the
      current Strings is encoded in `fromEncoding`

      :param toEncoding: The encoding that the strings will be converted to
      :type toEncoding: str
      :param fromEncoding: The current encoding of the strings object, default to
                           UTF-8
      :type fromEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: endswith(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True True True True True])
      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True True True True True])



   .. py:method:: equals(other: Any) -> bool_scalars

      Whether Strings are the same size and all entries are equal.

      :param other: object to compare.
      :type other: Any

      :returns: True if the Strings are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> s = ak.array(["a", "b", "c"])
      >>> s_cpy = ak.array(["a", "b", "c"])
      >>> s.equals(s_cpy)
      True
      >>> s2 = ak.array(["a", "x", "c"])
      >>> s.equals(s2)
      False



   .. py:method:: find_locations(pattern: Union[bytes, str_scalars]) -> Tuple[pdarray, pdarray, pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions,
      and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: bytes or str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2 2 2 2 2])
      >>> starts
      array([0 9 0 9 0 9 0 9 0 9])
      >>> lens
      array([1 1 1 1 1 1 1 1 1 1])



   .. py:method:: findall(pattern: Union[bytes, str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each
                                   pattern match is from
      :type return_match_origins: bool, default=False

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))



   .. py:method:: flatten() -> Strings

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. note::

         As multidimensional Strings are currently supported,
         flatten on a Strings object will always return itself.



   .. py:method:: from_parts(offset_attrib: Union[pdarray, str], bytes_attrib: Union[pdarray, str]) -> Strings

      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: pdarray or str
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: pdarray or str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.



   .. py:method:: from_return_msg(rep_msg: str) -> Strings

      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.



   .. py:method:: fullmatch(pattern: Union[bytes, str_scalars]) -> Match

      Returns a match object where elements match only if the whole string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the whole string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=False; matched=False>



   .. py:method:: get_bytes() -> pdarray

      Getter for the bytes component (uint8 pdarray) of this Strings.

      :returns: Pdarray of bytes of the string accessed
      :rtype: pdarray, uint8

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_bytes()
      [111 110 101 0 116 119 111 0 116 104 114 101 101 0]



   .. py:method:: get_lengths() -> pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: get_offsets() -> pdarray

      Getter for the offsets component (int64 pdarray) of this Strings.

      :returns: Pdarray of offsets of the string accessed
      :rtype: pdarray, int64

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_offsets()
      [0 4 8]



   .. py:method:: get_prefixes(n: int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, pdarray]]

      Return the n-long prefix of each string, where possible

      :param n: Length of prefix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-prefix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper prefixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a prefix.
      :type proper: bool, default=True

      :returns: * **prefixes** (*Strings*) -- The array of n-character prefixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character prefix, False otherwise.



   .. py:method:: get_suffixes(n: int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, pdarray]]

      Return the n-long suffix of each string, where possible

      :param n: Length of suffix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-suffix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper suffixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a suffix.
      :type proper: bool, default=True

      :returns: * **suffixes** (*Strings*) -- The array of n-character suffixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character suffix, False otherwise.



   .. py:method:: group() -> pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedString.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message



   .. py:method:: hash() -> Tuple[pdarray, pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:property:: inferred_type
      :type: Tuple[pdarray, pdarray]


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> np.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: isalnum() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphanumeric.

      :returns: True for elements that are alphanumeric, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_alnum = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alnum = ak.array([f'Strings{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_alnum, alnum])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'Strings0', 'Strings1', 'Strings2'])
      >>> strings.isalnum()
      array([False False False True True True])



   .. py:method:: isalpha() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphabetic.  This means there is at least one character,
      and all the characters are alphabetic.

      :returns: True for elements that are alphabetic, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`, :obj:`Strings.isalnum`

      .. rubric:: Examples

      >>> not_alpha = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alpha = ak.array(['StringA','StringB','StringC'])
      >>> strings = ak.concatenate([not_alpha, alpha])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'StringA', 'StringB', 'StringC'])
      >>> strings.isalpha()
      array([False False False True True True])



   .. py:method:: isdecimal() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all decimal characters.

      :returns: True for elements that are decimals, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isdigit`

      .. rubric:: Examples

      >>> not_decimal = ak.array([f'Strings {i}' for i in range(3)])
      >>> decimal = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_decimal, decimal])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdecimal()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdecimal()
      array([False True False False False])



   .. py:method:: isdigit() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all digit characters.

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_digit = ak.array([f'Strings {i}' for i in range(3)])
      >>> digit = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_digit, digit])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdigit()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdigit()
      array([False True True True False])



   .. py:method:: isempty() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is empty.


      True for elements that are the empty string, False otherwise

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_empty = ak.array([f'Strings {i}' for i in range(3)])
      >>> empty = ak.array(['' for i in range(3)])
      >>> strings = ak.concatenate([not_empty, empty])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '', '', ''])
      >>> strings.isempty()
      array([False False False True True True])



   .. py:method:: islower() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.islower()
      array([True True True False False False])



   .. py:method:: isspace() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i has all
      whitespace characters (‘ ’, ‘\\t’, ‘\\n’, ‘\\v’, ‘\\f’, ‘\\r’).

      :returns: True for elements that are whitespace, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_space = ak.array([f'Strings {i}' for i in range(3)])
      >>> space = ak.array([' ', '\t', '\n', '\v', '\f', '\r', ' \t\n\v\f\r'])
      >>> strings = ak.concatenate([not_space, space])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', ' ', 'u0009', 'n', 'u000B', 'u000C', 'u000D', ' u0009nu000Bu000Cu000D'])
      >>> strings.isspace()
      array([False False False True True True True True True True])



   .. py:method:: istitle() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is titlecase

      :returns: True for elements that are titlecase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> mixed = ak.array([f'sTrINgs {i}' for i in range(3)])
      >>> title = ak.array([f'Strings {i}' for i in range(3)])
      >>> strings = ak.concatenate([mixed, title])
      >>> strings
      array(['sTrINgs 0', 'sTrINgs 1', 'sTrINgs 2', 'Strings 0', 'Strings 1', 'Strings 2'])
      >>> strings.istitle()
      array([False False False True True True])



   .. py:method:: isupper() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.isupper()
      array([False False False True True True])



   .. py:method:: lower() -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with
      their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with
                their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])



   .. py:method:: lstick(other: Strings, delimiter: Union[bytes, str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])



   .. py:method:: match(pattern: Union[bytes, str_scalars]) -> Match

      Returns a match object where elements match only if the beginning of the string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the beginning of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=True, span=(0, 2); matched=False>



   .. py:method:: objType(*args, **kwargs)

      str(object='') -> str
      str(bytes_or_buffer[, encoding[, errors]]) -> str

      Create a new string object from the given object. If encoding or
      errors is specified, then the object must expose a data buffer
      that will be decoded using the given encoding and error handler.
      Otherwise, returns the result of object.__str__() (if defined)
      or repr(object).
      encoding defaults to sys.getdefaultencoding().
      errors defaults to 'strict'.




   .. py:method:: peel(delimiter: Union[bytes, str_scalars], times: int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool, default=False
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: purge_cached_regex_patterns() -> None

      purges cached regex patterns




   .. py:method:: regex_split(pattern: Union[bytes, str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern.
      If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: bytes or str_scalars
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int, default=0
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool, default=False

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.regex_split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))



   .. py:method:: register(user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and
                has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: rpeel(delimiter: Union[bytes, str_scalars], times: int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))

      Compared against peel

      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))



   .. py:method:: save(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None, file_format: Literal['HDF5', 'Parquet'] = 'HDF5', file_type: Literal['single', 'distribute'] = 'distribute') -> str

      DEPRECATED
      Save the Strings object to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool, default=True
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: {"HDF5", "Parquet"}, default = "HDF5"
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter. (3) Parquet files do not store the segments,
      only the values.



   .. py:method:: search(pattern: Union[bytes, str_scalars]) -> Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match if any part of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4);
      matched=False; matched=True, span=(0, 2); matched=False>



   .. py:method:: split(delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

              Parameters
              ----------
              delimiter: str
                  Characters used to split strings into substrings
              return_segments : bool, default=False
                  If True, also return mapping of original strings to first substring
                  in return array.
              regex : bool, default=False
                  Indicates whether delimiter is a regular expression
                  Note: only handles regular expressions supported by re2
                  (does not support lookaheads/lookbehinds)

              Returns
              -------
              Strings
                  Flattened substrings with delimiters removed
              pdarray, int64 (optional)
                  For each original string, the index of first corresponding substring
                  in the return array

              See Also
              --------
              peel, rpeel

              Examples
              --------
              >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
              >>> orig.split('|')
              array(['one', 'two', 'three', 'four', 'five', 'six'])
              >>> flat, mapping = orig.split('|', return_segments=True)
              >>> mapping
              array([0 2 5])
              >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
              >>> under_split, under_map = under.split('_+', return_segments=True, regex=True)
              >>> under_split
              array(['one', 'two', 'three', 'four', 'five', 'six'])
              >>> under_map
              array([0 2 5])





   .. py:method:: startswith(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True True True True True])
      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True True True True True])



   .. py:method:: stick(other: Strings, delimiter: Union[bytes, str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool, default=False

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])



   .. py:method:: strip(chars: Optional[Union[bytes, str_scalars]] = '') -> Strings

      Returns a new Strings object with all leading and trailing occurrences of characters contained
      in chars removed. The chars argument is a string specifying the set of characters to be removed.
      If omitted, the chars argument defaults to removing whitespace. The chars argument is not a
      prefix or suffix; rather, all combinations of its values are stripped.

      :param chars: the set of characters to be removed
      :type chars: bytes or str_scalars, optional

      :returns: Strings object with the leading and trailing characters matching the set of characters in
                the chars argument removed
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> strings = ak.array(['Strings ', '  StringS  ', 'StringS   '])
      >>> s = strings.strip()
      >>> s
      array(['Strings', 'StringS', 'StringS'])

      >>> strings = ak.array(['Strings 1', '1 StringS  ', '  1StringS  12 '])
      >>> s = strings.strip(' 12')
      >>> s
      array(['Strings', 'StringS', 'StringS'])



   .. py:method:: sub(pattern: Union[bytes, str_scalars], repl: Union[bytes, str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the
      replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])



   .. py:method:: subn(pattern: Union[bytes, str_scalars], repl: Union[bytes, str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))



   .. py:method:: title() -> Strings

      Returns a new Strings from the original replaced with their titlecase equivalent.

      :returns: Strings from the original replaced with their titlecase equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.title()
      array(['Strings 0', 'Strings 1', 'Strings 2', 'Strings 3', 'Strings 4'])



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'strings_array', col_delim: str = ',', overwrite: bool = False) -> str

      Write Strings to CSV file(s). File will contain a single column with the Strings data.
      All CSV Files written by Arkouda include a header denoting data types of the columns.
      Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing
      bytes as uint(8).

      :param prefix_path: The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                          when they are written to disk.
      :type prefix_path: str
      :param dataset: Column name to save the Strings under. Defaults to "strings_array".
      :type dataset: str, default="strings_array"
      :param col_delim: Defaults to ",". Value to be used to separate columns within the file.
                        Please be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, default=","
      :param overwrite: Defaults to False. If True, any existing files matching your provided prefix_path will
                        be overwritten. If False, an error will be returned if existing files are found.
      :type overwrite: bool, default=False

      :returns: response message
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one or
          more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          If `allow_errors` is true this may be raised if no values are returned
          from the server.
      :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline (``\n``) at this time.



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, file_type: Literal['single', 'distribute'] = 'distribute') -> str

      Save the Strings object to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - Parquet files do not store the segments, only the values.
      - Strings state is saved as two datasets within an hdf5 group:
        one for the string characters and one for the
        segments corresponding to the start of each string
      - the hdf5 group is named via the dataset parameter.
      - The prefix_path must be visible to the arkouda server and the user must
        have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
        ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
        the file name will be `prefix_path`.
      - If any of the output files already exist and
        the mode is 'truncate', they will be overwritten. If the mode is 'append'
        and the number of output files is less than the number of locales or a
        dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
        determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_list() -> list

      Convert the SegString to a list, transferring data from the
      arkouda server to Python. If the SegString exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A list with the same strings as this SegString
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_list()
      ['hello', 'my', 'world']
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> np.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None) -> str

      Save the Strings object to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.



   .. py:method:: transfer(hostname: str, port: int_scalars) -> Union[str, memoryview]

      Sends a Strings object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Strings object is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None

      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'strings_array', save_offsets: bool = True, repack: bool = True) -> str

      Overwrite the dataset with the name provided with this Strings object. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str, default="strings_array"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool, default=True

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the Strings object

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: upper() -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with
      their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with
                their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])



.. py:class:: Strings

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.


   .. py:method:: BinOps(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: astype(dtype: Union[np.dtype, str]) -> pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> Strings

      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: cached_regex_patterns() -> List

      Returns the regex patterns for which Match objects have been cached




   .. py:method:: capitalize() -> Strings

      Returns a new Strings from the original replaced with the first letter capitilzed
      and the remaining letters lowercase.

      :returns: Strings from the original replaced with the capitalized equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`, :obj:`String.title`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS aRe Here {i}' for i in range(5)])
      >>> strings
      array(['StrINgS aRe Here 0', 'StrINgS aRe Here 1', 'StrINgS aRe Here 2', 'StrINgS aRe Here 3', 'StrINgS aRe Here 4'])
      >>> strings.title()
      array(['Strings Are Here 0', 'Strings Are Here 1', 'Strings Are Here 2', 'Strings Are Here 3', 'Strings Are Here 4'])



   .. py:method:: contains(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True True True True True])
      >>> strings.contains('string \d', regex=True)
      array([True True True True True])



   .. py:method:: decode(fromEncoding: str, toEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `fromEncoding`, expecting that the
      current Strings is encoded in `toEncoding`

      :param fromEncoding: The current encoding of the strings object
      :type fromEncoding: str
      :param toEncoding: The encoding that the strings will be converted to,
                         default to UTF-8
      :type toEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: encode(toEncoding: str, fromEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `toEncoding`, expecting that the
      current Strings is encoded in `fromEncoding`

      :param toEncoding: The encoding that the strings will be converted to
      :type toEncoding: str
      :param fromEncoding: The current encoding of the strings object, default to
                           UTF-8
      :type fromEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: endswith(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True True True True True])
      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True True True True True])



   .. py:method:: equals(other: Any) -> bool_scalars

      Whether Strings are the same size and all entries are equal.

      :param other: object to compare.
      :type other: Any

      :returns: True if the Strings are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> s = ak.array(["a", "b", "c"])
      >>> s_cpy = ak.array(["a", "b", "c"])
      >>> s.equals(s_cpy)
      True
      >>> s2 = ak.array(["a", "x", "c"])
      >>> s.equals(s2)
      False



   .. py:method:: find_locations(pattern: Union[bytes, str_scalars]) -> Tuple[pdarray, pdarray, pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions,
      and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: bytes or str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2 2 2 2 2])
      >>> starts
      array([0 9 0 9 0 9 0 9 0 9])
      >>> lens
      array([1 1 1 1 1 1 1 1 1 1])



   .. py:method:: findall(pattern: Union[bytes, str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each
                                   pattern match is from
      :type return_match_origins: bool, default=False

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))



   .. py:method:: flatten() -> Strings

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. note::

         As multidimensional Strings are currently supported,
         flatten on a Strings object will always return itself.



   .. py:method:: from_parts(offset_attrib: Union[pdarray, str], bytes_attrib: Union[pdarray, str]) -> Strings

      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: pdarray or str
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: pdarray or str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.



   .. py:method:: from_return_msg(rep_msg: str) -> Strings

      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.



   .. py:method:: fullmatch(pattern: Union[bytes, str_scalars]) -> Match

      Returns a match object where elements match only if the whole string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the whole string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=False; matched=False>



   .. py:method:: get_bytes() -> pdarray

      Getter for the bytes component (uint8 pdarray) of this Strings.

      :returns: Pdarray of bytes of the string accessed
      :rtype: pdarray, uint8

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_bytes()
      [111 110 101 0 116 119 111 0 116 104 114 101 101 0]



   .. py:method:: get_lengths() -> pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: get_offsets() -> pdarray

      Getter for the offsets component (int64 pdarray) of this Strings.

      :returns: Pdarray of offsets of the string accessed
      :rtype: pdarray, int64

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_offsets()
      [0 4 8]



   .. py:method:: get_prefixes(n: int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, pdarray]]

      Return the n-long prefix of each string, where possible

      :param n: Length of prefix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-prefix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper prefixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a prefix.
      :type proper: bool, default=True

      :returns: * **prefixes** (*Strings*) -- The array of n-character prefixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character prefix, False otherwise.



   .. py:method:: get_suffixes(n: int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, pdarray]]

      Return the n-long suffix of each string, where possible

      :param n: Length of suffix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-suffix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper suffixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a suffix.
      :type proper: bool, default=True

      :returns: * **suffixes** (*Strings*) -- The array of n-character suffixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character suffix, False otherwise.



   .. py:method:: group() -> pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedString.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message



   .. py:method:: hash() -> Tuple[pdarray, pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:property:: inferred_type
      :type: Tuple[pdarray, pdarray]


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> np.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: isalnum() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphanumeric.

      :returns: True for elements that are alphanumeric, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_alnum = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alnum = ak.array([f'Strings{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_alnum, alnum])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'Strings0', 'Strings1', 'Strings2'])
      >>> strings.isalnum()
      array([False False False True True True])



   .. py:method:: isalpha() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphabetic.  This means there is at least one character,
      and all the characters are alphabetic.

      :returns: True for elements that are alphabetic, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`, :obj:`Strings.isalnum`

      .. rubric:: Examples

      >>> not_alpha = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alpha = ak.array(['StringA','StringB','StringC'])
      >>> strings = ak.concatenate([not_alpha, alpha])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'StringA', 'StringB', 'StringC'])
      >>> strings.isalpha()
      array([False False False True True True])



   .. py:method:: isdecimal() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all decimal characters.

      :returns: True for elements that are decimals, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isdigit`

      .. rubric:: Examples

      >>> not_decimal = ak.array([f'Strings {i}' for i in range(3)])
      >>> decimal = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_decimal, decimal])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdecimal()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdecimal()
      array([False True False False False])



   .. py:method:: isdigit() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all digit characters.

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_digit = ak.array([f'Strings {i}' for i in range(3)])
      >>> digit = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_digit, digit])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdigit()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdigit()
      array([False True True True False])



   .. py:method:: isempty() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is empty.


      True for elements that are the empty string, False otherwise

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_empty = ak.array([f'Strings {i}' for i in range(3)])
      >>> empty = ak.array(['' for i in range(3)])
      >>> strings = ak.concatenate([not_empty, empty])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '', '', ''])
      >>> strings.isempty()
      array([False False False True True True])



   .. py:method:: islower() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.islower()
      array([True True True False False False])



   .. py:method:: isspace() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i has all
      whitespace characters (‘ ’, ‘\\t’, ‘\\n’, ‘\\v’, ‘\\f’, ‘\\r’).

      :returns: True for elements that are whitespace, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_space = ak.array([f'Strings {i}' for i in range(3)])
      >>> space = ak.array([' ', '\t', '\n', '\v', '\f', '\r', ' \t\n\v\f\r'])
      >>> strings = ak.concatenate([not_space, space])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', ' ', 'u0009', 'n', 'u000B', 'u000C', 'u000D', ' u0009nu000Bu000Cu000D'])
      >>> strings.isspace()
      array([False False False True True True True True True True])



   .. py:method:: istitle() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is titlecase

      :returns: True for elements that are titlecase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> mixed = ak.array([f'sTrINgs {i}' for i in range(3)])
      >>> title = ak.array([f'Strings {i}' for i in range(3)])
      >>> strings = ak.concatenate([mixed, title])
      >>> strings
      array(['sTrINgs 0', 'sTrINgs 1', 'sTrINgs 2', 'Strings 0', 'Strings 1', 'Strings 2'])
      >>> strings.istitle()
      array([False False False True True True])



   .. py:method:: isupper() -> pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.isupper()
      array([False False False True True True])



   .. py:method:: lower() -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with
      their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with
                their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])



   .. py:method:: lstick(other: Strings, delimiter: Union[bytes, str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])



   .. py:method:: match(pattern: Union[bytes, str_scalars]) -> Match

      Returns a match object where elements match only if the beginning of the string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the beginning of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=True, span=(0, 2); matched=False>



   .. py:method:: objType(*args, **kwargs)

      str(object='') -> str
      str(bytes_or_buffer[, encoding[, errors]]) -> str

      Create a new string object from the given object. If encoding or
      errors is specified, then the object must expose a data buffer
      that will be decoded using the given encoding and error handler.
      Otherwise, returns the result of object.__str__() (if defined)
      or repr(object).
      encoding defaults to sys.getdefaultencoding().
      errors defaults to 'strict'.




   .. py:method:: peel(delimiter: Union[bytes, str_scalars], times: int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool, default=False
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: purge_cached_regex_patterns() -> None

      purges cached regex patterns




   .. py:method:: regex_split(pattern: Union[bytes, str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern.
      If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: bytes or str_scalars
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int, default=0
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool, default=False

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.regex_split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))



   .. py:method:: register(user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and
                has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: rpeel(delimiter: Union[bytes, str_scalars], times: int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))

      Compared against peel

      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))



   .. py:method:: save(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None, file_format: Literal['HDF5', 'Parquet'] = 'HDF5', file_type: Literal['single', 'distribute'] = 'distribute') -> str

      DEPRECATED
      Save the Strings object to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool, default=True
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: {"HDF5", "Parquet"}, default = "HDF5"
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter. (3) Parquet files do not store the segments,
      only the values.



   .. py:method:: search(pattern: Union[bytes, str_scalars]) -> Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match if any part of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4);
      matched=False; matched=True, span=(0, 2); matched=False>



   .. py:method:: split(delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

              Parameters
              ----------
              delimiter: str
                  Characters used to split strings into substrings
              return_segments : bool, default=False
                  If True, also return mapping of original strings to first substring
                  in return array.
              regex : bool, default=False
                  Indicates whether delimiter is a regular expression
                  Note: only handles regular expressions supported by re2
                  (does not support lookaheads/lookbehinds)

              Returns
              -------
              Strings
                  Flattened substrings with delimiters removed
              pdarray, int64 (optional)
                  For each original string, the index of first corresponding substring
                  in the return array

              See Also
              --------
              peel, rpeel

              Examples
              --------
              >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
              >>> orig.split('|')
              array(['one', 'two', 'three', 'four', 'five', 'six'])
              >>> flat, mapping = orig.split('|', return_segments=True)
              >>> mapping
              array([0 2 5])
              >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
              >>> under_split, under_map = under.split('_+', return_segments=True, regex=True)
              >>> under_split
              array(['one', 'two', 'three', 'four', 'five', 'six'])
              >>> under_map
              array([0 2 5])





   .. py:method:: startswith(substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True True True True True])
      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True True True True True])



   .. py:method:: stick(other: Strings, delimiter: Union[bytes, str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool, default=False

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])



   .. py:method:: strip(chars: Optional[Union[bytes, str_scalars]] = '') -> Strings

      Returns a new Strings object with all leading and trailing occurrences of characters contained
      in chars removed. The chars argument is a string specifying the set of characters to be removed.
      If omitted, the chars argument defaults to removing whitespace. The chars argument is not a
      prefix or suffix; rather, all combinations of its values are stripped.

      :param chars: the set of characters to be removed
      :type chars: bytes or str_scalars, optional

      :returns: Strings object with the leading and trailing characters matching the set of characters in
                the chars argument removed
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> strings = ak.array(['Strings ', '  StringS  ', 'StringS   '])
      >>> s = strings.strip()
      >>> s
      array(['Strings', 'StringS', 'StringS'])

      >>> strings = ak.array(['Strings 1', '1 StringS  ', '  1StringS  12 '])
      >>> s = strings.strip(' 12')
      >>> s
      array(['Strings', 'StringS', 'StringS'])



   .. py:method:: sub(pattern: Union[bytes, str_scalars], repl: Union[bytes, str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the
      replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])



   .. py:method:: subn(pattern: Union[bytes, str_scalars], repl: Union[bytes, str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))



   .. py:method:: title() -> Strings

      Returns a new Strings from the original replaced with their titlecase equivalent.

      :returns: Strings from the original replaced with their titlecase equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.title()
      array(['Strings 0', 'Strings 1', 'Strings 2', 'Strings 3', 'Strings 4'])



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'strings_array', col_delim: str = ',', overwrite: bool = False) -> str

      Write Strings to CSV file(s). File will contain a single column with the Strings data.
      All CSV Files written by Arkouda include a header denoting data types of the columns.
      Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing
      bytes as uint(8).

      :param prefix_path: The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                          when they are written to disk.
      :type prefix_path: str
      :param dataset: Column name to save the Strings under. Defaults to "strings_array".
      :type dataset: str, default="strings_array"
      :param col_delim: Defaults to ",". Value to be used to separate columns within the file.
                        Please be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, default=","
      :param overwrite: Defaults to False. If True, any existing files matching your provided prefix_path will
                        be overwritten. If False, an error will be returned if existing files are found.
      :type overwrite: bool, default=False

      :returns: response message
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one or
          more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          If `allow_errors` is true this may be raised if no values are returned
          from the server.
      :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline (``\n``) at this time.



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, file_type: Literal['single', 'distribute'] = 'distribute') -> str

      Save the Strings object to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - Parquet files do not store the segments, only the values.
      - Strings state is saved as two datasets within an hdf5 group:
        one for the string characters and one for the
        segments corresponding to the start of each string
      - the hdf5 group is named via the dataset parameter.
      - The prefix_path must be visible to the arkouda server and the user must
        have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
        ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
        the file name will be `prefix_path`.
      - If any of the output files already exist and
        the mode is 'truncate', they will be overwritten. If the mode is 'append'
        and the number of output files is less than the number of locales or a
        dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
        determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_list() -> list

      Convert the SegString to a list, transferring data from the
      arkouda server to Python. If the SegString exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A list with the same strings as this SegString
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_list()
      ['hello', 'my', 'world']
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> np.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None) -> str

      Save the Strings object to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.



   .. py:method:: transfer(hostname: str, port: int_scalars) -> Union[str, memoryview]

      Sends a Strings object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Strings object is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None

      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'strings_array', save_offsets: bool = True, repack: bool = True) -> str

      Overwrite the dataset with the name provided with this Strings object. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str, default="strings_array"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool, default=True

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the Strings object

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: upper() -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with
      their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with
                their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])



.. py:class:: Strings(strings_pdarray: arkouda.numpy.pdarrayclass.pdarray, bytes_size: arkouda.numpy.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.


   .. py:attribute:: BinOps


   .. py:method:: astype(dtype: Union[numpy.dtype, str]) -> arkouda.numpy.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:


      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: cached_regex_patterns() -> List

      Returns the regex patterns for which Match objects have been cached



   .. py:method:: capitalize() -> Strings

      Returns a new Strings from the original replaced with the first letter capitilzed
      and the remaining letters lowercase.

      :returns: Strings from the original replaced with the capitalized equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`, :obj:`String.title`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS aRe Here {i}' for i in range(5)])
      >>> strings
      array(['StrINgS aRe Here 0', 'StrINgS aRe Here 1', 'StrINgS aRe Here 2', 'StrINgS aRe Here 3', 'StrINgS aRe Here 4'])
      >>> strings.title()
      array(['Strings Are Here 0', 'Strings Are Here 1', 'Strings Are Here 2', 'Strings Are Here 3', 'Strings Are Here 4'])



   .. py:method:: contains(substr: Union[bytes, arkouda.numpy.dtypes.str_scalars], regex: bool = False) -> arkouda.numpy.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True True True True True])
      >>> strings.contains('string \d', regex=True)
      array([True True True True True])



   .. py:method:: decode(fromEncoding: str, toEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `fromEncoding`, expecting that the
      current Strings is encoded in `toEncoding`

      :param fromEncoding: The current encoding of the strings object
      :type fromEncoding: str
      :param toEncoding: The encoding that the strings will be converted to,
                         default to UTF-8
      :type toEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:attribute:: dtype


   .. py:method:: encode(toEncoding: str, fromEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `toEncoding`, expecting that the
      current Strings is encoded in `fromEncoding`

      :param toEncoding: The encoding that the strings will be converted to
      :type toEncoding: str
      :param fromEncoding: The current encoding of the strings object, default to
                           UTF-8
      :type fromEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: endswith(substr: Union[bytes, arkouda.numpy.dtypes.str_scalars], regex: bool = False) -> arkouda.numpy.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True True True True True])
      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True True True True True])



   .. py:attribute:: entry
      :type:  arkouda.numpy.pdarrayclass.pdarray


   .. py:method:: equals(other: Any) -> arkouda.numpy.dtypes.bool_scalars

      Whether Strings are the same size and all entries are equal.

      :param other: object to compare.
      :type other: Any

      :returns: True if the Strings are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> s = ak.array(["a", "b", "c"])
      >>> s_cpy = ak.array(["a", "b", "c"])
      >>> s.equals(s_cpy)
      True
      >>> s2 = ak.array(["a", "x", "c"])
      >>> s.equals(s2)
      False



   .. py:method:: find_locations(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> Tuple[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions,
      and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: bytes or str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2 2 2 2 2])
      >>> starts
      array([0 9 0 9 0 9 0 9 0 9])
      >>> lens
      array([1 1 1 1 1 1 1 1 1 1])



   .. py:method:: findall(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each
                                   pattern match is from
      :type return_match_origins: bool, default=False

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))



   .. py:method:: flatten() -> Strings

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. note::

         As multidimensional Strings are currently supported,
         flatten on a Strings object will always return itself.



   .. py:method:: from_parts(offset_attrib: Union[arkouda.numpy.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.numpy.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: pdarray or str
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: pdarray or str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.



   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.



   .. py:method:: fullmatch(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the whole string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=False; matched=False>



   .. py:method:: get_bytes() -> arkouda.numpy.pdarrayclass.pdarray

      Getter for the bytes component (uint8 pdarray) of this Strings.

      :returns: Pdarray of bytes of the string accessed
      :rtype: pdarray, uint8

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_bytes()
      [111 110 101 0 116 119 111 0 116 104 114 101 101 0]



   .. py:method:: get_lengths() -> arkouda.numpy.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: get_offsets() -> arkouda.numpy.pdarrayclass.pdarray

      Getter for the offsets component (int64 pdarray) of this Strings.

      :returns: Pdarray of offsets of the string accessed
      :rtype: pdarray, int64

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_offsets()
      [0 4 8]



   .. py:method:: get_prefixes(n: arkouda.numpy.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.numpy.pdarrayclass.pdarray]]

      Return the n-long prefix of each string, where possible

      :param n: Length of prefix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-prefix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper prefixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a prefix.
      :type proper: bool, default=True

      :returns: * **prefixes** (*Strings*) -- The array of n-character prefixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character prefix, False otherwise.



   .. py:method:: get_suffixes(n: arkouda.numpy.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.numpy.pdarrayclass.pdarray]]

      Return the n-long suffix of each string, where possible

      :param n: Length of suffix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-suffix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper suffixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a suffix.
      :type proper: bool, default=True

      :returns: * **suffixes** (*Strings*) -- The array of n-character suffixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character suffix, False otherwise.



   .. py:method:: group() -> arkouda.numpy.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedString.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message



   .. py:method:: hash() -> Tuple[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:property:: inferred_type
      :type: str


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: isalnum() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphanumeric.

      :returns: True for elements that are alphanumeric, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_alnum = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alnum = ak.array([f'Strings{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_alnum, alnum])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'Strings0', 'Strings1', 'Strings2'])
      >>> strings.isalnum()
      array([False False False True True True])



   .. py:method:: isalpha() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphabetic.  This means there is at least one character,
      and all the characters are alphabetic.

      :returns: True for elements that are alphabetic, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`, :obj:`Strings.isalnum`

      .. rubric:: Examples

      >>> not_alpha = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alpha = ak.array(['StringA','StringB','StringC'])
      >>> strings = ak.concatenate([not_alpha, alpha])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'StringA', 'StringB', 'StringC'])
      >>> strings.isalpha()
      array([False False False True True True])



   .. py:method:: isdecimal() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all decimal characters.

      :returns: True for elements that are decimals, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isdigit`

      .. rubric:: Examples

      >>> not_decimal = ak.array([f'Strings {i}' for i in range(3)])
      >>> decimal = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_decimal, decimal])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdecimal()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdecimal()
      array([False True False False False])



   .. py:method:: isdigit() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all digit characters.

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_digit = ak.array([f'Strings {i}' for i in range(3)])
      >>> digit = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_digit, digit])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdigit()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdigit()
      array([False True True True False])



   .. py:method:: isempty() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is empty.


      True for elements that are the empty string, False otherwise

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_empty = ak.array([f'Strings {i}' for i in range(3)])
      >>> empty = ak.array(['' for i in range(3)])
      >>> strings = ak.concatenate([not_empty, empty])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '', '', ''])
      >>> strings.isempty()
      array([False False False True True True])



   .. py:method:: islower() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.islower()
      array([True True True False False False])



   .. py:method:: isspace() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i has all
      whitespace characters (‘ ’, ‘\\t’, ‘\\n’, ‘\\v’, ‘\\f’, ‘\\r’).

      :returns: True for elements that are whitespace, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_space = ak.array([f'Strings {i}' for i in range(3)])
      >>> space = ak.array([' ', '\t', '\n', '\v', '\f', '\r', ' \t\n\v\f\r'])
      >>> strings = ak.concatenate([not_space, space])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', ' ', 'u0009', 'n', 'u000B', 'u000C', 'u000D', ' u0009nu000Bu000Cu000D'])
      >>> strings.isspace()
      array([False False False True True True True True True True])



   .. py:method:: istitle() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is titlecase

      :returns: True for elements that are titlecase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> mixed = ak.array([f'sTrINgs {i}' for i in range(3)])
      >>> title = ak.array([f'Strings {i}' for i in range(3)])
      >>> strings = ak.concatenate([mixed, title])
      >>> strings
      array(['sTrINgs 0', 'sTrINgs 1', 'sTrINgs 2', 'Strings 0', 'Strings 1', 'Strings 2'])
      >>> strings.istitle()
      array([False False False True True True])



   .. py:method:: isupper() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.isupper()
      array([False False False True True True])



   .. py:attribute:: logger


   .. py:method:: lower() -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with
      their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with
                their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])



   .. py:method:: lstick(other: Strings, delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])



   .. py:method:: match(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the beginning of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=True, span=(0, 2); matched=False>



   .. py:attribute:: objType
      :value: 'Strings'



   .. py:method:: peel(delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars], times: arkouda.numpy.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool, default=False
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: purge_cached_regex_patterns() -> None

      purges cached regex patterns



   .. py:method:: regex_split(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern.
      If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: bytes or str_scalars
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int, default=0
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool, default=False

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.regex_split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))



   .. py:method:: register(user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and
                has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:attribute:: registered_name
      :type:  Optional[str]
      :value: None



   .. py:method:: rpeel(delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars], times: arkouda.numpy.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))

      Compared against peel

      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))



   .. py:method:: save(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None, file_format: Literal['HDF5', 'Parquet'] = 'HDF5', file_type: Literal['single', 'distribute'] = 'distribute') -> str

      DEPRECATED
      Save the Strings object to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool, default=True
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: {"HDF5", "Parquet"}, default = "HDF5"
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter. (3) Parquet files do not store the segments,
      only the values.



   .. py:method:: search(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match if any part of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4);
      matched=False; matched=True, span=(0, 2); matched=False>



   .. py:attribute:: size
      :type:  arkouda.numpy.dtypes.int_scalars


   .. py:method:: split(delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.split('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, mapping = orig.split('|', return_segments=True)
      >>> mapping
      array([0 2 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_split, under_map = under.split('_+', return_segments=True, regex=True)
      >>> under_split
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0 2 5])



   .. py:method:: startswith(substr: Union[bytes, arkouda.numpy.dtypes.str_scalars], regex: bool = False) -> arkouda.numpy.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True True True True True])
      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True True True True True])



   .. py:method:: stick(other: Strings, delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool, default=False

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])



   .. py:method:: strip(chars: Optional[Union[bytes, arkouda.numpy.dtypes.str_scalars]] = '') -> Strings

      Returns a new Strings object with all leading and trailing occurrences of characters contained
      in chars removed. The chars argument is a string specifying the set of characters to be removed.
      If omitted, the chars argument defaults to removing whitespace. The chars argument is not a
      prefix or suffix; rather, all combinations of its values are stripped.

      :param chars: the set of characters to be removed
      :type chars: bytes or str_scalars, optional

      :returns: Strings object with the leading and trailing characters matching the set of characters in
                the chars argument removed
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> strings = ak.array(['Strings ', '  StringS  ', 'StringS   '])
      >>> s = strings.strip()
      >>> s
      array(['Strings', 'StringS', 'StringS'])

      >>> strings = ak.array(['Strings 1', '1 StringS  ', '  1StringS  12 '])
      >>> s = strings.strip(' 12')
      >>> s
      array(['Strings', 'StringS', 'StringS'])



   .. py:method:: sub(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], repl: Union[bytes, arkouda.numpy.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the
      replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])



   .. py:method:: subn(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], repl: Union[bytes, arkouda.numpy.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))



   .. py:method:: title() -> Strings

      Returns a new Strings from the original replaced with their titlecase equivalent.

      :returns: Strings from the original replaced with their titlecase equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.title()
      array(['Strings 0', 'Strings 1', 'Strings 2', 'Strings 3', 'Strings 4'])



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'strings_array', col_delim: str = ',', overwrite: bool = False) -> str

      Write Strings to CSV file(s). File will contain a single column with the Strings data.
      All CSV Files written by Arkouda include a header denoting data types of the columns.
      Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing
      bytes as uint(8).

      :param prefix_path: The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                          when they are written to disk.
      :type prefix_path: str
      :param dataset: Column name to save the Strings under. Defaults to "strings_array".
      :type dataset: str, default="strings_array"
      :param col_delim: Defaults to ",". Value to be used to separate columns within the file.
                        Please be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, default=","
      :param overwrite: Defaults to False. If True, any existing files matching your provided prefix_path will
                        be overwritten. If False, an error will be returned if existing files are found.
      :type overwrite: bool, default=False

      :returns: response message
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one or
          more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          If `allow_errors` is true this may be raised if no values are returned
          from the server.
      :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline (``\n``) at this time.



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, file_type: Literal['single', 'distribute'] = 'distribute') -> str

      Save the Strings object to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - Parquet files do not store the segments, only the values.
      - Strings state is saved as two datasets within an hdf5 group:
        one for the string characters and one for the
        segments corresponding to the start of each string
      - the hdf5 group is named via the dataset parameter.
      - The prefix_path must be visible to the arkouda server and the user must
        have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
        ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
        the file name will be `prefix_path`.
      - If any of the output files already exist and
        the mode is 'truncate', they will be overwritten. If the mode is 'append'
        and the number of output files is less than the number of locales or a
        dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
        determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_list() -> list

      Convert the SegString to a list, transferring data from the
      arkouda server to Python. If the SegString exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A list with the same strings as this SegString
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_list()
      ['hello', 'my', 'world']
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None) -> str

      Save the Strings object to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.



   .. py:method:: transfer(hostname: str, port: arkouda.numpy.dtypes.int_scalars) -> Union[str, memoryview]

      Sends a Strings object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Strings object is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:


      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'strings_array', save_offsets: bool = True, repack: bool = True) -> str

      Overwrite the dataset with the name provided with this Strings object. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str, default="strings_array"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool, default=True

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the Strings object

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: upper() -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with
      their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with
                their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])



.. py:class:: Strings(strings_pdarray: arkouda.numpy.pdarrayclass.pdarray, bytes_size: arkouda.numpy.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.


   .. py:attribute:: BinOps


   .. py:method:: astype(dtype: Union[numpy.dtype, str]) -> arkouda.numpy.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:


      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: cached_regex_patterns() -> List

      Returns the regex patterns for which Match objects have been cached



   .. py:method:: capitalize() -> Strings

      Returns a new Strings from the original replaced with the first letter capitilzed
      and the remaining letters lowercase.

      :returns: Strings from the original replaced with the capitalized equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`, :obj:`String.title`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS aRe Here {i}' for i in range(5)])
      >>> strings
      array(['StrINgS aRe Here 0', 'StrINgS aRe Here 1', 'StrINgS aRe Here 2', 'StrINgS aRe Here 3', 'StrINgS aRe Here 4'])
      >>> strings.title()
      array(['Strings Are Here 0', 'Strings Are Here 1', 'Strings Are Here 2', 'Strings Are Here 3', 'Strings Are Here 4'])



   .. py:method:: contains(substr: Union[bytes, arkouda.numpy.dtypes.str_scalars], regex: bool = False) -> arkouda.numpy.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True True True True True])
      >>> strings.contains('string \d', regex=True)
      array([True True True True True])



   .. py:method:: decode(fromEncoding: str, toEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `fromEncoding`, expecting that the
      current Strings is encoded in `toEncoding`

      :param fromEncoding: The current encoding of the strings object
      :type fromEncoding: str
      :param toEncoding: The encoding that the strings will be converted to,
                         default to UTF-8
      :type toEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:attribute:: dtype


   .. py:method:: encode(toEncoding: str, fromEncoding: str = 'UTF-8') -> Strings

      Return a new strings object in `toEncoding`, expecting that the
      current Strings is encoded in `fromEncoding`

      :param toEncoding: The encoding that the strings will be converted to
      :type toEncoding: str
      :param fromEncoding: The current encoding of the strings object, default to
                           UTF-8
      :type fromEncoding: str, default="UTF-8"

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: endswith(substr: Union[bytes, arkouda.numpy.dtypes.str_scalars], regex: bool = False) -> arkouda.numpy.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True True True True True])
      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True True True True True])



   .. py:attribute:: entry
      :type:  arkouda.numpy.pdarrayclass.pdarray


   .. py:method:: equals(other: Any) -> arkouda.numpy.dtypes.bool_scalars

      Whether Strings are the same size and all entries are equal.

      :param other: object to compare.
      :type other: Any

      :returns: True if the Strings are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> s = ak.array(["a", "b", "c"])
      >>> s_cpy = ak.array(["a", "b", "c"])
      >>> s.equals(s_cpy)
      True
      >>> s2 = ak.array(["a", "x", "c"])
      >>> s.equals(s2)
      False



   .. py:method:: find_locations(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> Tuple[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions,
      and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: bytes or str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2 2 2 2 2])
      >>> starts
      array([0 9 0 9 0 9 0 9 0 9])
      >>> lens
      array([1 1 1 1 1 1 1 1 1 1])



   .. py:method:: findall(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each
                                   pattern match is from
      :type return_match_origins: bool, default=False

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))



   .. py:method:: flatten() -> Strings

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. note::

         As multidimensional Strings are currently supported,
         flatten on a Strings object will always return itself.



   .. py:method:: from_parts(offset_attrib: Union[arkouda.numpy.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.numpy.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: pdarray or str
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: pdarray or str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.



   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.



   .. py:method:: fullmatch(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the whole string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=False; matched=False>



   .. py:method:: get_bytes() -> arkouda.numpy.pdarrayclass.pdarray

      Getter for the bytes component (uint8 pdarray) of this Strings.

      :returns: Pdarray of bytes of the string accessed
      :rtype: pdarray, uint8

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_bytes()
      [111 110 101 0 116 119 111 0 116 104 114 101 101 0]



   .. py:method:: get_lengths() -> arkouda.numpy.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: get_offsets() -> arkouda.numpy.pdarrayclass.pdarray

      Getter for the offsets component (int64 pdarray) of this Strings.

      :returns: Pdarray of offsets of the string accessed
      :rtype: pdarray, int64

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_offsets()
      [0 4 8]



   .. py:method:: get_prefixes(n: arkouda.numpy.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.numpy.pdarrayclass.pdarray]]

      Return the n-long prefix of each string, where possible

      :param n: Length of prefix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-prefix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper prefixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a prefix.
      :type proper: bool, default=True

      :returns: * **prefixes** (*Strings*) -- The array of n-character prefixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character prefix, False otherwise.



   .. py:method:: get_suffixes(n: arkouda.numpy.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.numpy.pdarrayclass.pdarray]]

      Return the n-long suffix of each string, where possible

      :param n: Length of suffix
      :type n: int_scalars
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-suffix
      :type return_origins: bool, default=True
      :param proper: If True, only return proper suffixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a suffix.
      :type proper: bool, default=True

      :returns: * **suffixes** (*Strings*) -- The array of n-character suffixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character suffix, False otherwise.



   .. py:method:: group() -> arkouda.numpy.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedString.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message



   .. py:method:: hash() -> Tuple[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:property:: inferred_type
      :type: str


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: isalnum() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphanumeric.

      :returns: True for elements that are alphanumeric, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_alnum = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alnum = ak.array([f'Strings{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_alnum, alnum])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'Strings0', 'Strings1', 'Strings2'])
      >>> strings.isalnum()
      array([False False False True True True])



   .. py:method:: isalpha() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphabetic.  This means there is at least one character,
      and all the characters are alphabetic.

      :returns: True for elements that are alphabetic, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`, :obj:`Strings.isalnum`

      .. rubric:: Examples

      >>> not_alpha = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alpha = ak.array(['StringA','StringB','StringC'])
      >>> strings = ak.concatenate([not_alpha, alpha])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'StringA', 'StringB', 'StringC'])
      >>> strings.isalpha()
      array([False False False True True True])



   .. py:method:: isdecimal() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all decimal characters.

      :returns: True for elements that are decimals, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isdigit`

      .. rubric:: Examples

      >>> not_decimal = ak.array([f'Strings {i}' for i in range(3)])
      >>> decimal = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_decimal, decimal])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdecimal()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdecimal()
      array([False True False False False])



   .. py:method:: isdigit() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all digit characters.

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_digit = ak.array([f'Strings {i}' for i in range(3)])
      >>> digit = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_digit, digit])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdigit()
      array([False False False True True True])

      Special Character Examples

      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdigit()
      array([False True True True False])



   .. py:method:: isempty() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is empty.


      True for elements that are the empty string, False otherwise

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_empty = ak.array([f'Strings {i}' for i in range(3)])
      >>> empty = ak.array(['' for i in range(3)])
      >>> strings = ak.concatenate([not_empty, empty])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '', '', ''])
      >>> strings.isempty()
      array([False False False True True True])



   .. py:method:: islower() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.islower()
      array([True True True False False False])



   .. py:method:: isspace() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i has all
      whitespace characters (‘ ’, ‘\\t’, ‘\\n’, ‘\\v’, ‘\\f’, ‘\\r’).

      :returns: True for elements that are whitespace, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_space = ak.array([f'Strings {i}' for i in range(3)])
      >>> space = ak.array([' ', '\t', '\n', '\v', '\f', '\r', ' \t\n\v\f\r'])
      >>> strings = ak.concatenate([not_space, space])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', ' ', 'u0009', 'n', 'u000B', 'u000C', 'u000D', ' u0009nu000Bu000Cu000D'])
      >>> strings.isspace()
      array([False False False True True True True True True True])



   .. py:method:: istitle() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is titlecase

      :returns: True for elements that are titlecase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> mixed = ak.array([f'sTrINgs {i}' for i in range(3)])
      >>> title = ak.array([f'Strings {i}' for i in range(3)])
      >>> strings = ak.concatenate([mixed, title])
      >>> strings
      array(['sTrINgs 0', 'sTrINgs 1', 'sTrINgs 2', 'Strings 0', 'Strings 1', 'Strings 2'])
      >>> strings.istitle()
      array([False False False True True True])



   .. py:method:: isupper() -> arkouda.numpy.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.isupper()
      array([False False False True True True])



   .. py:attribute:: logger


   .. py:method:: lower() -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with
      their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with
                their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])



   .. py:method:: lstick(other: Strings, delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])



   .. py:method:: match(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match only if the beginning of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=True, span=(0, 2); matched=False>



   .. py:attribute:: objType
      :value: 'Strings'



   .. py:method:: peel(delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars], times: arkouda.numpy.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool, default=False
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: purge_cached_regex_patterns() -> None

      purges cached regex patterns



   .. py:method:: regex_split(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern.
      If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: bytes or str_scalars
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int, default=0
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool, default=False

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.regex_split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))



   .. py:method:: register(user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and
                has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:attribute:: registered_name
      :type:  Optional[str]
      :value: None



   .. py:method:: rpeel(delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars], times: arkouda.numpy.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False) -> Tuple[Strings, Strings]

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: bytes or str_scalars
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: int_scalars, default=1
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool, default=False
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))

      Compared against peel

      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))



   .. py:method:: save(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None, file_format: Literal['HDF5', 'Parquet'] = 'HDF5', file_type: Literal['single', 'distribute'] = 'distribute') -> str

      DEPRECATED
      Save the Strings object to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool, default=True
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: {"HDF5", "Parquet"}, default = "HDF5"
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter. (3) Parquet files do not store the segments,
      only the values.



   .. py:method:: search(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: bytes or str_scalars

      :returns: Match object where elements match if any part of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4);
      matched=False; matched=True, span=(0, 2); matched=False>



   .. py:attribute:: size
      :type:  arkouda.numpy.dtypes.int_scalars


   .. py:method:: split(delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool, default=False
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.split('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, mapping = orig.split('|', return_segments=True)
      >>> mapping
      array([0 2 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_split, under_map = under.split('_+', return_segments=True, regex=True)
      >>> under_split
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0 2 5])



   .. py:method:: startswith(substr: Union[bytes, arkouda.numpy.dtypes.str_scalars], regex: bool = False) -> arkouda.numpy.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: bytes or str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool, default=False

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True True True True True])
      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True True True True True])



   .. py:method:: stick(other: Strings, delimiter: Union[bytes, arkouda.numpy.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: bytes or str_scalars, default=""
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool, default=False

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])



   .. py:method:: strip(chars: Optional[Union[bytes, arkouda.numpy.dtypes.str_scalars]] = '') -> Strings

      Returns a new Strings object with all leading and trailing occurrences of characters contained
      in chars removed. The chars argument is a string specifying the set of characters to be removed.
      If omitted, the chars argument defaults to removing whitespace. The chars argument is not a
      prefix or suffix; rather, all combinations of its values are stripped.

      :param chars: the set of characters to be removed
      :type chars: bytes or str_scalars, optional

      :returns: Strings object with the leading and trailing characters matching the set of characters in
                the chars argument removed
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> strings = ak.array(['Strings ', '  StringS  ', 'StringS   '])
      >>> s = strings.strip()
      >>> s
      array(['Strings', 'StringS', 'StringS'])

      >>> strings = ak.array(['Strings 1', '1 StringS  ', '  1StringS  12 '])
      >>> s = strings.strip(' 12')
      >>> s
      array(['Strings', 'StringS', 'StringS'])



   .. py:method:: sub(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], repl: Union[bytes, arkouda.numpy.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the
      replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])



   .. py:method:: subn(pattern: Union[bytes, arkouda.numpy.dtypes.str_scalars], repl: Union[bytes, arkouda.numpy.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: bytes or str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: bytes or str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int, default=0

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))



   .. py:method:: title() -> Strings

      Returns a new Strings from the original replaced with their titlecase equivalent.

      :returns: Strings from the original replaced with their titlecase equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.title()
      array(['Strings 0', 'Strings 1', 'Strings 2', 'Strings 3', 'Strings 4'])



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'strings_array', col_delim: str = ',', overwrite: bool = False) -> str

      Write Strings to CSV file(s). File will contain a single column with the Strings data.
      All CSV Files written by Arkouda include a header denoting data types of the columns.
      Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing
      bytes as uint(8).

      :param prefix_path: The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                          when they are written to disk.
      :type prefix_path: str
      :param dataset: Column name to save the Strings under. Defaults to "strings_array".
      :type dataset: str, default="strings_array"
      :param col_delim: Defaults to ",". Value to be used to separate columns within the file.
                        Please be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, default=","
      :param overwrite: Defaults to False. If True, any existing files matching your provided prefix_path will
                        be overwritten. If False, an error will be returned if existing files are found.
      :type overwrite: bool, default=False

      :returns: response message
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one or
          more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          If `allow_errors` is true this may be raised if no values are returned
          from the server.
      :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline (``\n``) at this time.



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', save_offsets: bool = True, file_type: Literal['single', 'distribute'] = 'distribute') -> str

      Save the Strings object to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: {"single", "distribute"}, default = "distribute"

      :rtype: String message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - Parquet files do not store the segments, only the values.
      - Strings state is saved as two datasets within an hdf5 group:
        one for the string characters and one for the
        segments corresponding to the start of each string
      - the hdf5 group is named via the dataset parameter.
      - The prefix_path must be visible to the arkouda server and the user must
        have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
        ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
        the file name will be `prefix_path`.
      - If any of the output files already exist and
        the mode is 'truncate', they will be overwritten. If the mode is 'append'
        and the number of output files is less than the number of locales or a
        dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
        determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_list() -> list

      Convert the SegString to a list, transferring data from the
      arkouda server to Python. If the SegString exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A list with the same strings as this SegString
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_list()
      ['hello', 'my', 'world']
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'strings_array', mode: Literal['truncate', 'append'] = 'truncate', compression: Optional[Literal['snappy', 'gzip', 'brotli', 'zstd', 'lz4']] = None) -> str

      Save the Strings object to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str, default="strings_array"
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: {"truncate", "append"}, default = "truncate"
      :param compression: Sets the compression type used with Parquet files
      :type compression: {"snappy", "gzip", "brotli", "zstd", "lz4"}, optional

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.



   .. py:method:: transfer(hostname: str, port: arkouda.numpy.dtypes.int_scalars) -> Union[str, memoryview]

      Sends a Strings object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Strings object is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:


      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'strings_array', save_offsets: bool = True, repack: bool = True) -> str

      Overwrite the dataset with the name provided with this Strings object. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str, default="strings_array"
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool, default=True
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool, default=True

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the Strings object

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: upper() -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with
      their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with
                their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])



.. py:class:: Timedelta(pda, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`


   Represents a duration, the difference between two dates or times.

   Timedelta is the Arkouda equivalent of pandas.TimedeltaIndex.

   :param pda:
   :type pda: int64 pdarray, pd.TimedeltaIndex, pd.Series, or np.timedelta64 array
   :param unit: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type unit: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.


   .. py:method:: abs()

      Absolute value of time interval.



   .. py:property:: components


   .. py:property:: days


   .. py:method:: is_registered() -> numpy.bool_

       Return True iff the object is contained in the registry or is a component of a
       registered object.

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: microseconds


   .. py:property:: nanoseconds


   .. py:method:: register(user_defined_name)

      Register this Timedelta object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the timedelta is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Timedelta which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different Timedeltas with the same name.
      :rtype: Timedelta

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the timedelta with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: seconds


   .. py:attribute:: special_objType
      :value: 'Timedelta'



   .. py:method:: std(ddof: arkouda.numpy.dtypes.int_scalars = 0)

      Returns the standard deviation as a pd.Timedelta object



   .. py:method:: sum()

      Return sum of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.sum(ak.array([1,2,3,4,5]))
      15
      >>> ak.sum(ak.array([5.5,4.5,3.5,2.5,1.5]))
      17.5
      >>> ak.array([[1,2,3],[5,4,3]]).sum(axis=1)
      array([6 12])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.sum()) or a standalone function (e.g. ak.sum(a))



   .. py:attribute:: supported_opeq


   .. py:attribute:: supported_with_datetime


   .. py:attribute:: supported_with_pdarray


   .. py:attribute:: supported_with_r_datetime


   .. py:attribute:: supported_with_r_pdarray


   .. py:attribute:: supported_with_r_timedelta


   .. py:attribute:: supported_with_timedelta


   .. py:method:: to_pandas()

      Convert array to a pandas TimedeltaIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`



   .. py:method:: total_seconds()


   .. py:method:: unregister()

      Unregister this timedelta object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



.. py:class:: Tuple(origin, nparams, *, inst=True, name=None)

   Bases: :py:obj:`_SpecialGenericAlias`


   Tuple type; Tuple[X, Y] is the cross-product type of X and Y.

       Example: Tuple[T1, T2] is a tuple of two elements corresponding
       to type variables T1 and T2.  Tuple[int, float, str] is a tuple
       of an int, a float and a string.

       To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].




.. py:class:: Tuple(origin, nparams, *, inst=True, name=None)

   Bases: :py:obj:`_SpecialGenericAlias`


   Tuple type; Tuple[X, Y] is the cross-product type of X and Y.

       Example: Tuple[T1, T2] is a tuple of two elements corresponding
       to type variables T1 and T2.  Tuple[int, float, str] is a tuple
       of an int, a float and a string.

       To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].




.. py:class:: Union

   Bases: :py:obj:`_Final`


   Union type; Union[X, Y] means either X or Y.

       To define a union, use e.g. Union[int, str].  Details:
       - The arguments must be types and there must be at least one.
       - None as an argument is a special case and is replaced by
         type(None).
       - Unions of unions are flattened, e.g.::

           Union[Union[int, str], float] == Union[int, str, float]

       - Unions of a single argument vanish, e.g.::

           Union[int] == int  # The constructor actually returns int

       - Redundant arguments are skipped, e.g.::

           Union[int, str, int] == Union[int, str]

       - When comparing unions, the argument order is ignored, e.g.::

           Union[int, str] == Union[str, int]

       - You cannot subclass or instantiate a union.
       - You can use Optional[X] as a shorthand for Union[X, None].




.. py:class:: Union

   Bases: :py:obj:`_Final`


   Union type; Union[X, Y] means either X or Y.

       To define a union, use e.g. Union[int, str].  Details:
       - The arguments must be types and there must be at least one.
       - None as an argument is a special case and is replaced by
         type(None).
       - Unions of unions are flattened, e.g.::

           Union[Union[int, str], float] == Union[int, str, float]

       - Unions of a single argument vanish, e.g.::

           Union[int] == int  # The constructor actually returns int

       - Redundant arguments are skipped, e.g.::

           Union[int, str, int] == Union[int, str]

       - When comparing unions, the argument order is ignored, e.g.::

           Union[int, str] == Union[str, int]

       - You cannot subclass or instantiate a union.
       - You can use Optional[X] as a shorthand for Union[X, None].




.. py:data:: VAL_SUFFIX
   :value: '_values'


.. py:function:: ak_array(a: Union[arkouda.numpy.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str, NoneType] = None, max_bits: int = -1) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if nbytes > maxTransferBytes, a.dtype is not supported (not in DTypes),
       or if the product of a size and a.itemsize > maxTransferBytes
   :raises ValueError: Raised if a has rank is not in get_array_ranks(), or if the returned message is malformed or does
       not contain the fields required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `ak.client.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.client.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1 2 3 4 5 6 7 8 9])

   >>> ak.array(range(1,10))
   array([1 2 3 4 5 6 7 8 9])

   >>> strings = ak.array([f'string {i}' for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.numpy.strings.Strings'>


.. py:data:: all_scalars

   The DType enum defines the supported Arkouda data types in string form.

.. py:class:: all_scalars(origin, params, *, inst=True, name=None)

   Bases: :py:obj:`_GenericAlias`


   The central part of internal API.

   This represents a generic version of type 'origin' with type arguments 'params'.
   There are two kind of these aliases: user defined and special. The special ones
   are wrappers around builtin collections and ABCs in collections.abc. These must
   have 'name' always set. If 'inst' is False, then the alias can't be instantiated,
   this is used by e.g. typing.List and typing.Dict.


.. py:function:: arange(*args, **kwargs) -> arkouda.numpy.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0 1 2 3 4])

   >>> ak.arange(5, 0, -1)
   array([5 4 3 2 1])

   >>> ak.arange(0, 10, 2)
   array([0 2 4 6 8])

   >>> ak.arange(-5, -10, -1)
   array([-5 -6 -7 -8 -9])


.. py:function:: arange(*args, **kwargs) -> arkouda.numpy.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0 1 2 3 4])

   >>> ak.arange(5, 0, -1)
   array([5 4 3 2 1])

   >>> ak.arange(0, 10, 2)
   array([0 2 4 6 8])

   >>> ak.arange(-5, -10, -1)
   array([-5 -6 -7 -8 -9])


.. py:function:: argmaxk(pda: pdarray, k: arkouda.numpy.dtypes.int_scalars) -> pdarray

   Find the indices corresponding to the `k` maximum values of an array.

   Returns the largest `k` values of an array, sorted

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of indices corresponding to maxmum array values
   :type k: int_scalars

   :returns: The indices of the maximum `k` values from the pda, sorted
   :rtype: pdarray, int

   :raises TypeError: Raised if pda is not a pdarray or k is not an integer
   :raises ValueError: Raised if the pda is empty, or pda.ndim > 1, or k < 1

   .. rubric:: Notes

   This call is equivalent in value to ak.argsort(a)[k:]
   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degradation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.argmaxk(A, 3)
   array([4, 6, 0])
   >>> ak.argmaxk(A, 4)
   array([1, 4, 6, 0])


.. py:function:: argmink(pda: pdarray, k: arkouda.numpy.dtypes.int_scalars) -> pdarray

   Finds the indices corresponding to the `k` minimum values of an array.

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of indices corresponding to minimum array values
   :type k: int_scalars

   :returns: The indices of the minimum `k` values from the pda, sorted
   :rtype: pdarray, int

   :raises TypeError: Raised if pda is not a pdarray or k is not an integer
   :raises ValueError: Raised if the pda is empty, or pda.ndim > 1, or k < 1

   .. rubric:: Notes

   This call is equivalent in value to ak.argsort(a)[:k]
   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degradation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.argmink(A, 3)
   array([7, 2, 5])
   >>> ak.argmink(A, 4)
   array([7, 2, 5, 3])


.. py:function:: argsort(pda: Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, arkouda.categorical.Categorical], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD, axis: arkouda.numpy.dtypes.int_scalars = 0) -> arkouda.numpy.pdarrayclass.pdarray

   Return the permutation that sorts the array.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray, Strings, or Categorical
   :param algorithm: The algorithm to be used for sorting the array.
   :type algorithm: SortingAlgorithm, default=SortingAlgorithm.RadixSortLSD
   :param axis: The axis to sort over.
   :type axis: int_scalars, default=0

   :returns: The indices such that ``pda[indices]`` is sorted
   :rtype: pdarray of int64

   :raises TypeError: Raised if the parameter is other than a pdarray, Strings or Categorical

   .. seealso:: :obj:`coargsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and
   resilient to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> perm = ak.argsort(a)
   >>> a[perm]
   array([0 1 3 3 5 5 5 6 6 6])

   >>> ak.argsort(a, ak.sorting.SortingAlgorithm["RadixSortLSD"])
   array([0 2 9 6 8 1 3 5 7 4])

   >>> ak.argsort(a, ak.sorting.SortingAlgorithm["TwoArrayRadixSort"])
   array([0 2 9 6 8 1 3 5 7 4])


.. py:function:: array(a: Union[arkouda.numpy.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str, None] = None, max_bits: int = -1) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if nbytes > maxTransferBytes, a.dtype is not supported (not in DTypes),
       or if the product of a size and a.itemsize > maxTransferBytes
   :raises ValueError: Raised if a has rank is not in get_array_ranks(), or if the returned message is malformed or does
       not contain the fields required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `ak.client.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.client.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1 2 3 4 5 6 7 8 9])

   >>> ak.array(range(1,10))
   array([1 2 3 4 5 6 7 8 9])

   >>> strings = ak.array([f'string {i}' for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.numpy.strings.Strings'>


.. py:function:: array(a: Union[arkouda.numpy.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str, None] = None, max_bits: int = -1) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if nbytes > maxTransferBytes, a.dtype is not supported (not in DTypes),
       or if the product of a size and a.itemsize > maxTransferBytes
   :raises ValueError: Raised if a has rank is not in get_array_ranks(), or if the returned message is malformed or does
       not contain the fields required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `ak.client.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.client.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1 2 3 4 5 6 7 8 9])

   >>> ak.array(range(1,10))
   array([1 2 3 4 5 6 7 8 9])

   >>> strings = ak.array([f'string {i}' for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.numpy.strings.Strings'>


.. py:function:: attach(name: str)

.. py:function:: attach_all(names: list)

   Attach to all objects registered with the names provide

   :param names: List of names to attach to
   :type names: list

   :rtype: dict


.. py:function:: attach_pdarray(user_defined_name: str) -> pdarray

   class method to return a pdarray attached to the registered name in the arkouda
   server which was registered using register()

   :param user_defined_name: user defined name which array was registered under
   :type user_defined_name: str

   :returns: pdarray which is bound to the corresponding server side component which was registered
             with user_defined_name
   :rtype: pdarray

   :raises TypeError: Raised if user_defined_name is not a str

   .. seealso:: :obj:`attach`, :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

   .. rubric:: Notes

   Registered names/pdarrays in the server are immune to deletion
   until they are unregistered.

   .. rubric:: Examples

   >>> a = zeros(100)
   >>> a.register("my_zeros")
   >>> # potentially disconnect from server and reconnect to server
   >>> b = ak.attach_pdarray("my_zeros")
   >>> # ...other work...
   >>> b.unregister()


.. py:class:: bigint

   Datatype for representing integers of variable size.

   May be used for integers that exceed 64 bits.


   .. py:attribute:: itemsize
      :value: 128



   .. py:attribute:: kind
      :value: 'ui'



   .. py:attribute:: name
      :value: 'bigint'



   .. py:attribute:: ndim
      :value: 0



   .. py:attribute:: shape
      :value: ()



   .. py:method:: type(x)


.. py:function:: bigint_from_uint_arrays(arrays, max_bits=-1)

   Create a bigint pdarray from an iterable of uint pdarrays.
   The first item in arrays will be the highest 64 bits and
   the last item will be the lowest 64 bits.

   :param arrays: An iterable of uint pdarrays used to construct the bigint pdarray.
                  The first item in arrays will be the highest 64 bits and
                  the last item will be the lowest 64 bits.
   :type arrays: Sequence[pdarray]
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: bigint pdarray constructed from uint arrays
   :rtype: pdarray

   :raises TypeError: Raised if any pdarray in arrays has a dtype other than uint or
       if the pdarrays are not the same size.
   :raises RuntimeError: Raised if there is a server-side error thrown

   .. seealso:: :obj:`pdarray.bigint_to_uint_arrays`

   .. rubric:: Examples

   >>> a = ak.bigint_from_uint_arrays([ak.ones(5, dtype=ak.uint64), ak.arange(5, dtype=ak.uint64)])
   >>> a
   array([18446744073709551616 18446744073709551617 18446744073709551618
   18446744073709551619 18446744073709551620])

   >>> a.dtype
   dtype(bigint)

   >>> all(a[i] == 2**64 + i for i in range(5))
   True


.. py:data:: bitType

.. py:data:: bool_scalars

.. py:class:: bool_scalars(origin, params, *, inst=True, name=None)

   Bases: :py:obj:`_GenericAlias`


   The central part of internal API.

   This represents a generic version of type 'origin' with type arguments 'params'.
   There are two kind of these aliases: user defined and special. The special ones
   are wrappers around builtin collections and ABCs in collections.abc. These must
   have 'name' always set. If 'inst' is False, then the alias can't be instantiated,
   this is used by e.g. typing.List and typing.Dict.


.. py:function:: broadcast(segments: pdarray, values: Union[pdarray, Strings], size: Union[int, np.int64, np.uint64] = -1, permutation: Union[pdarray, None] = None)

   Broadcast a dense column vector to the rows of a sparse matrix or grouped array.

   :param segments: Offsets of the start of each row in the sparse matrix or grouped array.
                    Must be sorted in ascending order.
   :type segments: pdarray, int64
   :param values: The values to broadcast, one per row (or group)
   :type values: pdarray, Strings
   :param size: The total number of nonzeros in the matrix. If permutation is given, this
                argument is ignored and the size is inferred from the permutation array.
   :type size: int
   :param permutation: The permutation to go from the original ordering of nonzeros to the ordering
                       grouped by row. To broadcast values back to the original ordering, this
                       permutation will be inverted. If no permutation is supplied, it is assumed
                       that the original nonzeros were already grouped by row. In this case, the
                       size argument must be given.
   :type permutation: pdarray, int64

   :returns: The broadcast values, one per nonzero
   :rtype: pdarray, Strings

   :raises ValueError: - If segments and values are different sizes
       - If segments are empty
       - If number of nonzeros (either user-specified or inferred from permutation)
         is less than one

   .. rubric:: Examples

   >>>
   # Define a sparse matrix with 3 rows and 7 nonzeros
   >>> row_starts = ak.array([0, 2, 5])
   >>> nnz = 7
   # Broadcast the row number to each nonzero element
   >>> row_number = ak.arange(3)
   >>> ak.broadcast(row_starts, row_number, nnz)
   array([0 0 1 1 1 2 2])
   # If the original nonzeros were in reverse order...
   >>> permutation = ak.arange(6, -1, -1)
   >>> ak.broadcast(row_starts, row_number, permutation=permutation)
   array([2 2 1 1 1 0 0])


.. py:function:: broadcast_dims(sa: Sequence[int], sb: Sequence[int]) -> Tuple[int, Ellipsis]

   Algorithm to determine shape of broadcasted PD array given two array shapes

   see: https://data-apis.org/array-api/latest/API_specification/broadcasting.html#algorithm


.. py:function:: broadcast_to_shape(pda: pdarray, shape: Tuple[int, Ellipsis]) -> pdarray

   Create a "broadcasted" array (of rank 'nd') by copying an array into an
   array of the given shape.

   E.g., given the following broadcast:

   pda    (3d array):  1 x 4 x 1

   shape  ( shape  ):  7 x 4 x 2

   Result (3d array):  7 x 4 x 2

   When copying from a singleton dimension, the value is repeated along
   that dimension (e.g., pda's 1st and 3rd above).
   For non singleton dimensions, the size of the two arrays must match,
   and the values are copied into the result array.

   When prepending a new dimension to increase an array's rank, the
   values from the other dimensions are repeated along the new dimension.


   :param pda: the input to be broadcast
   :type pda: pdarray
   :param shape: the shape to which pda is to be broadcast
   :type shape: tuple of int

   :returns: the result of the broadcast operation
   :rtype: pdarray

   .. rubric:: Examples

   >>> a = ak.arange(2).reshape(1,2,1)
   >>> ak.broadcast_to_shape(a,(2,2,2))
   array([array([array([0 0]) array([1 1])]) array([array([0 0]) array([1 1])])])
   >>> a = ak.array([5,19]).reshape(1,2)
   >>> ak.broadcast_to_shape(a,(2,2,2))
   array([array([array([5 19]) array([5 19])]) array([array([5 19]) array([5 19])])])

   :raises RuntimeError: raised if the pda can't be broadcast to the given shape


.. py:function:: can_cast(from_, to) -> bool

   Returns True if cast between data types can occur according to the casting rule.

   :param from_: Data type, NumPy scalar, or array to cast from.
   :type from_: dtype, dtype specifier, NumPy scalar, or pdarray
   :param to: Data type to cast to.
   :type to: dtype or dtype specifier

   :returns: True if cast can occur according to the casting rule.
   :rtype: bool


.. py:function:: cast(typ, val)

   Cast a value to a type.

       This returns the value unchanged.  To the type checker this
       signals that the return value has the designated type, but at
       runtime we intentionally don't check anything (we want this
       to be as fast as possible).




.. py:function:: clear() -> None

   Send a clear message to clear all unregistered data from the server symbol table

   :rtype: None

   :raises RuntimeError: Raised if there is a server-side error in executing clear request


.. py:function:: clz(pda: pdarray) -> pdarray

   Count leading zeros for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64, bigint

   :returns: **lz** -- The number of leading zeros of each element.
   :rtype: pdarray

   :raises TypeError: If input array is not int64, uint64, or bigint

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.clz(A)
   array([64, 63, 62, 62, 61, 61, 61, 61, 60, 60])


.. py:function:: coargsort(arrays: Sequence[Union[arkouda.numpy.strings.Strings, arkouda.numpy.pdarrayclass.pdarray, arkouda.categorical.Categorical]], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.numpy.pdarrayclass.pdarray

   Return the permutation that groups the rows (left-to-right), if the
   input arrays are treated as columns. The permutation sorts numeric
   columns, but not strings/Categoricals -- strings/Categoricals are grouped, but not ordered.

   :param arrays: The columns (int64, uint64, float64, Strings, or Categorical) to sort by row
   :type arrays: Sequence of Strings, pdarray, or Categorical
   :param algorithm: The algorithm to be used for sorting the arrays.
   :type algorithm: SortingAlgorithm, default=SortingAlgorithm.RadixSortLSD

   :returns: The indices that permute the rows to grouped order
   :rtype: pdarray of int64

   :raises ValueError: Raised if the pdarrays are not of the same size or if the parameter
       is not an Iterable containing pdarrays, Strings, or Categoricals

   .. seealso:: :obj:`argsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and resilient
   to non-uniformity in data but communication intensive. Starts with the
   last array and moves forward. This sort operates directly on numeric types,
   but for Strings, it operates on a hash. Thus, while grouping of equivalent
   strings is guaranteed, lexicographic ordering of the groups is not. For Categoricals,
   coargsort sorts based on Categorical.codes which guarantees grouping of equivalent categories
   but not lexicographic ordering of those groups.

   .. rubric:: Examples

   >>> a = ak.array([0, 1, 0, 1])
   >>> b = ak.array([1, 1, 0, 0])
   >>> perm = ak.coargsort([a, b])
   >>> perm
   array([2 0 3 1])
   >>> a[perm]
   array([0 0 1 1])
   >>> b[perm]
   array([0 1 0 1])


.. py:function:: concatenate(arrays: Sequence[Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, arkouda.categorical.Categorical]], ordered: bool = True) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, arkouda.categorical.Categorical, Sequence[arkouda.categorical.Categorical]]

   Concatenate a list or tuple of ``pdarray`` or ``Strings`` objects into
   one ``pdarray`` or ``Strings`` object, respectively.

   :param arrays: The arrays to concatenate. Must all have same dtype.
   :type arrays: Sequence[Union[pdarray,Strings,Categorical]]
   :param ordered: If True (default), the arrays will be appended in the
                   order given. If False, array data may be interleaved
                   in blocks, which can greatly improve performance but
                   results in non-deterministic ordering of elements.
   :type ordered: bool

   :returns: Single pdarray or Strings object containing all values, returned in
             the original order
   :rtype: Union[pdarray,Strings,Categorical]

   :raises ValueError: Raised if arrays is empty or if pdarrays have differing dtypes
   :raises TypeError: Raised if arrays is not a pdarrays or Strings python Sequence such as a
       list or tuple
   :raises RuntimeError: Raised if any array elements are dtypes for which
       concatenate has not been implemented.

   .. rubric:: Examples

   >>> ak.concatenate([ak.array([1, 2, 3]), ak.array([4, 5, 6])])
   array([1 2 3 4 5 6])

   >>> ak.concatenate([ak.array([True,False,True]),ak.array([False,True,True])])
   array([True False True False True True])

   >>> ak.concatenate([ak.array(['one','two']),ak.array(['three','four','five'])])
   array(['one', 'two', 'three', 'four', 'five'])


.. py:function:: concatenate(arrays: Sequence[Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, arkouda.categorical.Categorical]], ordered: bool = True) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, arkouda.categorical.Categorical, Sequence[arkouda.categorical.Categorical]]

   Concatenate a list or tuple of ``pdarray`` or ``Strings`` objects into
   one ``pdarray`` or ``Strings`` object, respectively.

   :param arrays: The arrays to concatenate. Must all have same dtype.
   :type arrays: Sequence[Union[pdarray,Strings,Categorical]]
   :param ordered: If True (default), the arrays will be appended in the
                   order given. If False, array data may be interleaved
                   in blocks, which can greatly improve performance but
                   results in non-deterministic ordering of elements.
   :type ordered: bool

   :returns: Single pdarray or Strings object containing all values, returned in
             the original order
   :rtype: Union[pdarray,Strings,Categorical]

   :raises ValueError: Raised if arrays is empty or if pdarrays have differing dtypes
   :raises TypeError: Raised if arrays is not a pdarrays or Strings python Sequence such as a
       list or tuple
   :raises RuntimeError: Raised if any array elements are dtypes for which
       concatenate has not been implemented.

   .. rubric:: Examples

   >>> ak.concatenate([ak.array([1, 2, 3]), ak.array([4, 5, 6])])
   array([1 2 3 4 5 6])

   >>> ak.concatenate([ak.array([True,False,True]),ak.array([False,True,True])])
   array([True False True False True True])

   >>> ak.concatenate([ak.array(['one','two']),ak.array(['three','four','five'])])
   array(['one', 'two', 'three', 'four', 'five'])


.. py:function:: corr(x: pdarray, y: pdarray) -> numpy.float64

   Return the correlation between x and y

   :param x: One of the pdarrays used to calculate correlation
   :type x: pdarray
   :param y: One of the pdarrays used to calculate correlation
   :type y: pdarray

   :returns: The scalar correlation of the two pdarrays
   :rtype: np.float64

   .. rubric:: Examples

   >>> a = ak.arange(10)
   >>> b = a + 1
   >>> ak.corr(a,b)
   0.9999999999999998
   >>> a.corr(b)
   0.9999999999999998

   :raises TypeError: Raised if x or y is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown

   .. seealso:: :obj:`std`, :obj:`cov`

   .. rubric:: Notes

   The correlation is calculated by
   cov(x, y) / (x.std(ddof=1) * y.std(ddof=1))


.. py:function:: cov(x: pdarray, y: pdarray) -> numpy.float64

   Return the covariance of x and y

   :param x: One of the pdarrays used to calculate covariance
   :type x: pdarray
   :param y: One of the pdarrays used to calculate covariance
   :type y: pdarray

   :returns: The scalar covariance of the two pdarrays
   :rtype: np.float64

   .. rubric:: Examples

   >>> a = ak.arange(10)
   >>> b = a + 1
   >>> ak.cov(a,b)
   9.166666666666666
   >>> a.cov(b)
   9.166666666666666

   :raises TypeError: Raised if x or y is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown

   .. seealso:: :obj:`mean`, :obj:`var`

   .. rubric:: Notes

   The covariance is calculated by
   ``cov = ((x - x.mean()) * (y - y.mean())).sum() / (x.size - 1)``.


.. py:function:: create_pdarray(repMsg: str, max_bits=None) -> pdarray

   Return a pdarray instance pointing to an array created by the arkouda server.
   The user should not call this function directly.

   :param repMsg: space-delimited string containing the pdarray name, datatype, size
                  dimension, shape,and itemsize
   :type repMsg: str

   :returns: A pdarray with the same attributes and data as the pdarray; on GPU
   :rtype: pdarray

   :raises ValueError: If there's an error in parsing the repMsg parameter into the six
       values needed to create the pdarray instance
   :raises RuntimeError: Raised if a server-side error is thrown in the process of creating
       the pdarray instance


.. py:function:: create_pdarray(repMsg: str, max_bits=None) -> pdarray

   Return a pdarray instance pointing to an array created by the arkouda server.
   The user should not call this function directly.

   :param repMsg: space-delimited string containing the pdarray name, datatype, size
                  dimension, shape,and itemsize
   :type repMsg: str

   :returns: A pdarray with the same attributes and data as the pdarray; on GPU
   :rtype: pdarray

   :raises ValueError: If there's an error in parsing the repMsg parameter into the six
       values needed to create the pdarray instance
   :raises RuntimeError: Raised if a server-side error is thrown in the process of creating
       the pdarray instance


.. py:function:: create_pdarray(repMsg: str, max_bits=None) -> pdarray

   Return a pdarray instance pointing to an array created by the arkouda server.
   The user should not call this function directly.

   :param repMsg: space-delimited string containing the pdarray name, datatype, size
                  dimension, shape,and itemsize
   :type repMsg: str

   :returns: A pdarray with the same attributes and data as the pdarray; on GPU
   :rtype: pdarray

   :raises ValueError: If there's an error in parsing the repMsg parameter into the six
       values needed to create the pdarray instance
   :raises RuntimeError: Raised if a server-side error is thrown in the process of creating
       the pdarray instance


.. py:function:: ctz(pda: pdarray) -> pdarray

   Count trailing zeros for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64, bigint

   :returns: **lz** -- The number of trailing zeros of each element.
   :rtype: pdarray

   .. rubric:: Notes

   ctz(0) is defined to be zero.

   :raises TypeError: If input array is not int64, uint64, or bigint

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.ctz(A)
   array([0, 0, 1, 0, 2, 0, 1, 0, 3, 0])


.. py:function:: date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, inclusive='both', **kwargs)

   Creates a fixed frequency Datetime range. Alias for
   ``ak.Datetime(pd.date_range(args))``. Subject to size limit
   imposed by client.maxTransferBytes.

   :param start: Left bound for generating dates.
   :type start: str or datetime-like, optional
   :param end: Right bound for generating dates.
   :type end: str or datetime-like, optional
   :param periods: Number of periods to generate.
   :type periods: int, optional
   :param freq: Frequency strings can have multiples, e.g. '5H'. See
                timeseries.offset_aliases for a list of
                frequency aliases.
   :type freq: str or DateOffset, default 'D'
   :param tz: Time zone name for returning localized DatetimeIndex, for example
              'Asia/Hong_Kong'. By default, the resulting DatetimeIndex is
              timezone-naive.
   :type tz: str or tzinfo, optional
   :param normalize: Normalize start/end dates to midnight before generating date range.
   :type normalize: bool, default False
   :param name: Name of the resulting DatetimeIndex.
   :type name: str, default None
   :param closed: Make the interval closed with respect to the given frequency to
                  the 'left', 'right', or both sides (None, the default).
                  *Deprecated*
   :type closed: {None, 'left', 'right'}, optional
   :param inclusive: Include boundaries. Whether to set each bound as closed or open.
   :type inclusive: {"both", "neither", "left", "right"}, default "both"
   :param \*\*kwargs: For compatibility. Has no effect on the result.

   :returns: **rng**
   :rtype: DatetimeIndex

   .. rubric:: Notes

   Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,
   exactly three must be specified. If ``freq`` is omitted, the resulting
   ``DatetimeIndex`` will have ``periods`` linearly spaced elements between
   ``start`` and ``end`` (closed on both sides).

   To learn more about the frequency strings, please see `this link
   <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.


.. py:function:: delete(arr: arkouda.numpy.pdarrayclass.pdarray, obj: Union[arkouda.numpy.pdarrayclass.pdarray, slice, int], axis: Optional[int] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Return a copy of 'arr' with elements along the specified axis removed.

   :param arr: The array to remove elements from
   :type arr: pdarray
   :param obj: The indices to remove from 'arr'. If obj is a pdarray, it must
               have an integer dtype.
   :type obj: Union[pdarray, slice, int]
   :param axis: The axis along which to remove elements. If None, the array will
                be flattened before removing elements. Defaults to None.
   :type axis: Optional[int], optional

   :returns: A copy of 'arr' with elements removed
   :rtype: pdarray


.. py:function:: divmod(x: Union[arkouda.numpy.dtypes.numeric_scalars, pdarray], y: Union[arkouda.numpy.dtypes.numeric_scalars, pdarray], where: Union[arkouda.numpy.dtypes.bool_scalars, pdarray] = True) -> Tuple[pdarray, pdarray]

   :param x: The dividend array, the values that will be the numerator of the floordivision and will be
             acted on by the bases for modular division.
   :type x: numeric_scalars(float_scalars, int_scalars) or pdarray
   :param y: The divisor array, the values that will be the denominator of the division and will be the
             bases for the modular division.
   :type y: numeric_scalars(float_scalars, int_scalars) or pdarray
   :param where: This condition is broadcast over the input. At locations where the condition is True, the
                 corresponding value will be divided using floor and modular division. Elsewhere, it will retain
                 its original value. Default set to True.
   :type where: Boolean or pdarray

   :returns: Returns a tuple that contains quotient and remainder of the division
   :rtype: (pdarray, pdarray)

   :raises TypeError: At least one entry must be a pdarray
   :raises ValueError: If both inputs are both pdarrays, their size must match
   :raises ZeroDivisionError: No entry in y is allowed to be 0, to prevent division by zero

   .. rubric:: Notes

   The div is calculated by x // y
   The mod is calculated by x % y

   .. rubric:: Examples

   >>> x = ak.arange(5, 10)
   >>> y = ak.array([2, 1, 4, 5, 8])
   >>> ak.divmod(x,y)
   (array([2 6 1 1 1]), array([1 0 3 3 1]))
   >>> ak.divmod(x,y, x % 2 == 0)
   (array([5 6 7 1 9]), array([5 0 7 3 9]))


.. py:function:: dot(pda1: Union[numpy.int64, numpy.float64, numpy.uint64, pdarray], pda2: Union[numpy.int64, numpy.float64, numpy.uint64, pdarray]) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

   Returns the sum of the elementwise product of two arrays of the same size (the dot product) or
   the product of a singleton element and an array.

   :param pda1:
   :type pda1: Union[numeric_scalars, pdarray]
   :param pda2:
   :type pda2: Union[numeric_scalars, pdarray]

   :returns: The sum of the elementwise product pda1 and pda2 or
             the product of a singleton element and an array.
   :rtype: Union[numeric_scalars, pdarray]

   :raises ValueError: Raised if the size of pda1 is not the same as pda2

   .. rubric:: Examples

   >>> x = ak.array([2, 3])
   >>> y = ak.array([4, 5])
   >>> ak.dot(x,y)
   23
   >>> ak.dot(x,2)
   array([4 6])


.. py:function:: dtype(dtype)

   Create a data type object.

   :param dtype: Object to be converted to a data type object.
   :type dtype: object

   :rtype: type


.. py:function:: flip(x: Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, arkouda.categorical.Categorical], /, *, axis: Union[int, Tuple[int, Ellipsis], NoneType] = None) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, arkouda.categorical.Categorical]

   Reverse an array's values along a particular axis or axes.

   :param x: Reverse the order of elements in an array along the given axis.

             The shape of the array is preserved, but the elements are reordered.
   :type x: pdarray, Strings, or Categorical
   :param axis: The axis or axes along which to flip the array. If None, flip the array along all axes.
   :type axis: int or Tuple[int, ...], optional

   :returns: An array with the entries of axis reversed.
   :rtype: pdarray, Strings, or Categorical

   .. note:: This differs from numpy as it actually reverses the data, rather than presenting a view.


.. py:data:: float_scalars

.. py:function:: fmod(dividend: Union[pdarray, arkouda.numpy.dtypes.numeric_scalars], divisor: Union[pdarray, arkouda.numpy.dtypes.numeric_scalars]) -> pdarray

   Returns the element-wise remainder of division.

   It is equivalent to np.fmod, the remainder has the same sign as the dividend.

   :param dividend: The array being acted on by the bases for the modular division.
   :type dividend: numeric scalars or pdarray
   :param divisor: The array that will be the bases for the modular division.
   :type divisor: numeric scalars or pdarray

   :returns: an array that contains the element-wise remainder of division.
   :rtype: pdarray

   :raises TypeError: Raised if neither dividend nor divisor is a pdarray (at least one must be)
       or if any scalar or pdarray element is not one of int, uint, float, bigint


.. py:function:: from_series(series: pandas.Series, dtype: Optional[Union[type, str]] = None) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings]

   Converts a Pandas Series to an Arkouda pdarray or Strings object. If
   dtype is None, the dtype is inferred from the Pandas Series. Otherwise,
   the dtype parameter is set if the dtype of the Pandas Series is to be
   overridden or is  unknown (for example, in situations where the Series
   dtype is object).

   :param series: The Pandas Series with a dtype of bool, float64, int64, or string
   :type series: Pandas Series
   :param dtype: The valid dtype types are np.bool, np.float64, np.int64, and np.str
   :type dtype: Optional[type]

   :rtype: Union[pdarray,Strings]

   :raises TypeError: Raised if series is not a Pandas Series object
   :raises ValueError: Raised if the Series dtype is not bool, float64, int64, string, datetime, or timedelta

   .. rubric:: Examples

   >>> np.random.seed(1701)
   >>> ak.from_series(pd.Series(np.random.randint(0,10,5)))
   array([4 3 3 5 0])

   >>> ak.from_series(pd.Series(['1', '2', '3', '4', '5']),dtype=np.int64)
   array([1 2 3 4 5])

   >>> np.random.seed(1701)
   >>> ak.from_series(pd.Series(np.random.uniform(low=0.0,high=1.0,size=3)))
   array([0.089433234324597599 0.1153776854774361 0.51874393620990389])

   >>> ak.from_series(pd.Series(['0.57600036956445599', '0.41619265571741659',
                      '0.6615356693784662']), dtype=np.float64)
   array([0.57600036956445599 0.41619265571741659 0.6615356693784662])

   >>> np.random.seed(1864)
   >>> ak.from_series(pd.Series(np.random.choice([True, False],size=5)))
   array([True True True False False])

   >>> ak.from_series(pd.Series(['True', 'False', 'False', 'True', 'True']), dtype=bool)
   array([True True True True True])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e'], dtype="string"))
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01')])))
   array([1514764800000000000 1514764800000000000])

   .. rubric:: Notes

   The supported datatypes are bool, float64, int64, string, and datetime64[ns]. The
   data type is either inferred from the the Series or is set via the dtype parameter.

   Series of datetime or timedelta are converted to Arkouda arrays of dtype int64 (nanoseconds)

   A Pandas Series containing strings has a dtype of object. Arkouda assumes the Series
   contains strings and sets the dtype to str


.. py:function:: from_series(series: pandas.Series, dtype: Optional[Union[type, str]] = None) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings]

   Converts a Pandas Series to an Arkouda pdarray or Strings object. If
   dtype is None, the dtype is inferred from the Pandas Series. Otherwise,
   the dtype parameter is set if the dtype of the Pandas Series is to be
   overridden or is  unknown (for example, in situations where the Series
   dtype is object).

   :param series: The Pandas Series with a dtype of bool, float64, int64, or string
   :type series: Pandas Series
   :param dtype: The valid dtype types are np.bool, np.float64, np.int64, and np.str
   :type dtype: Optional[type]

   :rtype: Union[pdarray,Strings]

   :raises TypeError: Raised if series is not a Pandas Series object
   :raises ValueError: Raised if the Series dtype is not bool, float64, int64, string, datetime, or timedelta

   .. rubric:: Examples

   >>> np.random.seed(1701)
   >>> ak.from_series(pd.Series(np.random.randint(0,10,5)))
   array([4 3 3 5 0])

   >>> ak.from_series(pd.Series(['1', '2', '3', '4', '5']),dtype=np.int64)
   array([1 2 3 4 5])

   >>> np.random.seed(1701)
   >>> ak.from_series(pd.Series(np.random.uniform(low=0.0,high=1.0,size=3)))
   array([0.089433234324597599 0.1153776854774361 0.51874393620990389])

   >>> ak.from_series(pd.Series(['0.57600036956445599', '0.41619265571741659',
                      '0.6615356693784662']), dtype=np.float64)
   array([0.57600036956445599 0.41619265571741659 0.6615356693784662])

   >>> np.random.seed(1864)
   >>> ak.from_series(pd.Series(np.random.choice([True, False],size=5)))
   array([True True True False False])

   >>> ak.from_series(pd.Series(['True', 'False', 'False', 'True', 'True']), dtype=bool)
   array([True True True True True])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e'], dtype="string"))
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01')])))
   array([1514764800000000000 1514764800000000000])

   .. rubric:: Notes

   The supported datatypes are bool, float64, int64, string, and datetime64[ns]. The
   data type is either inferred from the the Series or is set via the dtype parameter.

   Series of datetime or timedelta are converted to Arkouda arrays of dtype int64 (nanoseconds)

   A Pandas Series containing strings has a dtype of object. Arkouda assumes the Series
   contains strings and sets the dtype to str


.. py:function:: full(size: Union[arkouda.numpy.dtypes.int_scalars, Tuple[arkouda.numpy.dtypes.int_scalars, Ellipsis], str], fill_value: Union[arkouda.numpy.dtypes.numeric_scalars, str], dtype: Union[numpy.dtype, type, str, arkouda.numpy.dtypes.bigint] = float64, max_bits: Optional[int] = None) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings]

   Create a pdarray filled with fill_value.

   :param size: Size or shape of the array
   :type size: int_scalars or tuple of int_scalars
   :param fill_value: Value with which the array will be filled
   :type fill_value: int_scalars or str
   :param dtype: Resulting array type, default float64
   :type dtype: all_scalars
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: array of the requested size and dtype filled with fill_value
   :rtype: pdarray or Strings

   :raises TypeError: Raised if the supplied dtype is not supported
   :raises RuntimeError: Raised if the size parameter is neither an int nor a str that is parseable to an int.
   :raises ValueError: Raised if the rank of the given shape is not in get_array_ranks() or is empty

   .. seealso:: :obj:`zeros`, :obj:`ones`

   .. rubric:: Examples

   >>> ak.full(5, 7, dtype=ak.int64)
   array([7 7 7 7 7])

   >>> ak.full(5, 9, dtype=ak.float64)
   array([9.00000000000000000 9.00000000000000000 9.00000000000000000
          9.00000000000000000 9.00000000000000000])

   >>> ak.full(5, 5, dtype=ak.bool_)
   array([True True True True True])


.. py:function:: full_like(pda: arkouda.numpy.pdarrayclass.pdarray, fill_value: arkouda.numpy.dtypes.numeric_scalars) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings]

   Create a pdarray filled with fill_value of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray
   :param fill_value: Value with which the array will be filled
   :type fill_value: int_scalars

   :returns: Equivalent to ak.full(pda.size, fill_value, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`ones_like`, :obj:`zeros_like`

   .. rubric:: Notes

   Logic for generating the pdarray is delegated to the ak.full method.
   Accordingly, the supported dtypes match are defined by the ak.full method.

   .. rubric:: Examples

   >>> ak.full_like(ak.full(5,7,dtype=ak.int64),6)
   array([6 6 6 6 6])

   >>> ak.full_like(ak.full(7,9,dtype=ak.float64),10)
   array([10.00000000000000000 10.00000000000000000 10.00000000000000000
          10.00000000000000000 10.00000000000000000 10.00000000000000000 10.00000000000000000])

   >>> ak.full_like(ak.full(5,True,dtype=ak.bool_),False)
   array([False False False False False])


.. py:function:: generic_msg(cmd: str, args: Optional[Dict] = None, payload: Optional[memoryview] = None, send_binary: bool = False, recv_binary: bool = False) -> Union[str, memoryview]

   Sends a binary or string message composed of a command and corresponding
   arguments to the arkouda_server, returning the response sent by the server.

   :param cmd: The server-side command to be executed
   :type cmd: str
   :param args: A space-delimited list of command arguments
   :type args: str
   :param payload: The payload when sending binary data
   :type payload: memoryview
   :param send_binary: Indicates if the message to be sent is a string or binary
   :type send_binary: bool
   :param recv_binary: Indicates if the return message will be a string or binary
   :type recv_binary: bool

   :returns: The string or binary return message
   :rtype: Union[str, memoryview]

   :raises KeyboardInterrupt: Raised if the user interrupts during command execution
   :raises RuntimeError: Raised if the client is not connected to the server or if
       there is a server-side error thrown

   .. rubric:: Notes

   If the server response is a string, the string corresponds to a success
   confirmation, warn message, or error message. A memoryview response
   corresponds to an Arkouda array output as a numpy array.


.. py:function:: getArkoudaLogger(name: str, handlers: Optional[List[logging.Handler]] = None, logFormat: Optional[str] = ArkoudaLogger.DEFAULT_LOG_FORMAT, logLevel: Optional[LogLevel] = None) -> ArkoudaLogger

   A convenience method for instantiating an ArkoudaLogger that retrieves the
   logging level from the ARKOUDA_LOG_LEVEL env variable

   :param name: The name of the ArkoudaLogger
   :type name: str
   :param handlers: A list of logging.Handler objects, if None, a list consisting of
                    one StreamHandler named 'console-handler' is generated and configured
   :type handlers: List[Handler]
   :param logFormat: The format for log messages, defaults to the following format:
                     '[%(name)s] Line %(lineno)d %(levelname)s: %(message)s'
   :type logFormat: str

   :rtype: ArkoudaLogger

   :raises TypeError: Raised if either name or logFormat is not a str object or if handlers
       is not a list of str objects

   .. rubric:: Notes

   Important note: if a list of 1..n logging.Handler objects is passed in, and
   dynamic changes to 1..n handlers is desired, set a name for each Handler
   object as follows: handler.name = <desired name>, which will enable retrieval
   and updates for the specified handler.


.. py:function:: get_byteorder(dt: numpy.dtype) -> str

   Get a concrete byteorder (turns '=' into '<' or '>') on the client.

   :param dt: The numpy dtype to determine the byteorder of.
   :type dt: np.dtype

   :returns: Returns "<" for little endian and ">" for big endian.
   :rtype: str

   :raises ValueError: Returned if sys.byteorder is not "little" or "big"

   .. rubric:: Examples

   >>> ak.get_byteorder(ak.dtype(ak.int64))
   '<'


.. py:function:: get_server_byteorder() -> str

   Get the server's byteorder

   :returns: Returns "little" for little endian and "big" for big endian.
   :rtype: str

   :raises ValueError: Raised if Server byteorder is not 'little' or 'big'

   .. rubric:: Examples

   >>> ak.get_server_byteorder()
   'little'


.. py:function:: in1d(A: arkouda.groupbyclass.groupable, B: arkouda.groupbyclass.groupable, assume_unique: bool = False, symmetric: bool = False, invert: bool = False) -> arkouda.groupbyclass.groupable

   Test whether each element of a 1-D array is also present in a second array.

   Returns a boolean array the same length as `A` that is True
   where an element of `A` is in `B` and False otherwise.

   Supports multi-level, i.e. test if rows of a are in the set of rows of b.
   But note that multi-dimensional pdarrays are not supported.

   :param A: Entries will be tested for membership in B
   :type A: list of pdarrays, pdarray, Strings, or Categorical
   :param B: The set of elements in which to test membership
   :type B: list of pdarrays, pdarray, Strings, or Categorical
   :param assume_unique: If true, assume rows of a and b are each unique and sorted.
                         By default, sort and unique them explicitly.
   :type assume_unique: bool, optional, defaults to False
   :param symmetric: Return in1d(A, B), in1d(B, A) when A and B are single items.
   :type symmetric: bool, optional, defaults to False
   :param invert: If True, the values in the returned array are inverted (that is,
                  False where an element of `A` is in `B` and True otherwise).
                  Default is False. ``ak.in1d(a, b, invert=True)`` is equivalent
                  to (but is faster than) ``~ak.in1d(a, b)``.
   :type invert: bool, optional, defaults to False

   :returns: True for each row in a that is contained in b
   :rtype: pdarray, bool

   :raises TypeError: Raised if either A or B is not a pdarray, Strings, or Categorical
       object, or if both are pdarrays and either has rank > 1,
       or if invert is not a bool
   :raises RuntimeError: Raised if the dtype of either array is not supported

   .. rubric:: Examples

   >>> ak.in1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([False True False])

   >>> ak.in1d(ak.array(['one','two']),ak.array(['two', 'three','four','five']))
   array([False True])

   .. seealso:: :obj:`arkouda.groupbyclass.unique`, :obj:`intersect1d`, :obj:`union1d`

   .. rubric:: Notes

   `in1d` can be considered as an element-wise function version of the
   python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
   equivalent to ``ak.array([item in b for item in a])``, but is much
   faster and scales to arbitrarily large ``a``.

   ak.in1d is not supported for bool or float64 pdarrays


.. py:function:: indexof1d(query: arkouda.groupbyclass.groupable, space: arkouda.groupbyclass.groupable) -> arkouda.numpy.pdarrayclass.pdarray

   Return indices of query items in a search list of items. Items not found will be excluded.
   When duplicate terms are present in search space return indices of all occurrences.

   :param query: The items to search for. If multiple arrays, each "row" is an item.
   :type query: (sequence of) pdarray or Strings or Categorical
   :param space: The set of items in which to search. Must have same shape/dtype as query.
   :type space: (sequence of) pdarray or Strings or Categorical

   :returns: **indices** -- For each item in query that is found in space, its index in space.
   :rtype: pdarray, int64

   .. rubric:: Notes

   This is an alias of
   `ak.find(query, space, all_occurrences=True, remove_missing=True).values`

   .. rubric:: Examples

   >>> select_from = ak.arange(10)
   >>> query = select_from[ak.randint(0, select_from.size, 20, seed=10)]
   >>> space = select_from[ak.randint(0, select_from.size, 20, seed=11)]

   remove some values to ensure that query has entries
   which don't appear in space

   >>> space = space[arr2 != 9]
   >>> space = space[arr2 != 3]

   >>> ak.indexof1d(query, space)
   array([0 4 1 3 10 2 6 12 13 5 7 8 9 14 5 7 11 15 5 7 0 4])

   :raises TypeError: Raised if either `query` or `space` is not a pdarray, Strings, or
       Categorical object
   :raises RuntimeError: Raised if the dtype of either array is not supported


.. py:data:: intTypes

.. py:data:: intTypes

.. py:data:: int_scalars

.. py:data:: int_scalars

.. py:data:: int_scalars

.. py:function:: intersect1d(A: arkouda.groupbyclass.groupable, B: arkouda.groupbyclass.groupable, assume_unique: bool = False) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.groupbyclass.groupable]

   Find the intersection of two arrays.

   Return the sorted, unique values that are in both of the input arrays.

   :param A:
   :type A: list of pdarrays, pdarray, Strings, or Categorical
   :param B:
   :type B: list of pdarrays, pdarray, Strings, or Categorical
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array/List of sorted pdarrays of common and unique elements.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either A or B is not a groupable
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. seealso:: :obj:`arkouda.groupbyclass.unique`, :obj:`union1d`

   .. rubric:: Examples

   1D Example

   >>> ak.intersect1d(ak.array([1, 3, 4, 3]), ak.array([3, 1, 2, 1]))
   array([1 3])

   Multi-Array Example

   >>> a = ak.arange(5)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.intersect1d(multia, multib)
   [array([1 3]), array([1 3]), array([1 3])]


.. py:function:: isSupportedBool(num)

   Whether a scalar is an arkouda supported boolean dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported boolean dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedBool(ak.int64)
   False
   >>> ak.isSupportedBool(bool)
   True


.. py:function:: isSupportedDType(scalar: object) -> bool

   Whether a scalar is an arkouda supported dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedDType(ak.int64)
   True
   >>> ak.isSupportedDType(np.complex128(1+2j))
   False


.. py:function:: isSupportedDType(scalar: object) -> bool

   Whether a scalar is an arkouda supported dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedDType(ak.int64)
   True
   >>> ak.isSupportedDType(np.complex128(1+2j))
   False


.. py:function:: isSupportedFloat(num)

   Whether a scalar is an arkouda supported float dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported float dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedFloat(ak.int64)
   False
   >>> ak.isSupportedFloat(ak.float64)
   True


.. py:function:: isSupportedInt(num)

   Whether a scalar is an arkouda supported integer dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported integer dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedInt(ak.int64)
   True
   >>> ak.isSupportedInt(ak.float64)
   False


.. py:function:: isSupportedInt(num)

   Whether a scalar is an arkouda supported integer dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported integer dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedInt(ak.int64)
   True
   >>> ak.isSupportedInt(ak.float64)
   False


.. py:function:: isSupportedInt(num)

   Whether a scalar is an arkouda supported integer dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported integer dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedInt(ak.int64)
   True
   >>> ak.isSupportedInt(ak.float64)
   False


.. py:function:: isSupportedNumber(num)

   Whether a scalar is an arkouda supported numeric dtype.

   :param scalar:
   :type scalar: object

   :returns: True if scalar is an instance of an arkouda supported numeric dtype, else False.
   :rtype: bool

   .. rubric:: Examples

   >>> ak.isSupportedNumber(ak.int64)
   True
   >>> ak.isSupportedNumber(ak.str_)
   False


.. py:function:: is_registered(name: str, as_component: bool = False) -> bool

   Determine if the name provided is associated with a registered Object

   :param name: The name to check for in the registry
   :type name: str
   :param as_component: When True, the name will be checked to determine if it is registered as a component of
                        a registered object
   :type as_component: bool, default=False

   :rtype: bool


.. py:function:: linspace(start: arkouda.numpy.dtypes.numeric_scalars, stop: arkouda.numpy.dtypes.numeric_scalars, length: arkouda.numpy.dtypes.int_scalars) -> arkouda.numpy.pdarrayclass.pdarray

   Create a pdarray of linearly-spaced floats in a closed interval.

   :param start: Start of interval (inclusive)
   :type start: numeric_scalars
   :param stop: End of interval (inclusive)
   :type stop: numeric_scalars
   :param length: Number of points
   :type length: int_scalars

   :returns: Array of evenly spaced float values along the interval
   :rtype: pdarray, float64

   :raises TypeError: Raised if start or stop is not a float or int or if length is not an int

   .. seealso:: :obj:`arange`

   .. rubric:: Notes

   If that start is greater than stop, the pdarray values are generated
   in descending order.

   .. rubric:: Examples

   >>> ak.linspace(0, 1, 5)
   array([0.00000000000000000 0.25 0.5 0.75 1.00000000000000000])

   >>> ak.linspace(start=1, stop=0, length=5)
   array([1.00000000000000000 0.75 0.5 0.25 0.00000000000000000])

   >>> ak.linspace(start=-5, stop=0, length=5)
   array([-5.00000000000000000 -3.75 -2.5 -1.25 0.00000000000000000])


.. py:function:: maxk(pda: pdarray, k: arkouda.numpy.dtypes.int_scalars) -> pdarray

   Find the `k` maximum values of an array.

   Returns the largest `k` values of an array, sorted

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of maximum values to be returned by the output.
   :type k: int_scalars

   :returns: The maximum `k` values from pda, sorted
   :rtype: pdarray, int

   :raises TypeError: Raised if pda is not a pdarray or k is not an integer
   :raises ValueError: Raised if the pda is empty, or pda.ndim > 1, or k < 1

   .. rubric:: Notes

   This call is equivalent in value to a[ak.argsort(a)[k:]]

   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degredation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.maxk(A, 3)
   array([7, 9, 10])
   >>> ak.maxk(A, 4)
   array([5, 7, 9, 10])


.. py:function:: mean(pda: pdarray) -> numpy.float64

   Return the mean of the array.

   :param pda: Values for which to calculate the mean
   :type pda: pdarray

   :returns: The mean calculated from the pda sum and size
   :rtype: np.float64

   .. rubric:: Examples

   >>> a = ak.arange(10)
   >>> ak.mean(a)
   4.5
   >>> a.mean()
   4.5

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: mink(pda: pdarray, k: arkouda.numpy.dtypes.int_scalars) -> pdarray

   Find the `k` minimum values of an array.

   Returns the smallest `k` values of an array, sorted

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of minimum values to be returned by the output.
   :type k: int_scalars

   :returns: The minimum `k` values from pda, sorted
   :rtype: pdarray

   :raises TypeError: Raised if pda is not a pdarray
   :raises ValueError: Raised if the pda is empty, or pda.ndim > 1, or k < 1

   .. rubric:: Notes

   This call is equivalent in value to a[ak.argsort(a)[:k]]
   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degredation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.mink(A, 3)
   array([0, 1, 2])
   >>> ak.mink(A, 4)
   array([0, 1, 2, 3])


.. py:function:: mod(dividend, divisor) -> pdarray

   Returns the element-wise remainder of division.

   Computes the remainder complementary to the floor_divide function.
   It is equivalent to np.mod, the remainder has the same sign as the divisor.

   :param dividend: pdarray : The numeric scalar or pdarray being acted on by the bases for the modular division.
   :param divisor: pdarray : The numeric scalar or pdarray that will be the bases for the modular division.

   :returns: an array that contains the element-wise remainder of division.
   :rtype: pdarray

   .. rubric:: Examples

   >>> a = ak.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])
   >>> b = ak.array([2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,7,7,7,8,8])
   >>> ak.mod(a,b)
   array([1 0 1 1 2 0 3 0 1 0 1 2 1 2 3 2 3 4 3 4])

   :raises ValueError: raised if shapes of dividend and divisor are incompatible


.. py:class:: ndarray

   ndarray(shape, dtype=float, buffer=None, offset=0,
               strides=None, order=None)

       An array object represents a multidimensional, homogeneous array
       of fixed-size items.  An associated data-type object describes the
       format of each element in the array (its byte-order, how many bytes it
       occupies in memory, whether it is an integer, a floating point number,
       or something else, etc.)

       Arrays should be constructed using `array`, `zeros` or `empty` (refer
       to the See Also section below).  The parameters given here refer to
       a low-level method (`ndarray(...)`) for instantiating an array.

       For more information, refer to the `numpy` module and examine the
       methods and attributes of an array.

       Parameters
       ----------
       (for the __new__ method; see Notes below)

       shape : tuple of ints
           Shape of created array.
       dtype : data-type, optional
           Any object that can be interpreted as a numpy data type.
       buffer : object exposing buffer interface, optional
           Used to fill the array with data.
       offset : int, optional
           Offset of array data in buffer.
       strides : tuple of ints, optional
           Strides of data in memory.
       order : {'C', 'F'}, optional
           Row-major (C-style) or column-major (Fortran-style) order.

       Attributes
       ----------
       T : ndarray
           Transpose of the array.
       data : buffer
           The array's elements, in memory.
       dtype : dtype object
           Describes the format of the elements in the array.
       flags : dict
           Dictionary containing information related to memory use, e.g.,
           'C_CONTIGUOUS', 'OWNDATA', 'WRITEABLE', etc.
       flat : numpy.flatiter object
           Flattened version of the array as an iterator.  The iterator
           allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for
           assignment examples; TODO).
       imag : ndarray
           Imaginary part of the array.
       real : ndarray
           Real part of the array.
       size : int
           Number of elements in the array.
       itemsize : int
           The memory use of each array element in bytes.
       nbytes : int
           The total number of bytes required to store the array data,
           i.e., ``itemsize * size``.
       ndim : int
           The array's number of dimensions.
       shape : tuple of ints
           Shape of the array.
       strides : tuple of ints
           The step-size required to move from one element to the next in
           memory. For example, a contiguous ``(3, 4)`` array of type
           ``int16`` in C-order has strides ``(8, 2)``.  This implies that
           to move from element to element in memory requires jumps of 2 bytes.
           To move from row-to-row, one needs to jump 8 bytes at a time
           (``2 * 4``).
       ctypes : ctypes object
           Class containing properties of the array needed for interaction
           with ctypes.
       base : ndarray
           If the array is a view into another array, that array is its `base`
           (unless that array is also a view).  The `base` array is where the
           array data is actually stored.

       See Also
       --------
       array : Construct an array.
       zeros : Create an array, each element of which is zero.
       empty : Create an array, but leave its allocated memory unchanged (i.e.,
               it contains "garbage").
       dtype : Create a data-type.
       numpy.typing.NDArray : An ndarray alias :term:`generic <generic type>`
                              w.r.t. its `dtype.type <numpy.dtype.type>`.

       Notes
       -----
       There are two modes of creating an array using ``__new__``:

       1. If `buffer` is None, then only `shape`, `dtype`, and `order`
          are used.
       2. If `buffer` is an object exposing the buffer interface, then
          all keywords are interpreted.

       No ``__init__`` method is needed because the array is fully initialized
       after the ``__new__`` method.

       Examples
       --------
       These examples illustrate the low-level `ndarray` constructor.  Refer
       to the `See Also` section above for easier ways of constructing an
       ndarray.

       First mode, `buffer` is None:

       >>> np.ndarray(shape=(2,2), dtype=float, order='F')
       array([[0.0e+000, 0.0e+000], # random
              [     nan, 2.5e-323]])

       Second mode:

       >>> np.ndarray((2,), buffer=np.array([1,2,3]),
       ...            offset=np.int_().itemsize,
       ...            dtype=int) # offset = 1*itemsize, i.e. skip first element
       array([2, 3])



   .. py:method:: T(*args, **kwargs)

      View of the transposed array.

          Same as ``self.transpose()``.

          Examples
          --------
          >>> a = np.array([[1, 2], [3, 4]])
          >>> a
          array([[1, 2],
                 [3, 4]])
          >>> a.T
          array([[1, 3],
                 [2, 4]])

          >>> a = np.array([1, 2, 3, 4])
          >>> a
          array([1, 2, 3, 4])
          >>> a.T
          array([1, 2, 3, 4])

          See Also
          --------
          transpose




   .. py:method:: all(*args, **kwargs)

      a.all(axis=None, out=None, keepdims=False, *, where=True)

          Returns True if all elements evaluate to True.

          Refer to `numpy.all` for full documentation.

          See Also
          --------
          numpy.all : equivalent function




   .. py:method:: any(*args, **kwargs)

      a.any(axis=None, out=None, keepdims=False, *, where=True)

          Returns True if any of the elements of `a` evaluate to True.

          Refer to `numpy.any` for full documentation.

          See Also
          --------
          numpy.any : equivalent function




   .. py:method:: argmax(*args, **kwargs)

      a.argmax(axis=None, out=None, *, keepdims=False)

          Return indices of the maximum values along the given axis.

          Refer to `numpy.argmax` for full documentation.

          See Also
          --------
          numpy.argmax : equivalent function




   .. py:method:: argmin(*args, **kwargs)

      a.argmin(axis=None, out=None, *, keepdims=False)

          Return indices of the minimum values along the given axis.

          Refer to `numpy.argmin` for detailed documentation.

          See Also
          --------
          numpy.argmin : equivalent function




   .. py:method:: argpartition(*args, **kwargs)

      a.argpartition(kth, axis=-1, kind='introselect', order=None)

          Returns the indices that would partition this array.

          Refer to `numpy.argpartition` for full documentation.

          .. versionadded:: 1.8.0

          See Also
          --------
          numpy.argpartition : equivalent function




   .. py:method:: argsort(*args, **kwargs)

      a.argsort(axis=-1, kind=None, order=None)

          Returns the indices that would sort this array.

          Refer to `numpy.argsort` for full documentation.

          See Also
          --------
          numpy.argsort : equivalent function




   .. py:method:: astype(*args, **kwargs)

      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)

          Copy of the array, cast to a specified type.

          Parameters
          ----------
          dtype : str or dtype
              Typecode or data-type to which the array is cast.
          order : {'C', 'F', 'A', 'K'}, optional
              Controls the memory layout order of the result.
              'C' means C order, 'F' means Fortran order, 'A'
              means 'F' order if all the arrays are Fortran contiguous,
              'C' order otherwise, and 'K' means as close to the
              order the array elements appear in memory as possible.
              Default is 'K'.
          casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
              Controls what kind of data casting may occur. Defaults to 'unsafe'
              for backwards compatibility.

                * 'no' means the data types should not be cast at all.
                * 'equiv' means only byte-order changes are allowed.
                * 'safe' means only casts which can preserve values are allowed.
                * 'same_kind' means only safe casts or casts within a kind,
                  like float64 to float32, are allowed.
                * 'unsafe' means any data conversions may be done.
          subok : bool, optional
              If True, then sub-classes will be passed-through (default), otherwise
              the returned array will be forced to be a base-class array.
          copy : bool, optional
              By default, astype always returns a newly allocated array. If this
              is set to false, and the `dtype`, `order`, and `subok`
              requirements are satisfied, the input array is returned instead
              of a copy.

          Returns
          -------
          arr_t : ndarray
              Unless `copy` is False and the other conditions for returning the input
              array are satisfied (see description for `copy` input parameter), `arr_t`
              is a new array of the same shape as the input array, with dtype, order
              given by `dtype`, `order`.

          Notes
          -----
          .. versionchanged:: 1.17.0
             Casting between a simple data type and a structured one is possible only
             for "unsafe" casting.  Casting to multiple fields is allowed, but
             casting from multiple fields is not.

          .. versionchanged:: 1.9.0
             Casting from numeric to string types in 'safe' casting mode requires
             that the string dtype length is long enough to store the max
             integer/float value converted.

          Raises
          ------
          ComplexWarning
              When casting from complex to float or int. To avoid this,
              one should use ``a.real.astype(t)``.

          Examples
          --------
          >>> x = np.array([1, 2, 2.5])
          >>> x
          array([1. ,  2. ,  2.5])

          >>> x.astype(int)
          array([1, 2, 2])




   .. py:method:: base(*args, **kwargs)

      Base object if memory is from some other object.

          Examples
          --------
          The base of an array that owns its memory is None:

          >>> x = np.array([1,2,3,4])
          >>> x.base is None
          True

          Slicing creates a view, whose memory is shared with x:

          >>> y = x[2:]
          >>> y.base is x
          True




   .. py:method:: byteswap(*args, **kwargs)

      a.byteswap(inplace=False)

          Swap the bytes of the array elements

          Toggle between low-endian and big-endian data representation by
          returning a byteswapped array, optionally swapped in-place.
          Arrays of byte-strings are not swapped. The real and imaginary
          parts of a complex number are swapped individually.

          Parameters
          ----------
          inplace : bool, optional
              If ``True``, swap bytes in-place, default is ``False``.

          Returns
          -------
          out : ndarray
              The byteswapped array. If `inplace` is ``True``, this is
              a view to self.

          Examples
          --------
          >>> A = np.array([1, 256, 8755], dtype=np.int16)
          >>> list(map(hex, A))
          ['0x1', '0x100', '0x2233']
          >>> A.byteswap(inplace=True)
          array([  256,     1, 13090], dtype=int16)
          >>> list(map(hex, A))
          ['0x100', '0x1', '0x3322']

          Arrays of byte-strings are not swapped

          >>> A = np.array([b'ceg', b'fac'])
          >>> A.byteswap()
          array([b'ceg', b'fac'], dtype='|S3')

          ``A.newbyteorder().byteswap()`` produces an array with the same values
            but different representation in memory

          >>> A = np.array([1, 2, 3])
          >>> A.view(np.uint8)
          array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,
                 0, 0], dtype=uint8)
          >>> A.newbyteorder().byteswap(inplace=True)
          array([1, 2, 3])
          >>> A.view(np.uint8)
          array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,
                 0, 3], dtype=uint8)




   .. py:method:: choose(*args, **kwargs)

      a.choose(choices, out=None, mode='raise')

          Use an index array to construct a new array from a set of choices.

          Refer to `numpy.choose` for full documentation.

          See Also
          --------
          numpy.choose : equivalent function




   .. py:method:: clip(*args, **kwargs)

      a.clip(min=None, max=None, out=None, **kwargs)

          Return an array whose values are limited to ``[min, max]``.
          One of max or min must be given.

          Refer to `numpy.clip` for full documentation.

          See Also
          --------
          numpy.clip : equivalent function




   .. py:method:: compress(*args, **kwargs)

      a.compress(condition, axis=None, out=None)

          Return selected slices of this array along given axis.

          Refer to `numpy.compress` for full documentation.

          See Also
          --------
          numpy.compress : equivalent function




   .. py:method:: conj(*args, **kwargs)

      a.conj()

          Complex-conjugate all elements.

          Refer to `numpy.conjugate` for full documentation.

          See Also
          --------
          numpy.conjugate : equivalent function




   .. py:method:: conjugate(*args, **kwargs)

      a.conjugate()

          Return the complex conjugate, element-wise.

          Refer to `numpy.conjugate` for full documentation.

          See Also
          --------
          numpy.conjugate : equivalent function




   .. py:method:: copy(*args, **kwargs)

      a.copy(order='C')

          Return a copy of the array.

          Parameters
          ----------
          order : {'C', 'F', 'A', 'K'}, optional
              Controls the memory layout of the copy. 'C' means C-order,
              'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
              'C' otherwise. 'K' means match the layout of `a` as closely
              as possible. (Note that this function and :func:`numpy.copy` are very
              similar but have different default values for their order=
              arguments, and this function always passes sub-classes through.)

          See also
          --------
          numpy.copy : Similar function with different default behavior
          numpy.copyto

          Notes
          -----
          This function is the preferred method for creating an array copy.  The
          function :func:`numpy.copy` is similar, but it defaults to using order 'K',
          and will not pass sub-classes through by default.

          Examples
          --------
          >>> x = np.array([[1,2,3],[4,5,6]], order='F')

          >>> y = x.copy()

          >>> x.fill(0)

          >>> x
          array([[0, 0, 0],
                 [0, 0, 0]])

          >>> y
          array([[1, 2, 3],
                 [4, 5, 6]])

          >>> y.flags['C_CONTIGUOUS']
          True




   .. py:method:: ctypes(*args, **kwargs)

      An object to simplify the interaction of the array with the ctypes
          module.

          This attribute creates an object that makes it easier to use arrays
          when calling shared libraries with the ctypes module. The returned
          object has, among others, data, shape, and strides attributes (see
          Notes below) which themselves return ctypes objects that can be used
          as arguments to a shared library.

          Parameters
          ----------
          None

          Returns
          -------
          c : Python object
              Possessing attributes data, shape, strides, etc.

          See Also
          --------
          numpy.ctypeslib

          Notes
          -----
          Below are the public attributes of this object which were documented
          in "Guide to NumPy" (we have omitted undocumented public attributes,
          as well as documented private attributes):

          .. autoattribute:: numpy.core._internal._ctypes.data
              :noindex:

          .. autoattribute:: numpy.core._internal._ctypes.shape
              :noindex:

          .. autoattribute:: numpy.core._internal._ctypes.strides
              :noindex:

          .. automethod:: numpy.core._internal._ctypes.data_as
              :noindex:

          .. automethod:: numpy.core._internal._ctypes.shape_as
              :noindex:

          .. automethod:: numpy.core._internal._ctypes.strides_as
              :noindex:

          If the ctypes module is not available, then the ctypes attribute
          of array objects still returns something useful, but ctypes objects
          are not returned and errors may be raised instead. In particular,
          the object will still have the ``as_parameter`` attribute which will
          return an integer equal to the data attribute.

          Examples
          --------
          >>> import ctypes
          >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32)
          >>> x
          array([[0, 1],
                 [2, 3]], dtype=int32)
          >>> x.ctypes.data
          31962608 # may vary
          >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32))
          <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary
          >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents
          c_uint(0)
          >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents
          c_ulong(4294967296)
          >>> x.ctypes.shape
          <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary
          >>> x.ctypes.strides
          <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary




   .. py:method:: cumprod(*args, **kwargs)

      a.cumprod(axis=None, dtype=None, out=None)

          Return the cumulative product of the elements along the given axis.

          Refer to `numpy.cumprod` for full documentation.

          See Also
          --------
          numpy.cumprod : equivalent function




   .. py:method:: cumsum(*args, **kwargs)

      a.cumsum(axis=None, dtype=None, out=None)

          Return the cumulative sum of the elements along the given axis.

          Refer to `numpy.cumsum` for full documentation.

          See Also
          --------
          numpy.cumsum : equivalent function




   .. py:method:: data(*args, **kwargs)

      Python buffer object pointing to the start of the array's data.




   .. py:method:: diagonal(*args, **kwargs)

      a.diagonal(offset=0, axis1=0, axis2=1)

          Return specified diagonals. In NumPy 1.9 the returned array is a
          read-only view instead of a copy as in previous NumPy versions.  In
          a future version the read-only restriction will be removed.

          Refer to :func:`numpy.diagonal` for full documentation.

          See Also
          --------
          numpy.diagonal : equivalent function




   .. py:method:: dot(*args, **kwargs)


   .. py:method:: dtype(*args, **kwargs)

      Data-type of the array's elements.

          .. warning::

              Setting ``arr.dtype`` is discouraged and may be deprecated in the
              future.  Setting will replace the ``dtype`` without modifying the
              memory (see also `ndarray.view` and `ndarray.astype`).

          Parameters
          ----------
          None

          Returns
          -------
          d : numpy dtype object

          See Also
          --------
          ndarray.astype : Cast the values contained in the array to a new data-type.
          ndarray.view : Create a view of the same data but a different data-type.
          numpy.dtype

          Examples
          --------
          >>> x
          array([[0, 1],
                 [2, 3]])
          >>> x.dtype
          dtype('int32')
          >>> type(x.dtype)
          <type 'numpy.dtype'>




   .. py:method:: dump(*args, **kwargs)

      a.dump(file)

          Dump a pickle of the array to the specified file.
          The array can be read back with pickle.load or numpy.load.

          Parameters
          ----------
          file : str or Path
              A string naming the dump file.

              .. versionchanged:: 1.17.0
                  `pathlib.Path` objects are now accepted.




   .. py:method:: dumps(*args, **kwargs)

      a.dumps()

          Returns the pickle of the array as a string.
          pickle.loads will convert the string back to an array.

          Parameters
          ----------
          None




   .. py:method:: fill(*args, **kwargs)

      a.fill(value)

          Fill the array with a scalar value.

          Parameters
          ----------
          value : scalar
              All elements of `a` will be assigned this value.

          Examples
          --------
          >>> a = np.array([1, 2])
          >>> a.fill(0)
          >>> a
          array([0, 0])
          >>> a = np.empty(2)
          >>> a.fill(1)
          >>> a
          array([1.,  1.])

          Fill expects a scalar value and always behaves the same as assigning
          to a single array element.  The following is a rare example where this
          distinction is important:

          >>> a = np.array([None, None], dtype=object)
          >>> a[0] = np.array(3)
          >>> a
          array([array(3), None], dtype=object)
          >>> a.fill(np.array(3))
          >>> a
          array([array(3), array(3)], dtype=object)

          Where other forms of assignments will unpack the array being assigned:

          >>> a[...] = np.array(3)
          >>> a
          array([3, 3], dtype=object)




   .. py:method:: flags(*args, **kwargs)

      Information about the memory layout of the array.

          Attributes
          ----------
          C_CONTIGUOUS (C)
              The data is in a single, C-style contiguous segment.
          F_CONTIGUOUS (F)
              The data is in a single, Fortran-style contiguous segment.
          OWNDATA (O)
              The array owns the memory it uses or borrows it from another object.
          WRITEABLE (W)
              The data area can be written to.  Setting this to False locks
              the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE
              from its base array at creation time, but a view of a writeable
              array may be subsequently locked while the base array remains writeable.
              (The opposite is not true, in that a view of a locked array may not
              be made writeable.  However, currently, locking a base object does not
              lock any views that already reference it, so under that circumstance it
              is possible to alter the contents of a locked array via a previously
              created writeable view onto it.)  Attempting to change a non-writeable
              array raises a RuntimeError exception.
          ALIGNED (A)
              The data and all elements are aligned appropriately for the hardware.
          WRITEBACKIFCOPY (X)
              This array is a copy of some other array. The C-API function
              PyArray_ResolveWritebackIfCopy must be called before deallocating
              to the base array will be updated with the contents of this array.
          FNC
              F_CONTIGUOUS and not C_CONTIGUOUS.
          FORC
              F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).
          BEHAVED (B)
              ALIGNED and WRITEABLE.
          CARRAY (CA)
              BEHAVED and C_CONTIGUOUS.
          FARRAY (FA)
              BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.

          Notes
          -----
          The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),
          or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag
          names are only supported in dictionary access.

          Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED flags can be
          changed by the user, via direct assignment to the attribute or dictionary
          entry, or by calling `ndarray.setflags`.

          The array flags cannot be set arbitrarily:

          - WRITEBACKIFCOPY can only be set ``False``.
          - ALIGNED can only be set ``True`` if the data is truly aligned.
          - WRITEABLE can only be set ``True`` if the array owns its own memory
            or the ultimate owner of the memory exposes a writeable buffer
            interface or is a string.

          Arrays can be both C-style and Fortran-style contiguous simultaneously.
          This is clear for 1-dimensional arrays, but can also be true for higher
          dimensional arrays.

          Even for contiguous arrays a stride for a given dimension
          ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``
          or the array has no elements.
          It does *not* generally hold that ``self.strides[-1] == self.itemsize``
          for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for
          Fortran-style contiguous arrays is true.




   .. py:method:: flat(*args, **kwargs)

      A 1-D iterator over the array.

          This is a `numpy.flatiter` instance, which acts similarly to, but is not
          a subclass of, Python's built-in iterator object.

          See Also
          --------
          flatten : Return a copy of the array collapsed into one dimension.

          flatiter

          Examples
          --------
          >>> x = np.arange(1, 7).reshape(2, 3)
          >>> x
          array([[1, 2, 3],
                 [4, 5, 6]])
          >>> x.flat[3]
          4
          >>> x.T
          array([[1, 4],
                 [2, 5],
                 [3, 6]])
          >>> x.T.flat[3]
          5
          >>> type(x.flat)
          <class 'numpy.flatiter'>

          An assignment example:

          >>> x.flat = 3; x
          array([[3, 3, 3],
                 [3, 3, 3]])
          >>> x.flat[[1,4]] = 1; x
          array([[3, 1, 3],
                 [3, 1, 3]])




   .. py:method:: flatten(*args, **kwargs)

      a.flatten(order='C')

          Return a copy of the array collapsed into one dimension.

          Parameters
          ----------
          order : {'C', 'F', 'A', 'K'}, optional
              'C' means to flatten in row-major (C-style) order.
              'F' means to flatten in column-major (Fortran-
              style) order. 'A' means to flatten in column-major
              order if `a` is Fortran *contiguous* in memory,
              row-major order otherwise. 'K' means to flatten
              `a` in the order the elements occur in memory.
              The default is 'C'.

          Returns
          -------
          y : ndarray
              A copy of the input array, flattened to one dimension.

          See Also
          --------
          ravel : Return a flattened array.
          flat : A 1-D flat iterator over the array.

          Examples
          --------
          >>> a = np.array([[1,2], [3,4]])
          >>> a.flatten()
          array([1, 2, 3, 4])
          >>> a.flatten('F')
          array([1, 3, 2, 4])




   .. py:method:: getfield(*args, **kwargs)

      a.getfield(dtype, offset=0)

          Returns a field of the given array as a certain type.

          A field is a view of the array data with a given data-type. The values in
          the view are determined by the given type and the offset into the current
          array in bytes. The offset needs to be such that the view dtype fits in the
          array dtype; for example an array of dtype complex128 has 16-byte elements.
          If taking a view with a 32-bit integer (4 bytes), the offset needs to be
          between 0 and 12 bytes.

          Parameters
          ----------
          dtype : str or dtype
              The data type of the view. The dtype size of the view can not be larger
              than that of the array itself.
          offset : int
              Number of bytes to skip before beginning the element view.

          Examples
          --------
          >>> x = np.diag([1.+1.j]*2)
          >>> x[1, 1] = 2 + 4.j
          >>> x
          array([[1.+1.j,  0.+0.j],
                 [0.+0.j,  2.+4.j]])
          >>> x.getfield(np.float64)
          array([[1.,  0.],
                 [0.,  2.]])

          By choosing an offset of 8 bytes we can select the complex part of the
          array for our view:

          >>> x.getfield(np.float64, offset=8)
          array([[1.,  0.],
                 [0.,  4.]])




   .. py:method:: imag(*args, **kwargs)

      The imaginary part of the array.

          Examples
          --------
          >>> x = np.sqrt([1+0j, 0+1j])
          >>> x.imag
          array([ 0.        ,  0.70710678])
          >>> x.imag.dtype
          dtype('float64')




   .. py:method:: item(*args, **kwargs)

      a.item(*args)

          Copy an element of an array to a standard Python scalar and return it.

          Parameters
          ----------
          \*args : Arguments (variable number and type)

              * none: in this case, the method only works for arrays
                with one element (`a.size == 1`), which element is
                copied into a standard Python scalar object and returned.

              * int_type: this argument is interpreted as a flat index into
                the array, specifying which element to copy and return.

              * tuple of int_types: functions as does a single int_type argument,
                except that the argument is interpreted as an nd-index into the
                array.

          Returns
          -------
          z : Standard Python scalar object
              A copy of the specified element of the array as a suitable
              Python scalar

          Notes
          -----
          When the data type of `a` is longdouble or clongdouble, item() returns
          a scalar array object because there is no available Python scalar that
          would not lose information. Void arrays return a buffer object for item(),
          unless fields are defined, in which case a tuple is returned.

          `item` is very similar to a[args], except, instead of an array scalar,
          a standard Python scalar is returned. This can be useful for speeding up
          access to elements of the array and doing arithmetic on elements of the
          array using Python's optimized math.

          Examples
          --------
          >>> np.random.seed(123)
          >>> x = np.random.randint(9, size=(3, 3))
          >>> x
          array([[2, 2, 6],
                 [1, 3, 6],
                 [1, 0, 1]])
          >>> x.item(3)
          1
          >>> x.item(7)
          0
          >>> x.item((0, 1))
          2
          >>> x.item((2, 2))
          1




   .. py:method:: itemset(*args, **kwargs)

      a.itemset(*args)

          Insert scalar into an array (scalar is cast to array's dtype, if possible)

          There must be at least 1 argument, and define the last argument
          as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster
          than ``a[args] = item``.  The item should be a scalar value and `args`
          must select a single item in the array `a`.

          Parameters
          ----------
          \*args : Arguments
              If one argument: a scalar, only used in case `a` is of size 1.
              If two arguments: the last argument is the value to be set
              and must be a scalar, the first argument specifies a single array
              element location. It is either an int or a tuple.

          Notes
          -----
          Compared to indexing syntax, `itemset` provides some speed increase
          for placing a scalar into a particular location in an `ndarray`,
          if you must do this.  However, generally this is discouraged:
          among other problems, it complicates the appearance of the code.
          Also, when using `itemset` (and `item`) inside a loop, be sure
          to assign the methods to a local variable to avoid the attribute
          look-up at each loop iteration.

          Examples
          --------
          >>> np.random.seed(123)
          >>> x = np.random.randint(9, size=(3, 3))
          >>> x
          array([[2, 2, 6],
                 [1, 3, 6],
                 [1, 0, 1]])
          >>> x.itemset(4, 0)
          >>> x.itemset((2, 2), 9)
          >>> x
          array([[2, 2, 6],
                 [1, 0, 6],
                 [1, 0, 9]])




   .. py:method:: itemsize(*args, **kwargs)

      Length of one array element in bytes.

          Examples
          --------
          >>> x = np.array([1,2,3], dtype=np.float64)
          >>> x.itemsize
          8
          >>> x = np.array([1,2,3], dtype=np.complex128)
          >>> x.itemsize
          16




   .. py:method:: max(*args, **kwargs)

      a.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True)

          Return the maximum along a given axis.

          Refer to `numpy.amax` for full documentation.

          See Also
          --------
          numpy.amax : equivalent function




   .. py:method:: mean(*args, **kwargs)

      a.mean(axis=None, dtype=None, out=None, keepdims=False, *, where=True)

          Returns the average of the array elements along given axis.

          Refer to `numpy.mean` for full documentation.

          See Also
          --------
          numpy.mean : equivalent function




   .. py:method:: min(*args, **kwargs)

      a.min(axis=None, out=None, keepdims=False, initial=<no value>, where=True)

          Return the minimum along a given axis.

          Refer to `numpy.amin` for full documentation.

          See Also
          --------
          numpy.amin : equivalent function




   .. py:method:: nbytes(*args, **kwargs)

      Total bytes consumed by the elements of the array.

          Notes
          -----
          Does not include memory consumed by non-element attributes of the
          array object.

          See Also
          --------
          sys.getsizeof
              Memory consumed by the object itself without parents in case view.
              This does include memory consumed by non-element attributes.

          Examples
          --------
          >>> x = np.zeros((3,5,2), dtype=np.complex128)
          >>> x.nbytes
          480
          >>> np.prod(x.shape) * x.itemsize
          480




   .. py:method:: ndim(*args, **kwargs)

      Number of array dimensions.

          Examples
          --------
          >>> x = np.array([1, 2, 3])
          >>> x.ndim
          1
          >>> y = np.zeros((2, 3, 4))
          >>> y.ndim
          3




   .. py:method:: newbyteorder(*args, **kwargs)

      arr.newbyteorder(new_order='S', /)

          Return the array with the same data viewed with a different byte order.

          Equivalent to::

              arr.view(arr.dtype.newbytorder(new_order))

          Changes are also made in all fields and sub-arrays of the array data
          type.



          Parameters
          ----------
          new_order : string, optional
              Byte order to force; a value from the byte order specifications
              below. `new_order` codes can be any of:

              * 'S' - swap dtype from current to opposite endian
              * {'<', 'little'} - little endian
              * {'>', 'big'} - big endian
              * {'=', 'native'} - native order, equivalent to `sys.byteorder`
              * {'|', 'I'} - ignore (no change to byte order)

              The default value ('S') results in swapping the current
              byte order.


          Returns
          -------
          new_arr : array
              New array object with the dtype reflecting given change to the
              byte order.




   .. py:method:: nonzero(*args, **kwargs)

      a.nonzero()

          Return the indices of the elements that are non-zero.

          Refer to `numpy.nonzero` for full documentation.

          See Also
          --------
          numpy.nonzero : equivalent function




   .. py:method:: partition(*args, **kwargs)

      a.partition(kth, axis=-1, kind='introselect', order=None)

          Rearranges the elements in the array in such a way that the value of the
          element in kth position is in the position it would be in a sorted array.
          All elements smaller than the kth element are moved before this element and
          all equal or greater are moved behind it. The ordering of the elements in
          the two partitions is undefined.

          .. versionadded:: 1.8.0

          Parameters
          ----------
          kth : int or sequence of ints
              Element index to partition by. The kth element value will be in its
              final sorted position and all smaller elements will be moved before it
              and all equal or greater elements behind it.
              The order of all elements in the partitions is undefined.
              If provided with a sequence of kth it will partition all elements
              indexed by kth of them into their sorted position at once.

              .. deprecated:: 1.22.0
                  Passing booleans as index is deprecated.
          axis : int, optional
              Axis along which to sort. Default is -1, which means sort along the
              last axis.
          kind : {'introselect'}, optional
              Selection algorithm. Default is 'introselect'.
          order : str or list of str, optional
              When `a` is an array with fields defined, this argument specifies
              which fields to compare first, second, etc. A single field can
              be specified as a string, and not all fields need to be specified,
              but unspecified fields will still be used, in the order in which
              they come up in the dtype, to break ties.

          See Also
          --------
          numpy.partition : Return a partitioned copy of an array.
          argpartition : Indirect partition.
          sort : Full sort.

          Notes
          -----
          See ``np.partition`` for notes on the different algorithms.

          Examples
          --------
          >>> a = np.array([3, 4, 2, 1])
          >>> a.partition(3)
          >>> a
          array([2, 1, 3, 4])

          >>> a.partition((1, 3))
          >>> a
          array([1, 2, 3, 4])




   .. py:method:: prod(*args, **kwargs)

      a.prod(axis=None, dtype=None, out=None, keepdims=False, initial=1, where=True)

          Return the product of the array elements over the given axis

          Refer to `numpy.prod` for full documentation.

          See Also
          --------
          numpy.prod : equivalent function




   .. py:method:: ptp(*args, **kwargs)

      a.ptp(axis=None, out=None, keepdims=False)

          Peak to peak (maximum - minimum) value along a given axis.

          Refer to `numpy.ptp` for full documentation.

          See Also
          --------
          numpy.ptp : equivalent function




   .. py:method:: put(*args, **kwargs)

      a.put(indices, values, mode='raise')

          Set ``a.flat[n] = values[n]`` for all `n` in indices.

          Refer to `numpy.put` for full documentation.

          See Also
          --------
          numpy.put : equivalent function




   .. py:method:: ravel(*args, **kwargs)

      a.ravel([order])

          Return a flattened array.

          Refer to `numpy.ravel` for full documentation.

          See Also
          --------
          numpy.ravel : equivalent function

          ndarray.flat : a flat iterator on the array.




   .. py:method:: real(*args, **kwargs)

      The real part of the array.

          Examples
          --------
          >>> x = np.sqrt([1+0j, 0+1j])
          >>> x.real
          array([ 1.        ,  0.70710678])
          >>> x.real.dtype
          dtype('float64')

          See Also
          --------
          numpy.real : equivalent function




   .. py:method:: repeat(*args, **kwargs)

      a.repeat(repeats, axis=None)

          Repeat elements of an array.

          Refer to `numpy.repeat` for full documentation.

          See Also
          --------
          numpy.repeat : equivalent function




   .. py:method:: reshape(*args, **kwargs)

      a.reshape(shape, order='C')

          Returns an array containing the same data with a new shape.

          Refer to `numpy.reshape` for full documentation.

          See Also
          --------
          numpy.reshape : equivalent function

          Notes
          -----
          Unlike the free function `numpy.reshape`, this method on `ndarray` allows
          the elements of the shape parameter to be passed in as separate arguments.
          For example, ``a.reshape(10, 11)`` is equivalent to
          ``a.reshape((10, 11))``.




   .. py:method:: resize(*args, **kwargs)

      a.resize(new_shape, refcheck=True)

          Change shape and size of array in-place.

          Parameters
          ----------
          new_shape : tuple of ints, or `n` ints
              Shape of resized array.
          refcheck : bool, optional
              If False, reference count will not be checked. Default is True.

          Returns
          -------
          None

          Raises
          ------
          ValueError
              If `a` does not own its own data or references or views to it exist,
              and the data memory must be changed.
              PyPy only: will always raise if the data memory must be changed, since
              there is no reliable way to determine if references or views to it
              exist.

          SystemError
              If the `order` keyword argument is specified. This behaviour is a
              bug in NumPy.

          See Also
          --------
          resize : Return a new array with the specified shape.

          Notes
          -----
          This reallocates space for the data area if necessary.

          Only contiguous arrays (data elements consecutive in memory) can be
          resized.

          The purpose of the reference count check is to make sure you
          do not use this array as a buffer for another Python object and then
          reallocate the memory. However, reference counts can increase in
          other ways so if you are sure that you have not shared the memory
          for this array with another Python object, then you may safely set
          `refcheck` to False.

          Examples
          --------
          Shrinking an array: array is flattened (in the order that the data are
          stored in memory), resized, and reshaped:

          >>> a = np.array([[0, 1], [2, 3]], order='C')
          >>> a.resize((2, 1))
          >>> a
          array([[0],
                 [1]])

          >>> a = np.array([[0, 1], [2, 3]], order='F')
          >>> a.resize((2, 1))
          >>> a
          array([[0],
                 [2]])

          Enlarging an array: as above, but missing entries are filled with zeros:

          >>> b = np.array([[0, 1], [2, 3]])
          >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple
          >>> b
          array([[0, 1, 2],
                 [3, 0, 0]])

          Referencing an array prevents resizing...

          >>> c = a
          >>> a.resize((1, 1))
          Traceback (most recent call last):
          ...
          ValueError: cannot resize an array that references or is referenced ...

          Unless `refcheck` is False:

          >>> a.resize((1, 1), refcheck=False)
          >>> a
          array([[0]])
          >>> c
          array([[0]])




   .. py:method:: round(*args, **kwargs)

      a.round(decimals=0, out=None)

          Return `a` with each element rounded to the given number of decimals.

          Refer to `numpy.around` for full documentation.

          See Also
          --------
          numpy.around : equivalent function




   .. py:method:: searchsorted(*args, **kwargs)

      a.searchsorted(v, side='left', sorter=None)

          Find indices where elements of v should be inserted in a to maintain order.

          For full documentation, see `numpy.searchsorted`

          See Also
          --------
          numpy.searchsorted : equivalent function




   .. py:method:: setfield(*args, **kwargs)

      a.setfield(val, dtype, offset=0)

          Put a value into a specified place in a field defined by a data-type.

          Place `val` into `a`'s field defined by `dtype` and beginning `offset`
          bytes into the field.

          Parameters
          ----------
          val : object
              Value to be placed in field.
          dtype : dtype object
              Data-type of the field in which to place `val`.
          offset : int, optional
              The number of bytes into the field at which to place `val`.

          Returns
          -------
          None

          See Also
          --------
          getfield

          Examples
          --------
          >>> x = np.eye(3)
          >>> x.getfield(np.float64)
          array([[1.,  0.,  0.],
                 [0.,  1.,  0.],
                 [0.,  0.,  1.]])
          >>> x.setfield(3, np.int32)
          >>> x.getfield(np.int32)
          array([[3, 3, 3],
                 [3, 3, 3],
                 [3, 3, 3]], dtype=int32)
          >>> x
          array([[1.0e+000, 1.5e-323, 1.5e-323],
                 [1.5e-323, 1.0e+000, 1.5e-323],
                 [1.5e-323, 1.5e-323, 1.0e+000]])
          >>> x.setfield(np.eye(3), np.int32)
          >>> x
          array([[1.,  0.,  0.],
                 [0.,  1.,  0.],
                 [0.,  0.,  1.]])




   .. py:method:: setflags(*args, **kwargs)

      a.setflags(write=None, align=None, uic=None)

          Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY,
          respectively.

          These Boolean-valued flags affect how numpy interprets the memory
          area used by `a` (see Notes below). The ALIGNED flag can only
          be set to True if the data is actually aligned according to the type.
          The WRITEBACKIFCOPY and flag can never be set
          to True. The flag WRITEABLE can only be set to True if the array owns its
          own memory, or the ultimate owner of the memory exposes a writeable buffer
          interface, or is a string. (The exception for string is made so that
          unpickling can be done without copying memory.)

          Parameters
          ----------
          write : bool, optional
              Describes whether or not `a` can be written to.
          align : bool, optional
              Describes whether or not `a` is aligned properly for its type.
          uic : bool, optional
              Describes whether or not `a` is a copy of another "base" array.

          Notes
          -----
          Array flags provide information about how the memory area used
          for the array is to be interpreted. There are 7 Boolean flags
          in use, only four of which can be changed by the user:
          WRITEBACKIFCOPY, WRITEABLE, and ALIGNED.

          WRITEABLE (W) the data area can be written to;

          ALIGNED (A) the data and strides are aligned appropriately for the hardware
          (as determined by the compiler);

          WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced
          by .base). When the C-API function PyArray_ResolveWritebackIfCopy is
          called, the base array will be updated with the contents of this array.

          All flags can be accessed using the single (upper case) letter as well
          as the full name.

          Examples
          --------
          >>> y = np.array([[3, 1, 7],
          ...               [2, 0, 0],
          ...               [8, 5, 9]])
          >>> y
          array([[3, 1, 7],
                 [2, 0, 0],
                 [8, 5, 9]])
          >>> y.flags
            C_CONTIGUOUS : True
            F_CONTIGUOUS : False
            OWNDATA : True
            WRITEABLE : True
            ALIGNED : True
            WRITEBACKIFCOPY : False
          >>> y.setflags(write=0, align=0)
          >>> y.flags
            C_CONTIGUOUS : True
            F_CONTIGUOUS : False
            OWNDATA : True
            WRITEABLE : False
            ALIGNED : False
            WRITEBACKIFCOPY : False
          >>> y.setflags(uic=1)
          Traceback (most recent call last):
            File "<stdin>", line 1, in <module>
          ValueError: cannot set WRITEBACKIFCOPY flag to True




   .. py:method:: shape(*args, **kwargs)

      Tuple of array dimensions.

          The shape property is usually used to get the current shape of an array,
          but may also be used to reshape the array in-place by assigning a tuple of
          array dimensions to it.  As with `numpy.reshape`, one of the new shape
          dimensions can be -1, in which case its value is inferred from the size of
          the array and the remaining dimensions. Reshaping an array in-place will
          fail if a copy is required.

          .. warning::

              Setting ``arr.shape`` is discouraged and may be deprecated in the
              future.  Using `ndarray.reshape` is the preferred approach.

          Examples
          --------
          >>> x = np.array([1, 2, 3, 4])
          >>> x.shape
          (4,)
          >>> y = np.zeros((2, 3, 4))
          >>> y.shape
          (2, 3, 4)
          >>> y.shape = (3, 8)
          >>> y
          array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
                 [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
                 [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])
          >>> y.shape = (3, 6)
          Traceback (most recent call last):
            File "<stdin>", line 1, in <module>
          ValueError: total size of new array must be unchanged
          >>> np.zeros((4,2))[::2].shape = (-1,)
          Traceback (most recent call last):
            File "<stdin>", line 1, in <module>
          AttributeError: Incompatible shape for in-place modification. Use
          `.reshape()` to make a copy with the desired shape.

          See Also
          --------
          numpy.shape : Equivalent getter function.
          numpy.reshape : Function similar to setting ``shape``.
          ndarray.reshape : Method similar to setting ``shape``.




   .. py:method:: size(*args, **kwargs)

      Number of elements in the array.

          Equal to ``np.prod(a.shape)``, i.e., the product of the array's
          dimensions.

          Notes
          -----
          `a.size` returns a standard arbitrary precision Python integer. This
          may not be the case with other methods of obtaining the same value
          (like the suggested ``np.prod(a.shape)``, which returns an instance
          of ``np.int_``), and may be relevant if the value is used further in
          calculations that may overflow a fixed size integer type.

          Examples
          --------
          >>> x = np.zeros((3, 5, 2), dtype=np.complex128)
          >>> x.size
          30
          >>> np.prod(x.shape)
          30




   .. py:method:: sort(*args, **kwargs)

      a.sort(axis=-1, kind=None, order=None)

          Sort an array in-place. Refer to `numpy.sort` for full documentation.

          Parameters
          ----------
          axis : int, optional
              Axis along which to sort. Default is -1, which means sort along the
              last axis.
          kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional
              Sorting algorithm. The default is 'quicksort'. Note that both 'stable'
              and 'mergesort' use timsort under the covers and, in general, the
              actual implementation will vary with datatype. The 'mergesort' option
              is retained for backwards compatibility.

              .. versionchanged:: 1.15.0
                 The 'stable' option was added.

          order : str or list of str, optional
              When `a` is an array with fields defined, this argument specifies
              which fields to compare first, second, etc.  A single field can
              be specified as a string, and not all fields need be specified,
              but unspecified fields will still be used, in the order in which
              they come up in the dtype, to break ties.

          See Also
          --------
          numpy.sort : Return a sorted copy of an array.
          numpy.argsort : Indirect sort.
          numpy.lexsort : Indirect stable sort on multiple keys.
          numpy.searchsorted : Find elements in sorted array.
          numpy.partition: Partial sort.

          Notes
          -----
          See `numpy.sort` for notes on the different sorting algorithms.

          Examples
          --------
          >>> a = np.array([[1,4], [3,1]])
          >>> a.sort(axis=1)
          >>> a
          array([[1, 4],
                 [1, 3]])
          >>> a.sort(axis=0)
          >>> a
          array([[1, 3],
                 [1, 4]])

          Use the `order` keyword to specify a field to use when sorting a
          structured array:

          >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])
          >>> a.sort(order='y')
          >>> a
          array([(b'c', 1), (b'a', 2)],
                dtype=[('x', 'S1'), ('y', '<i8')])




   .. py:method:: squeeze(*args, **kwargs)

      a.squeeze(axis=None)

          Remove axes of length one from `a`.

          Refer to `numpy.squeeze` for full documentation.

          See Also
          --------
          numpy.squeeze : equivalent function




   .. py:method:: std(*args, **kwargs)

      a.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)

          Returns the standard deviation of the array elements along given axis.

          Refer to `numpy.std` for full documentation.

          See Also
          --------
          numpy.std : equivalent function




   .. py:method:: strides(*args, **kwargs)

      Tuple of bytes to step in each dimension when traversing an array.

          The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`
          is::

              offset = sum(np.array(i) * a.strides)

          A more detailed explanation of strides can be found in the
          "ndarray.rst" file in the NumPy reference guide.

          .. warning::

              Setting ``arr.strides`` is discouraged and may be deprecated in the
              future.  `numpy.lib.stride_tricks.as_strided` should be preferred
              to create a new view of the same data in a safer way.

          Notes
          -----
          Imagine an array of 32-bit integers (each 4 bytes)::

            x = np.array([[0, 1, 2, 3, 4],
                          [5, 6, 7, 8, 9]], dtype=np.int32)

          This array is stored in memory as 40 bytes, one after the other
          (known as a contiguous block of memory).  The strides of an array tell
          us how many bytes we have to skip in memory to move to the next position
          along a certain axis.  For example, we have to skip 4 bytes (1 value) to
          move to the next column, but 20 bytes (5 values) to get to the same
          position in the next row.  As such, the strides for the array `x` will be
          ``(20, 4)``.

          See Also
          --------
          numpy.lib.stride_tricks.as_strided

          Examples
          --------
          >>> y = np.reshape(np.arange(2*3*4), (2,3,4))
          >>> y
          array([[[ 0,  1,  2,  3],
                  [ 4,  5,  6,  7],
                  [ 8,  9, 10, 11]],
                 [[12, 13, 14, 15],
                  [16, 17, 18, 19],
                  [20, 21, 22, 23]]])
          >>> y.strides
          (48, 16, 4)
          >>> y[1,1,1]
          17
          >>> offset=sum(y.strides * np.array((1,1,1)))
          >>> offset/y.itemsize
          17

          >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)
          >>> x.strides
          (32, 4, 224, 1344)
          >>> i = np.array([3,5,2,2])
          >>> offset = sum(i * x.strides)
          >>> x[3,5,2,2]
          813
          >>> offset / x.itemsize
          813




   .. py:method:: sum(*args, **kwargs)

      a.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)

          Return the sum of the array elements over the given axis.

          Refer to `numpy.sum` for full documentation.

          See Also
          --------
          numpy.sum : equivalent function




   .. py:method:: swapaxes(*args, **kwargs)

      a.swapaxes(axis1, axis2)

          Return a view of the array with `axis1` and `axis2` interchanged.

          Refer to `numpy.swapaxes` for full documentation.

          See Also
          --------
          numpy.swapaxes : equivalent function




   .. py:method:: take(*args, **kwargs)

      a.take(indices, axis=None, out=None, mode='raise')

          Return an array formed from the elements of `a` at the given indices.

          Refer to `numpy.take` for full documentation.

          See Also
          --------
          numpy.take : equivalent function




   .. py:method:: tobytes(*args, **kwargs)

      a.tobytes(order='C')

          Construct Python bytes containing the raw data bytes in the array.

          Constructs Python bytes showing a copy of the raw contents of
          data memory. The bytes object is produced in C-order by default.
          This behavior is controlled by the ``order`` parameter.

          .. versionadded:: 1.9.0

          Parameters
          ----------
          order : {'C', 'F', 'A'}, optional
              Controls the memory layout of the bytes object. 'C' means C-order,
              'F' means F-order, 'A' (short for *Any*) means 'F' if `a` is
              Fortran contiguous, 'C' otherwise. Default is 'C'.

          Returns
          -------
          s : bytes
              Python bytes exhibiting a copy of `a`'s raw data.

          See also
          --------
          frombuffer
              Inverse of this operation, construct a 1-dimensional array from Python
              bytes.

          Examples
          --------
          >>> x = np.array([[0, 1], [2, 3]], dtype='<u2')
          >>> x.tobytes()
          b'\x00\x00\x01\x00\x02\x00\x03\x00'
          >>> x.tobytes('C') == x.tobytes()
          True
          >>> x.tobytes('F')
          b'\x00\x00\x02\x00\x01\x00\x03\x00'




   .. py:method:: tofile(*args, **kwargs)

      a.tofile(fid, sep="", format="%s")

          Write array to a file as text or binary (default).

          Data is always written in 'C' order, independent of the order of `a`.
          The data produced by this method can be recovered using the function
          fromfile().

          Parameters
          ----------
          fid : file or str or Path
              An open file object, or a string containing a filename.

              .. versionchanged:: 1.17.0
                  `pathlib.Path` objects are now accepted.

          sep : str
              Separator between array items for text output.
              If "" (empty), a binary file is written, equivalent to
              ``file.write(a.tobytes())``.
          format : str
              Format string for text file output.
              Each entry in the array is formatted to text by first converting
              it to the closest Python type, and then using "format" % item.

          Notes
          -----
          This is a convenience function for quick storage of array data.
          Information on endianness and precision is lost, so this method is not a
          good choice for files intended to archive data or transport data between
          machines with different endianness. Some of these problems can be overcome
          by outputting the data as text files, at the expense of speed and file
          size.

          When fid is a file object, array contents are directly written to the
          file, bypassing the file object's ``write`` method. As a result, tofile
          cannot be used with files objects supporting compression (e.g., GzipFile)
          or file-like objects that do not support ``fileno()`` (e.g., BytesIO).




   .. py:method:: tolist(*args, **kwargs)

      a.tolist()

          Return the array as an ``a.ndim``-levels deep nested list of Python scalars.

          Return a copy of the array data as a (nested) Python list.
          Data items are converted to the nearest compatible builtin Python type, via
          the `~numpy.ndarray.item` function.

          If ``a.ndim`` is 0, then since the depth of the nested list is 0, it will
          not be a list at all, but a simple Python scalar.

          Parameters
          ----------
          none

          Returns
          -------
          y : object, or list of object, or list of list of object, or ...
              The possibly nested list of array elements.

          Notes
          -----
          The array may be recreated via ``a = np.array(a.tolist())``, although this
          may sometimes lose precision.

          Examples
          --------
          For a 1D array, ``a.tolist()`` is almost the same as ``list(a)``,
          except that ``tolist`` changes numpy scalars to Python scalars:

          >>> a = np.uint32([1, 2])
          >>> a_list = list(a)
          >>> a_list
          [1, 2]
          >>> type(a_list[0])
          <class 'numpy.uint32'>
          >>> a_tolist = a.tolist()
          >>> a_tolist
          [1, 2]
          >>> type(a_tolist[0])
          <class 'int'>

          Additionally, for a 2D array, ``tolist`` applies recursively:

          >>> a = np.array([[1, 2], [3, 4]])
          >>> list(a)
          [array([1, 2]), array([3, 4])]
          >>> a.tolist()
          [[1, 2], [3, 4]]

          The base case for this recursion is a 0D array:

          >>> a = np.array(1)
          >>> list(a)
          Traceback (most recent call last):
            ...
          TypeError: iteration over a 0-d array
          >>> a.tolist()
          1




   .. py:method:: tostring(*args, **kwargs)

      a.tostring(order='C')

          A compatibility alias for `tobytes`, with exactly the same behavior.

          Despite its name, it returns `bytes` not `str`\ s.

          .. deprecated:: 1.19.0




   .. py:method:: trace(*args, **kwargs)

      a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)

          Return the sum along diagonals of the array.

          Refer to `numpy.trace` for full documentation.

          See Also
          --------
          numpy.trace : equivalent function




   .. py:method:: transpose(*args, **kwargs)

      a.transpose(*axes)

          Returns a view of the array with axes transposed.

          Refer to `numpy.transpose` for full documentation.

          Parameters
          ----------
          axes : None, tuple of ints, or `n` ints

           * None or no argument: reverses the order of the axes.

           * tuple of ints: `i` in the `j`-th place in the tuple means that the
             array's `i`-th axis becomes the transposed array's `j`-th axis.

           * `n` ints: same as an n-tuple of the same ints (this form is
             intended simply as a "convenience" alternative to the tuple form).

          Returns
          -------
          p : ndarray
              View of the array with its axes suitably permuted.

          See Also
          --------
          transpose : Equivalent function.
          ndarray.T : Array property returning the array transposed.
          ndarray.reshape : Give a new shape to an array without changing its data.

          Examples
          --------
          >>> a = np.array([[1, 2], [3, 4]])
          >>> a
          array([[1, 2],
                 [3, 4]])
          >>> a.transpose()
          array([[1, 3],
                 [2, 4]])
          >>> a.transpose((1, 0))
          array([[1, 3],
                 [2, 4]])
          >>> a.transpose(1, 0)
          array([[1, 3],
                 [2, 4]])

          >>> a = np.array([1, 2, 3, 4])
          >>> a
          array([1, 2, 3, 4])
          >>> a.transpose()
          array([1, 2, 3, 4])




   .. py:method:: var(*args, **kwargs)

      a.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)

          Returns the variance of the array elements, along given axis.

          Refer to `numpy.var` for full documentation.

          See Also
          --------
          numpy.var : equivalent function




   .. py:method:: view(*args, **kwargs)

      a.view([dtype][, type])

          New view of array with the same data.

          .. note::
              Passing None for ``dtype`` is different from omitting the parameter,
              since the former invokes ``dtype(None)`` which is an alias for
              ``dtype('float_')``.

          Parameters
          ----------
          dtype : data-type or ndarray sub-class, optional
              Data-type descriptor of the returned view, e.g., float32 or int16.
              Omitting it results in the view having the same data-type as `a`.
              This argument can also be specified as an ndarray sub-class, which
              then specifies the type of the returned object (this is equivalent to
              setting the ``type`` parameter).
          type : Python type, optional
              Type of the returned view, e.g., ndarray or matrix.  Again, omission
              of the parameter results in type preservation.

          Notes
          -----
          ``a.view()`` is used two different ways:

          ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view
          of the array's memory with a different data-type.  This can cause a
          reinterpretation of the bytes of memory.

          ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just
          returns an instance of `ndarray_subclass` that looks at the same array
          (same shape, dtype, etc.)  This does not cause a reinterpretation of the
          memory.

          For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of
          bytes per entry than the previous dtype (for example, converting a regular
          array to a structured array), then the last axis of ``a`` must be
          contiguous. This axis will be resized in the result.

          .. versionchanged:: 1.23.0
             Only the last axis needs to be contiguous. Previously, the entire array
             had to be C-contiguous.

          Examples
          --------
          >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])

          Viewing array data using a different type and dtype:

          >>> y = x.view(dtype=np.int16, type=np.matrix)
          >>> y
          matrix([[513]], dtype=int16)
          >>> print(type(y))
          <class 'numpy.matrix'>

          Creating a view on a structured array so it can be used in calculations

          >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])
          >>> xv = x.view(dtype=np.int8).reshape(-1,2)
          >>> xv
          array([[1, 2],
                 [3, 4]], dtype=int8)
          >>> xv.mean(0)
          array([2.,  3.])

          Making changes to the view changes the underlying array

          >>> xv[0,1] = 20
          >>> x
          array([(1, 20), (3,  4)], dtype=[('a', 'i1'), ('b', 'i1')])

          Using a view to convert an array to a recarray:

          >>> z = x.view(np.recarray)
          >>> z.a
          array([1, 3], dtype=int8)

          Views share data:

          >>> x[0] = (9, 10)
          >>> z[0]
          (9, 10)

          Views that change the dtype size (bytes per entry) should normally be
          avoided on arrays defined by slices, transposes, fortran-ordering, etc.:

          >>> x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int16)
          >>> y = x[:, ::2]
          >>> y
          array([[1, 3],
                 [4, 6]], dtype=int16)
          >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])
          Traceback (most recent call last):
              ...
          ValueError: To change to a dtype of a different size, the last axis must be contiguous
          >>> z = y.copy()
          >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])
          array([[(1, 3)],
                 [(4, 6)]], dtype=[('width', '<i2'), ('length', '<i2')])

          However, views that change dtype are totally fine for arrays with a
          contiguous last axis, even if the rest of the axes are not C-contiguous:

          >>> x = np.arange(2 * 3 * 4, dtype=np.int8).reshape(2, 3, 4)
          >>> x.transpose(1, 0, 2).view(np.int16)
          array([[[ 256,  770],
                  [3340, 3854]],
          <BLANKLINE>
                 [[1284, 1798],
                  [4368, 4882]],
          <BLANKLINE>
                 [[2312, 2826],
                  [5396, 5910]]], dtype=int16)




.. py:data:: numeric_and_bool_scalars

.. py:data:: numeric_scalars

.. py:class:: numeric_scalars(origin, params, *, inst=True, name=None)

   Bases: :py:obj:`_GenericAlias`


   The central part of internal API.

   This represents a generic version of type 'origin' with type arguments 'params'.
   There are two kind of these aliases: user defined and special. The special ones
   are wrappers around builtin collections and ABCs in collections.abc. These must
   have 'name' always set. If 'inst' is False, then the alias can't be instantiated,
   this is used by e.g. typing.List and typing.Dict.


.. py:data:: numpy_scalars

.. py:function:: ones(size: Union[arkouda.numpy.dtypes.int_scalars, Tuple[arkouda.numpy.dtypes.int_scalars, Ellipsis], str], dtype: Union[numpy.dtype, type, str, arkouda.numpy.dtypes.bigint] = float64, max_bits: Optional[int] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size or shape of the array
   :type size: int_scalars or tuple of int_scalars
   :param dtype: Resulting array type, default ak.float64
   :type dtype: Union[float64, int64, bool]
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
                    Included for consistency, as ones are all zeros ending on a one, regardless
                    of max_bits
   :type max_bits: int

   :returns: Ones of the requested size or shape and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported
   :raises RuntimeError: Raised if the size parameter is neither an int nor a str that is parseable to an int.
   :raises ValueError: Raised if the rank of the given shape is not in get_array_ranks() or is empty

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1 1 1 1 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1.00000000000000000 1.00000000000000000 1.00000000000000000
          1.00000000000000000 1.00000000000000000])

   >>> ak.ones(5, dtype=ak.bool_)
   array([True True True True True])

   .. rubric:: Notes

   Logic for generating the pdarray is delegated to the ak.full method.


.. py:function:: ones(size: Union[arkouda.numpy.dtypes.int_scalars, Tuple[arkouda.numpy.dtypes.int_scalars, Ellipsis], str], dtype: Union[numpy.dtype, type, str, arkouda.numpy.dtypes.bigint] = float64, max_bits: Optional[int] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size or shape of the array
   :type size: int_scalars or tuple of int_scalars
   :param dtype: Resulting array type, default ak.float64
   :type dtype: Union[float64, int64, bool]
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
                    Included for consistency, as ones are all zeros ending on a one, regardless
                    of max_bits
   :type max_bits: int

   :returns: Ones of the requested size or shape and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported
   :raises RuntimeError: Raised if the size parameter is neither an int nor a str that is parseable to an int.
   :raises ValueError: Raised if the rank of the given shape is not in get_array_ranks() or is empty

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1 1 1 1 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1.00000000000000000 1.00000000000000000 1.00000000000000000
          1.00000000000000000 1.00000000000000000])

   >>> ak.ones(5, dtype=ak.bool_)
   array([True True True True True])

   .. rubric:: Notes

   Logic for generating the pdarray is delegated to the ak.full method.


.. py:function:: ones_like(pda: arkouda.numpy.pdarrayclass.pdarray) -> arkouda.numpy.pdarrayclass.pdarray

   Create a one-filled pdarray of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray

   :returns: Equivalent to ak.ones(pda.size, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Notes

   Logic for generating the pdarray is delegated to the ak.ones method.
   Accordingly, the supported dtypes match are defined by the ak.ones method.

   .. rubric:: Examples

   >>> ak.ones_like(ak.zeros(5,dtype=ak.int64))
   array([1 1 1 1 1])

   >>> ak.ones_like(ak.zeros(5,dtype=ak.float64))
   array([1.00000000000000000 1.00000000000000000 1.00000000000000000
          1.00000000000000000 1.00000000000000000])

   >>> ak.ones_like(ak.zeros(5,dtype=ak.bool_))
   array([True True True True True])


.. py:function:: parity(pda: pdarray) -> pdarray

   Find the bit parity (XOR of all bits) for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64, bigint

   :returns: **parity** -- The parity of each element: 0 if even number of bits set, 1 if odd.
   :rtype: pdarray

   :raises TypeError: If input array is not int64, uint64, or bigint

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.parity(A)
   array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0])


.. py:class:: pdarray

   The basic arkouda array class. This class contains only the
   attributes of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars


   .. py:method:: BinOps(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: OpEqOps(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: all(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[bool_scalars, pdarray]

      Return True iff all elements of the array along the given axis evaluate to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.all(ak.array([True,False,False]))
      False
      >>> ak.all(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([False True False])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([False False False])])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).all()
      False

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.all(a))



   .. py:method:: any(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[bool_scalars, pdarray]

      Return True iff any element of the array along the given axis evaluates to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.any(ak.array([True,False,False]))
      True
      >>> ak.any(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([True True True])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([True True True])])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).any()
      True

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.any(a))



   .. py:method:: argmax(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[np.int64, np.uint64, pdarray]

      Return index of the first occurrence of the maximum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmax(ak.array([1,2,3,4,5]))
      4
      >>> ak.argmax(ak.array([5.5,4.5,3.5,2.5,1.5]))
      0
      >>> ak.array([[1,2,3],[5,4,3]]).argmax(axis=1)
      array([2 0])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmax()) or a standalone function (e.g. ak.argmax(a))



   .. py:method:: argmaxk(k: int_scalars) -> pdarray

      Finds the indices corresponding to the `k` maximum values of an array.
      See ``arkouda.argmaxk`` for details.




   .. py:method:: argmin(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[np.int64, np.uint64, pdarray]

      Return index of the first occurrence of the minimum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmin(ak.array([1,2,3,4,5]))
      0
      >>> ak.argmin(ak.array([5.5,4.5,3.5,2.5,1.5]))
      4
      >>> ak.array([[1,2,3],[5,4,3]]).argmin(axis=1)
      array([0 2])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmin()) or a standalone function (e.g. ak.argmin(a))



   .. py:method:: argmink(k: int_scalars) -> pdarray

      Finds the indices corresponding to the `k` minimum values of an array.
      See ``arkouda.argmink`` for details.




   .. py:method:: astype(dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      .. rubric:: Examples

      >>> ak.array([1,2,3]).astype(ak.float64)
      array([1.00000000000000000 2.00000000000000000 3.00000000000000000])
      >>> ak.array([1.5,2.5]).astype(ak.int64)
      array([1 2])
      >>> ak.array([True,False]).astype(ak.int64)
      array([1 0])

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> pdarray

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to the corresponding server side component which was registered
                with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: bigint_to_uint_arrays() -> List[pdarray]

      Creates a list of uint pdarrays from a bigint pdarray.
      The first item in return will be the highest 64 bits of the
      bigint pdarray and the last item will be the lowest 64 bits.

      :returns: A list of uint pdarrays where:
                The first item in return will be the highest 64 bits of the
                bigint pdarray and the last item will be the lowest 64 bits.
      :rtype: List[pdarrays]

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`pdarraycreation.bigint_from_uint_arrays`

      .. rubric:: Examples

      >>> a = ak.arange(2**64, 2**64 + 5)
      >>> a
      array([18446744073709551616 18446744073709551617 18446744073709551618
      18446744073709551619 18446744073709551620])
      >>> a.bigint_to_uint_arrays()
      [array([1 1 1 1 1]), array([0 1 2 3 4])]



   .. py:method:: clz() -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.




   .. py:method:: corr(y: pdarray) -> np.float64

      Compute the correlation between self and y using pearson correlation coefficient.
      See ``arkouda.corr`` for details.




   .. py:method:: cov(y: pdarray) -> np.float64

      Compute the covariance between self and y.




   .. py:method:: ctz() -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.




   .. py:method:: equals(other) -> bool_scalars

      Whether pdarrays are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the pdarrays are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> a = ak.array([1, 2, 3])
      >>> a_cpy = ak.array([1, 2, 3])
      >>> a.equals(a_cpy)
      True
      >>> a2 = ak.array([1, 2, 5)
      >>> a.equals(a2)
      False



   .. py:method:: fill(value: numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64



   .. py:method:: flatten()

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.flatten()
      array([3 2 1 2 3 1])



   .. py:method:: format_other(other) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype



   .. py:property:: inferred_type
      :type: str


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> np.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. note::

         This will return True if the object is registered itself or as a component
         of another object



   .. py:method:: is_sorted(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[bool_scalars, pdarray]

      Return True iff the array (or given axis of the array) is monotonically non-decreasing.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.is_sorted(ak.array([1,2,3,4,5]))
      True
      >>> ak.is_sorted(ak.array([5,4,3,2,1]))
      False
      >>> ak.array([[1,2,3],[5,4,3]]).is_sorted(axis=1)
      array([True False])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.is_sorted()) or a
      standalone function (e.g. ak.is_sorted(a))



   .. py:method:: max(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return max of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.max(ak.array([1,2,3,4,5]))
      5
      >>> ak.max(ak.array([5.5,4.5,3.5,2.5,1.5]))
      5.5
      >>> ak.array([[1,2,3],[5,4,3]]).max(axis=1)
      array([3 5])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.max()) or a standalone function (e.g. ak.max(a))



   .. py:property:: max_bits
      :type: Union[numpy_scalars, pdarray]



   .. py:method:: maxk(k: int_scalars) -> pdarray

      Compute the maximum "k" values.  See ``arkouda.maxk`` for details.




   .. py:method:: mean() -> np.float64

      Compute the mean.  See ``arkouda.mean`` for details.




   .. py:method:: min(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return min of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.min(ak.array([1,2,3,4,5]))
      1
      >>> ak.min(ak.array([5.5,4.5,3.5,2.5,1.5]))
      1.5
      >>> ak.array([[1,2,3],[5,4,3]]).min(axis=1)
      array([1 3])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.min()) or a standalone function (e.g. ak.min(a))



   .. py:method:: mink(k: int_scalars) -> pdarray

      Compute the minimum "k" values.  See ``arkouda.mink`` for details.




   .. py:property:: nbytes
      :type: pdarray


      The size of the pdarray in bytes.

      :returns: The size of the pdarray in bytes.
      :rtype: int


   .. py:method:: objType(*args, **kwargs)

      str(object='') -> str
      str(bytes_or_buffer[, encoding[, errors]]) -> str

      Create a new string object from the given object. If encoding or
      errors is specified, then the object must expose a data buffer
      that will be decoded using the given encoding and error handler.
      Otherwise, returns the result of object.__str__() (if defined)
      or repr(object).
      encoding defaults to sys.getdefaultencoding().
      errors defaults to 'strict'.




   .. py:method:: opeq(other, op)


   .. py:method:: parity() -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.




   .. py:method:: popcount() -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.




   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: prod(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return prod of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, defalt = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.prod(ak.array([1,2,3,4,5]))
      120
      >>> ak.prod(ak.array([5.5,4.5,3.5,2.5,1.5]))
      324.84375
      >>> ak.array([[1,2,3],[5,4,3]]).prod(axis=1)
      array([6 60])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.prod()) or a standalone function (e.g. ak.prod(a))



   .. py:method:: register(user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: reshape(*shape)

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray

      :returns: a pdarray with the same data, reshaped to the new shape
      :rtype: pdarray

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.reshape((3,2))
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape(3,2)
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape((6,1))
      array([array([3]) array([2]) array([1]) array([2]) array([3]) array([1])])

      .. rubric:: Notes

      only available as a method, not as a standalone function, i.e.,
      a.reshape(compatibleShape) is valid, but ak.reshape(a,compatibleShape) is not.



   .. py:method:: rotl(other) -> pdarray

      Rotate bits left by <other>.




   .. py:method:: rotr(other) -> pdarray

      Rotate bits right by <other>.




   .. py:method:: save(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.save('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.save('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving with an extension (Parquet)
      >>> a.save('path/prefix.parquet', dataset='array', file_format='Parquet')
      Saves the array in numLocales Parquet files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:property:: shape
      :type: str


      Return the shape of an array.

      :returns: The elements of the shape tuple give the lengths of the corresponding array dimensions.
      :rtype: tuple of int


   .. py:method:: slice_bits(low, high) -> pdarray

      Returns a pdarray containing only bits from low to high of self.

      This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
      pda.slice_bits(0, 63)

      :param low: The lowest bit included in the slice (inclusive)
                  zero indexed, so the first bit is 0
      :type low: int
      :param high: The highest bit included in the slice (inclusive)
      :type high: int

      :returns: A new pdarray containing the bits of self from low to high
      :rtype: pdarray

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> p = ak.array([2**65 + (2**64 - 1)])
      >>> bin(p[0])
      '0b101111111111111111111111111111111111111111111111111111111111111111'
      >>> bin(p.slice_bits(64, 65)[0])
      '0b10'
      >>> a = ak.array([143,15])
      >>> a.slice_bits(1,3)
      array([7 7])
      >>> a.slice_bits(4,9)
      array([8 0])
      >>> a.slice_bits(1,9)
      array([71 7])



   .. py:method:: std(ddof: int_scalars = 0) -> np.float64

      Compute the standard deviation. See ``arkouda.std`` for details.




   .. py:method:: sum(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return sum of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.sum(ak.array([1,2,3,4,5]))
      15
      >>> ak.sum(ak.array([5.5,4.5,3.5,2.5,1.5]))
      17.5
      >>> ak.array([[1,2,3],[5,4,3]]).sum(axis=1)
      array([6 12])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.sum()) or a standalone function (e.g. ak.sum(a))



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'array', col_delim: str = ',', overwrite: bool = False)

      Write pdarry to CSV file(s).  File will contain a single column
      with the pdarray data.  All CSV files written by Arkouda include
      a header denoting data types of the columns.

      :param prefix_path: filename prefix to be used for saving files.  Files will have
                          _LOCALE#### appended when they are written to disk.
      :type prefix_path: str
      :param dataset: column name to save the pdarray under.
      :type dataset: str, defaults to "array"
      :param col_delim: value to be used to separate columns within the file.  Please
                        be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, defaults to ","
      :param overwrite: If True, existing files matching the provided path will be overwritten.
                        if False and existing files are found, an error will be returned.
      :type overwrite: bool, defaults to False

      :returns: **response message**
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one
          or more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          if 'allow_errors' is true, this may be raised if no values are returned
          from the server.
      :raises TypeError: Raise if the server returns an unknown arkouda_type

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for all column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline ("\n") at this time.



   .. py:method:: to_cuda()

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_cuda())
      numpy.devicendarray



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute') -> str

      Save the pdarray to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_hdf('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_hdf('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving to a single file
      >>> a.to_hdf('path/prefix.hdf5', dataset='array', file_type='single')
      Saves the array in to single hdf5 file on the root node.
      ``cwd/path/name_prefix.hdf5``



   .. py:method:: to_list() -> List

      Convert the array to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the pdarray
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_list()
      [0, 1, 2, 3, 4]
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> np.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the pdarray to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_parquet('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_parqet('path/prefix.parquet', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: transfer(hostname: str, port: int_scalars)

      Sends a pdarray to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the pdarray is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Overwrite the dataset with the name provided with this pdarray. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: value_counts()

      Count the occurrences of the unique values of self.

      :returns: * **unique_values** (*pdarray*) -- The unique values, sorted in ascending order
                * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

      .. rubric:: Examples

      >>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
      (array([0, 2, 4]), array([3, 2, 1]))



   .. py:method:: var(ddof: int_scalars = 0) -> np.float64

      Compute the variance. See ``arkouda.var`` for details.




.. py:class:: pdarray

   The basic arkouda array class. This class contains only the
   attributes of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars


   .. py:method:: BinOps(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: OpEqOps(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: all(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[bool_scalars, pdarray]

      Return True iff all elements of the array along the given axis evaluate to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.all(ak.array([True,False,False]))
      False
      >>> ak.all(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([False True False])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([False False False])])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).all()
      False

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.all(a))



   .. py:method:: any(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[bool_scalars, pdarray]

      Return True iff any element of the array along the given axis evaluates to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.any(ak.array([True,False,False]))
      True
      >>> ak.any(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([True True True])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([True True True])])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).any()
      True

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.any(a))



   .. py:method:: argmax(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[np.int64, np.uint64, pdarray]

      Return index of the first occurrence of the maximum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmax(ak.array([1,2,3,4,5]))
      4
      >>> ak.argmax(ak.array([5.5,4.5,3.5,2.5,1.5]))
      0
      >>> ak.array([[1,2,3],[5,4,3]]).argmax(axis=1)
      array([2 0])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmax()) or a standalone function (e.g. ak.argmax(a))



   .. py:method:: argmaxk(k: int_scalars) -> pdarray

      Finds the indices corresponding to the `k` maximum values of an array.
      See ``arkouda.argmaxk`` for details.




   .. py:method:: argmin(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[np.int64, np.uint64, pdarray]

      Return index of the first occurrence of the minimum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmin(ak.array([1,2,3,4,5]))
      0
      >>> ak.argmin(ak.array([5.5,4.5,3.5,2.5,1.5]))
      4
      >>> ak.array([[1,2,3],[5,4,3]]).argmin(axis=1)
      array([0 2])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmin()) or a standalone function (e.g. ak.argmin(a))



   .. py:method:: argmink(k: int_scalars) -> pdarray

      Finds the indices corresponding to the `k` minimum values of an array.
      See ``arkouda.argmink`` for details.




   .. py:method:: astype(dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      .. rubric:: Examples

      >>> ak.array([1,2,3]).astype(ak.float64)
      array([1.00000000000000000 2.00000000000000000 3.00000000000000000])
      >>> ak.array([1.5,2.5]).astype(ak.int64)
      array([1 2])
      >>> ak.array([True,False]).astype(ak.int64)
      array([1 0])

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> pdarray

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to the corresponding server side component which was registered
                with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: bigint_to_uint_arrays() -> List[pdarray]

      Creates a list of uint pdarrays from a bigint pdarray.
      The first item in return will be the highest 64 bits of the
      bigint pdarray and the last item will be the lowest 64 bits.

      :returns: A list of uint pdarrays where:
                The first item in return will be the highest 64 bits of the
                bigint pdarray and the last item will be the lowest 64 bits.
      :rtype: List[pdarrays]

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`pdarraycreation.bigint_from_uint_arrays`

      .. rubric:: Examples

      >>> a = ak.arange(2**64, 2**64 + 5)
      >>> a
      array([18446744073709551616 18446744073709551617 18446744073709551618
      18446744073709551619 18446744073709551620])
      >>> a.bigint_to_uint_arrays()
      [array([1 1 1 1 1]), array([0 1 2 3 4])]



   .. py:method:: clz() -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.




   .. py:method:: corr(y: pdarray) -> np.float64

      Compute the correlation between self and y using pearson correlation coefficient.
      See ``arkouda.corr`` for details.




   .. py:method:: cov(y: pdarray) -> np.float64

      Compute the covariance between self and y.




   .. py:method:: ctz() -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.




   .. py:method:: equals(other) -> bool_scalars

      Whether pdarrays are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the pdarrays are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> a = ak.array([1, 2, 3])
      >>> a_cpy = ak.array([1, 2, 3])
      >>> a.equals(a_cpy)
      True
      >>> a2 = ak.array([1, 2, 5)
      >>> a.equals(a2)
      False



   .. py:method:: fill(value: numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64



   .. py:method:: flatten()

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.flatten()
      array([3 2 1 2 3 1])



   .. py:method:: format_other(other) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype



   .. py:property:: inferred_type
      :type: str


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> np.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. note::

         This will return True if the object is registered itself or as a component
         of another object



   .. py:method:: is_sorted(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[bool_scalars, pdarray]

      Return True iff the array (or given axis of the array) is monotonically non-decreasing.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.is_sorted(ak.array([1,2,3,4,5]))
      True
      >>> ak.is_sorted(ak.array([5,4,3,2,1]))
      False
      >>> ak.array([[1,2,3],[5,4,3]]).is_sorted(axis=1)
      array([True False])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.is_sorted()) or a
      standalone function (e.g. ak.is_sorted(a))



   .. py:method:: max(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return max of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.max(ak.array([1,2,3,4,5]))
      5
      >>> ak.max(ak.array([5.5,4.5,3.5,2.5,1.5]))
      5.5
      >>> ak.array([[1,2,3],[5,4,3]]).max(axis=1)
      array([3 5])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.max()) or a standalone function (e.g. ak.max(a))



   .. py:property:: max_bits
      :type: Union[numpy_scalars, pdarray]



   .. py:method:: maxk(k: int_scalars) -> pdarray

      Compute the maximum "k" values.  See ``arkouda.maxk`` for details.




   .. py:method:: mean() -> np.float64

      Compute the mean.  See ``arkouda.mean`` for details.




   .. py:method:: min(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return min of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.min(ak.array([1,2,3,4,5]))
      1
      >>> ak.min(ak.array([5.5,4.5,3.5,2.5,1.5]))
      1.5
      >>> ak.array([[1,2,3],[5,4,3]]).min(axis=1)
      array([1 3])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.min()) or a standalone function (e.g. ak.min(a))



   .. py:method:: mink(k: int_scalars) -> pdarray

      Compute the minimum "k" values.  See ``arkouda.mink`` for details.




   .. py:property:: nbytes
      :type: pdarray


      The size of the pdarray in bytes.

      :returns: The size of the pdarray in bytes.
      :rtype: int


   .. py:method:: objType(*args, **kwargs)

      str(object='') -> str
      str(bytes_or_buffer[, encoding[, errors]]) -> str

      Create a new string object from the given object. If encoding or
      errors is specified, then the object must expose a data buffer
      that will be decoded using the given encoding and error handler.
      Otherwise, returns the result of object.__str__() (if defined)
      or repr(object).
      encoding defaults to sys.getdefaultencoding().
      errors defaults to 'strict'.




   .. py:method:: opeq(other, op)


   .. py:method:: parity() -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.




   .. py:method:: popcount() -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.




   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: prod(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return prod of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, defalt = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.prod(ak.array([1,2,3,4,5]))
      120
      >>> ak.prod(ak.array([5.5,4.5,3.5,2.5,1.5]))
      324.84375
      >>> ak.array([[1,2,3],[5,4,3]]).prod(axis=1)
      array([6 60])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.prod()) or a standalone function (e.g. ak.prod(a))



   .. py:method:: register(user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: reshape(*shape)

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray

      :returns: a pdarray with the same data, reshaped to the new shape
      :rtype: pdarray

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.reshape((3,2))
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape(3,2)
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape((6,1))
      array([array([3]) array([2]) array([1]) array([2]) array([3]) array([1])])

      .. rubric:: Notes

      only available as a method, not as a standalone function, i.e.,
      a.reshape(compatibleShape) is valid, but ak.reshape(a,compatibleShape) is not.



   .. py:method:: rotl(other) -> pdarray

      Rotate bits left by <other>.




   .. py:method:: rotr(other) -> pdarray

      Rotate bits right by <other>.




   .. py:method:: save(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.save('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.save('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving with an extension (Parquet)
      >>> a.save('path/prefix.parquet', dataset='array', file_format='Parquet')
      Saves the array in numLocales Parquet files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:property:: shape
      :type: str


      Return the shape of an array.

      :returns: The elements of the shape tuple give the lengths of the corresponding array dimensions.
      :rtype: tuple of int


   .. py:method:: slice_bits(low, high) -> pdarray

      Returns a pdarray containing only bits from low to high of self.

      This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
      pda.slice_bits(0, 63)

      :param low: The lowest bit included in the slice (inclusive)
                  zero indexed, so the first bit is 0
      :type low: int
      :param high: The highest bit included in the slice (inclusive)
      :type high: int

      :returns: A new pdarray containing the bits of self from low to high
      :rtype: pdarray

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> p = ak.array([2**65 + (2**64 - 1)])
      >>> bin(p[0])
      '0b101111111111111111111111111111111111111111111111111111111111111111'
      >>> bin(p.slice_bits(64, 65)[0])
      '0b10'
      >>> a = ak.array([143,15])
      >>> a.slice_bits(1,3)
      array([7 7])
      >>> a.slice_bits(4,9)
      array([8 0])
      >>> a.slice_bits(1,9)
      array([71 7])



   .. py:method:: std(ddof: int_scalars = 0) -> np.float64

      Compute the standard deviation. See ``arkouda.std`` for details.




   .. py:method:: sum(axis: Optional[Union[int, Tuple[int, ...]]] = None, keepdims: bool = False) -> Union[numpy_scalars, pdarray]

      Return sum of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.sum(ak.array([1,2,3,4,5]))
      15
      >>> ak.sum(ak.array([5.5,4.5,3.5,2.5,1.5]))
      17.5
      >>> ak.array([[1,2,3],[5,4,3]]).sum(axis=1)
      array([6 12])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.sum()) or a standalone function (e.g. ak.sum(a))



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'array', col_delim: str = ',', overwrite: bool = False)

      Write pdarry to CSV file(s).  File will contain a single column
      with the pdarray data.  All CSV files written by Arkouda include
      a header denoting data types of the columns.

      :param prefix_path: filename prefix to be used for saving files.  Files will have
                          _LOCALE#### appended when they are written to disk.
      :type prefix_path: str
      :param dataset: column name to save the pdarray under.
      :type dataset: str, defaults to "array"
      :param col_delim: value to be used to separate columns within the file.  Please
                        be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, defaults to ","
      :param overwrite: If True, existing files matching the provided path will be overwritten.
                        if False and existing files are found, an error will be returned.
      :type overwrite: bool, defaults to False

      :returns: **response message**
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one
          or more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          if 'allow_errors' is true, this may be raised if no values are returned
          from the server.
      :raises TypeError: Raise if the server returns an unknown arkouda_type

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for all column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline ("\n") at this time.



   .. py:method:: to_cuda()

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_cuda())
      numpy.devicendarray



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute') -> str

      Save the pdarray to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_hdf('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_hdf('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving to a single file
      >>> a.to_hdf('path/prefix.hdf5', dataset='array', file_type='single')
      Saves the array in to single hdf5 file on the root node.
      ``cwd/path/name_prefix.hdf5``



   .. py:method:: to_list() -> List

      Convert the array to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the pdarray
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_list()
      [0, 1, 2, 3, 4]
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> np.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the pdarray to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_parquet('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_parqet('path/prefix.parquet', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: transfer(hostname: str, port: int_scalars)

      Sends a pdarray to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the pdarray is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Overwrite the dataset with the name provided with this pdarray. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: value_counts()

      Count the occurrences of the unique values of self.

      :returns: * **unique_values** (*pdarray*) -- The unique values, sorted in ascending order
                * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

      .. rubric:: Examples

      >>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
      (array([0, 2, 4]), array([3, 2, 1]))



   .. py:method:: var(ddof: int_scalars = 0) -> np.float64

      Compute the variance. See ``arkouda.var`` for details.




.. py:class:: pdarray(name: str, mydtype: Union[numpy.dtype, str], size: arkouda.numpy.dtypes.int_scalars, ndim: arkouda.numpy.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.numpy.dtypes.int_scalars, max_bits: Optional[int] = None)

   The basic arkouda array class. This class contains only the
   attributes of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars


   .. py:attribute:: BinOps


   .. py:attribute:: OpEqOps


   .. py:method:: all(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff all elements of the array along the given axis evaluate to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.all(ak.array([True,False,False]))
      False
      >>> ak.all(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([False True False])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([False False False])])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).all()
      False

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.all(a))



   .. py:method:: any(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff any element of the array along the given axis evaluates to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.any(ak.array([True,False,False]))
      True
      >>> ak.any(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([True True True])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([True True True])])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).any()
      True

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.any(a))



   .. py:method:: argmax(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[numpy.int64, numpy.uint64, pdarray]

      Return index of the first occurrence of the maximum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmax(ak.array([1,2,3,4,5]))
      4
      >>> ak.argmax(ak.array([5.5,4.5,3.5,2.5,1.5]))
      0
      >>> ak.array([[1,2,3],[5,4,3]]).argmax(axis=1)
      array([2 0])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmax()) or a standalone function (e.g. ak.argmax(a))



   .. py:method:: argmaxk(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the `k` maximum values of an array.
      See ``arkouda.argmaxk`` for details.



   .. py:method:: argmin(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[numpy.int64, numpy.uint64, pdarray]

      Return index of the first occurrence of the minimum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmin(ak.array([1,2,3,4,5]))
      0
      >>> ak.argmin(ak.array([5.5,4.5,3.5,2.5,1.5]))
      4
      >>> ak.array([[1,2,3],[5,4,3]]).argmin(axis=1)
      array([0 2])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmin()) or a standalone function (e.g. ak.argmin(a))



   .. py:method:: argmink(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the `k` minimum values of an array.
      See ``arkouda.argmink`` for details.



   .. py:method:: astype(dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      .. rubric:: Examples

      >>> ak.array([1,2,3]).astype(ak.float64)
      array([1.00000000000000000 2.00000000000000000 3.00000000000000000])
      >>> ak.array([1.5,2.5]).astype(ak.int64)
      array([1 2])
      >>> ak.array([True,False]).astype(ak.int64)
      array([1 0])

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:


      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to the corresponding server side component which was registered
                with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: bigint_to_uint_arrays() -> List[pdarray]

      Creates a list of uint pdarrays from a bigint pdarray.
      The first item in return will be the highest 64 bits of the
      bigint pdarray and the last item will be the lowest 64 bits.

      :returns: A list of uint pdarrays where:
                The first item in return will be the highest 64 bits of the
                bigint pdarray and the last item will be the lowest 64 bits.
      :rtype: List[pdarrays]

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`pdarraycreation.bigint_from_uint_arrays`

      .. rubric:: Examples

      >>> a = ak.arange(2**64, 2**64 + 5)
      >>> a
      array([18446744073709551616 18446744073709551617 18446744073709551618
      18446744073709551619 18446744073709551620])
      >>> a.bigint_to_uint_arrays()
      [array([1 1 1 1 1]), array([0 1 2 3 4])]



   .. py:method:: clz() -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.



   .. py:method:: corr(y: pdarray) -> numpy.float64

      Compute the correlation between self and y using pearson correlation coefficient.
      See ``arkouda.corr`` for details.



   .. py:method:: cov(y: pdarray) -> numpy.float64

      Compute the covariance between self and y.



   .. py:method:: ctz() -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.



   .. py:attribute:: dtype


   .. py:method:: equals(other) -> arkouda.numpy.dtypes.bool_scalars

      Whether pdarrays are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the pdarrays are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> a = ak.array([1, 2, 3])
      >>> a_cpy = ak.array([1, 2, 3])
      >>> a.equals(a_cpy)
      True
      >>> a2 = ak.array([1, 2, 5)
      >>> a.equals(a2)
      False



   .. py:method:: fill(value: arkouda.numpy.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64



   .. py:method:: flatten()

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.flatten()
      array([3 2 1 2 3 1])



   .. py:method:: format_other(other) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype



   .. py:property:: inferred_type
      :type: Union[str, None]


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. note::

         This will return True if the object is registered itself or as a component
         of another object



   .. py:method:: is_sorted(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff the array (or given axis of the array) is monotonically non-decreasing.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.is_sorted(ak.array([1,2,3,4,5]))
      True
      >>> ak.is_sorted(ak.array([5,4,3,2,1]))
      False
      >>> ak.array([[1,2,3],[5,4,3]]).is_sorted(axis=1)
      array([True False])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.is_sorted()) or a
      standalone function (e.g. ak.is_sorted(a))



   .. py:attribute:: itemsize


   .. py:method:: max(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return max of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.max(ak.array([1,2,3,4,5]))
      5
      >>> ak.max(ak.array([5.5,4.5,3.5,2.5,1.5]))
      5.5
      >>> ak.array([[1,2,3],[5,4,3]]).max(axis=1)
      array([3 5])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.max()) or a standalone function (e.g. ak.max(a))



   .. py:property:: max_bits


   .. py:method:: maxk(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.  See ``arkouda.maxk`` for details.



   .. py:method:: mean() -> numpy.float64

      Compute the mean.  See ``arkouda.mean`` for details.



   .. py:method:: min(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return min of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.min(ak.array([1,2,3,4,5]))
      1
      >>> ak.min(ak.array([5.5,4.5,3.5,2.5,1.5]))
      1.5
      >>> ak.array([[1,2,3],[5,4,3]]).min(axis=1)
      array([1 3])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.min()) or a standalone function (e.g. ak.min(a))



   .. py:method:: mink(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.  See ``arkouda.mink`` for details.



   .. py:attribute:: name


   .. py:property:: nbytes

      The size of the pdarray in bytes.

      :returns: The size of the pdarray in bytes.
      :rtype: int


   .. py:attribute:: ndim


   .. py:attribute:: objType
      :value: 'pdarray'



   .. py:method:: opeq(other, op)


   .. py:method:: parity() -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.



   .. py:method:: popcount() -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: prod(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return prod of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, defalt = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.prod(ak.array([1,2,3,4,5]))
      120
      >>> ak.prod(ak.array([5.5,4.5,3.5,2.5,1.5]))
      324.84375
      >>> ak.array([[1,2,3],[5,4,3]]).prod(axis=1)
      array([6 60])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.prod()) or a standalone function (e.g. ak.prod(a))



   .. py:method:: register(user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:attribute:: registered_name
      :type:  Optional[str]
      :value: None



   .. py:method:: reshape(*shape)

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray

      :returns: a pdarray with the same data, reshaped to the new shape
      :rtype: pdarray

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.reshape((3,2))
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape(3,2)
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape((6,1))
      array([array([3]) array([2]) array([1]) array([2]) array([3]) array([1])])

      .. rubric:: Notes

      only available as a method, not as a standalone function, i.e.,
      a.reshape(compatibleShape) is valid, but ak.reshape(a,compatibleShape) is not.



   .. py:method:: rotl(other) -> pdarray

      Rotate bits left by <other>.



   .. py:method:: rotr(other) -> pdarray

      Rotate bits right by <other>.



   .. py:method:: save(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.save('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.save('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving with an extension (Parquet)
      >>> a.save('path/prefix.parquet', dataset='array', file_format='Parquet')
      Saves the array in numLocales Parquet files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:property:: shape

      Return the shape of an array.

      :returns: The elements of the shape tuple give the lengths of the corresponding array dimensions.
      :rtype: tuple of int


   .. py:attribute:: size


   .. py:method:: slice_bits(low, high) -> pdarray

      Returns a pdarray containing only bits from low to high of self.

      This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
      pda.slice_bits(0, 63)

      :param low: The lowest bit included in the slice (inclusive)
                  zero indexed, so the first bit is 0
      :type low: int
      :param high: The highest bit included in the slice (inclusive)
      :type high: int

      :returns: A new pdarray containing the bits of self from low to high
      :rtype: pdarray

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> p = ak.array([2**65 + (2**64 - 1)])
      >>> bin(p[0])
      '0b101111111111111111111111111111111111111111111111111111111111111111'
      >>> bin(p.slice_bits(64, 65)[0])
      '0b10'
      >>> a = ak.array([143,15])
      >>> a.slice_bits(1,3)
      array([7 7])
      >>> a.slice_bits(4,9)
      array([8 0])
      >>> a.slice_bits(1,9)
      array([71 7])



   .. py:method:: std(ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.



   .. py:method:: sum(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return sum of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.sum(ak.array([1,2,3,4,5]))
      15
      >>> ak.sum(ak.array([5.5,4.5,3.5,2.5,1.5]))
      17.5
      >>> ak.array([[1,2,3],[5,4,3]]).sum(axis=1)
      array([6 12])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.sum()) or a standalone function (e.g. ak.sum(a))



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'array', col_delim: str = ',', overwrite: bool = False)

      Write pdarry to CSV file(s).  File will contain a single column
      with the pdarray data.  All CSV files written by Arkouda include
      a header denoting data types of the columns.

      :param prefix_path: filename prefix to be used for saving files.  Files will have
                          _LOCALE#### appended when they are written to disk.
      :type prefix_path: str
      :param dataset: column name to save the pdarray under.
      :type dataset: str, defaults to "array"
      :param col_delim: value to be used to separate columns within the file.  Please
                        be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, defaults to ","
      :param overwrite: If True, existing files matching the provided path will be overwritten.
                        if False and existing files are found, an error will be returned.
      :type overwrite: bool, defaults to False

      :returns: **response message**
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one
          or more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          if 'allow_errors' is true, this may be raised if no values are returned
          from the server.
      :raises TypeError: Raise if the server returns an unknown arkouda_type

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for all column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline ("\n") at this time.



   .. py:method:: to_cuda()

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_cuda())
      numpy.devicendarray



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute') -> str

      Save the pdarray to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_hdf('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_hdf('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving to a single file
      >>> a.to_hdf('path/prefix.hdf5', dataset='array', file_type='single')
      Saves the array in to single hdf5 file on the root node.
      ``cwd/path/name_prefix.hdf5``



   .. py:method:: to_list() -> List

      Convert the array to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the pdarray
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_list()
      [0, 1, 2, 3, 4]
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the pdarray to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_parquet('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_parqet('path/prefix.parquet', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: transfer(hostname: str, port: arkouda.numpy.dtypes.int_scalars)

      Sends a pdarray to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the pdarray is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Overwrite the dataset with the name provided with this pdarray. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: value_counts()

      Count the occurrences of the unique values of self.

      :returns: * **unique_values** (*pdarray*) -- The unique values, sorted in ascending order
                * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

      .. rubric:: Examples

      >>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
      (array([0, 2, 4]), array([3, 2, 1]))



   .. py:method:: var(ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.



.. py:class:: pdarray(name: str, mydtype: Union[numpy.dtype, str], size: arkouda.numpy.dtypes.int_scalars, ndim: arkouda.numpy.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.numpy.dtypes.int_scalars, max_bits: Optional[int] = None)

   The basic arkouda array class. This class contains only the
   attributes of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars


   .. py:attribute:: BinOps


   .. py:attribute:: OpEqOps


   .. py:method:: all(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff all elements of the array along the given axis evaluate to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.all(ak.array([True,False,False]))
      False
      >>> ak.all(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([False True False])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([False False False])])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).all()
      False

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.all(a))



   .. py:method:: any(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff any element of the array along the given axis evaluates to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.any(ak.array([True,False,False]))
      True
      >>> ak.any(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([True True True])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([True True True])])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).any()
      True

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.any(a))



   .. py:method:: argmax(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[numpy.int64, numpy.uint64, pdarray]

      Return index of the first occurrence of the maximum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmax(ak.array([1,2,3,4,5]))
      4
      >>> ak.argmax(ak.array([5.5,4.5,3.5,2.5,1.5]))
      0
      >>> ak.array([[1,2,3],[5,4,3]]).argmax(axis=1)
      array([2 0])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmax()) or a standalone function (e.g. ak.argmax(a))



   .. py:method:: argmaxk(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the `k` maximum values of an array.
      See ``arkouda.argmaxk`` for details.



   .. py:method:: argmin(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[numpy.int64, numpy.uint64, pdarray]

      Return index of the first occurrence of the minimum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmin(ak.array([1,2,3,4,5]))
      0
      >>> ak.argmin(ak.array([5.5,4.5,3.5,2.5,1.5]))
      4
      >>> ak.array([[1,2,3],[5,4,3]]).argmin(axis=1)
      array([0 2])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmin()) or a standalone function (e.g. ak.argmin(a))



   .. py:method:: argmink(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the `k` minimum values of an array.
      See ``arkouda.argmink`` for details.



   .. py:method:: astype(dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      .. rubric:: Examples

      >>> ak.array([1,2,3]).astype(ak.float64)
      array([1.00000000000000000 2.00000000000000000 3.00000000000000000])
      >>> ak.array([1.5,2.5]).astype(ak.int64)
      array([1 2])
      >>> ak.array([True,False]).astype(ak.int64)
      array([1 0])

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:


      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to the corresponding server side component which was registered
                with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: bigint_to_uint_arrays() -> List[pdarray]

      Creates a list of uint pdarrays from a bigint pdarray.
      The first item in return will be the highest 64 bits of the
      bigint pdarray and the last item will be the lowest 64 bits.

      :returns: A list of uint pdarrays where:
                The first item in return will be the highest 64 bits of the
                bigint pdarray and the last item will be the lowest 64 bits.
      :rtype: List[pdarrays]

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`pdarraycreation.bigint_from_uint_arrays`

      .. rubric:: Examples

      >>> a = ak.arange(2**64, 2**64 + 5)
      >>> a
      array([18446744073709551616 18446744073709551617 18446744073709551618
      18446744073709551619 18446744073709551620])
      >>> a.bigint_to_uint_arrays()
      [array([1 1 1 1 1]), array([0 1 2 3 4])]



   .. py:method:: clz() -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.



   .. py:method:: corr(y: pdarray) -> numpy.float64

      Compute the correlation between self and y using pearson correlation coefficient.
      See ``arkouda.corr`` for details.



   .. py:method:: cov(y: pdarray) -> numpy.float64

      Compute the covariance between self and y.



   .. py:method:: ctz() -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.



   .. py:attribute:: dtype


   .. py:method:: equals(other) -> arkouda.numpy.dtypes.bool_scalars

      Whether pdarrays are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the pdarrays are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> a = ak.array([1, 2, 3])
      >>> a_cpy = ak.array([1, 2, 3])
      >>> a.equals(a_cpy)
      True
      >>> a2 = ak.array([1, 2, 5)
      >>> a.equals(a2)
      False



   .. py:method:: fill(value: arkouda.numpy.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64



   .. py:method:: flatten()

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.flatten()
      array([3 2 1 2 3 1])



   .. py:method:: format_other(other) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype



   .. py:property:: inferred_type
      :type: Union[str, None]


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. note::

         This will return True if the object is registered itself or as a component
         of another object



   .. py:method:: is_sorted(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff the array (or given axis of the array) is monotonically non-decreasing.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.is_sorted(ak.array([1,2,3,4,5]))
      True
      >>> ak.is_sorted(ak.array([5,4,3,2,1]))
      False
      >>> ak.array([[1,2,3],[5,4,3]]).is_sorted(axis=1)
      array([True False])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.is_sorted()) or a
      standalone function (e.g. ak.is_sorted(a))



   .. py:attribute:: itemsize


   .. py:method:: max(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return max of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.max(ak.array([1,2,3,4,5]))
      5
      >>> ak.max(ak.array([5.5,4.5,3.5,2.5,1.5]))
      5.5
      >>> ak.array([[1,2,3],[5,4,3]]).max(axis=1)
      array([3 5])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.max()) or a standalone function (e.g. ak.max(a))



   .. py:property:: max_bits


   .. py:method:: maxk(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.  See ``arkouda.maxk`` for details.



   .. py:method:: mean() -> numpy.float64

      Compute the mean.  See ``arkouda.mean`` for details.



   .. py:method:: min(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return min of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.min(ak.array([1,2,3,4,5]))
      1
      >>> ak.min(ak.array([5.5,4.5,3.5,2.5,1.5]))
      1.5
      >>> ak.array([[1,2,3],[5,4,3]]).min(axis=1)
      array([1 3])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.min()) or a standalone function (e.g. ak.min(a))



   .. py:method:: mink(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.  See ``arkouda.mink`` for details.



   .. py:attribute:: name


   .. py:property:: nbytes

      The size of the pdarray in bytes.

      :returns: The size of the pdarray in bytes.
      :rtype: int


   .. py:attribute:: ndim


   .. py:attribute:: objType
      :value: 'pdarray'



   .. py:method:: opeq(other, op)


   .. py:method:: parity() -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.



   .. py:method:: popcount() -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: prod(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return prod of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, defalt = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.prod(ak.array([1,2,3,4,5]))
      120
      >>> ak.prod(ak.array([5.5,4.5,3.5,2.5,1.5]))
      324.84375
      >>> ak.array([[1,2,3],[5,4,3]]).prod(axis=1)
      array([6 60])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.prod()) or a standalone function (e.g. ak.prod(a))



   .. py:method:: register(user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:attribute:: registered_name
      :type:  Optional[str]
      :value: None



   .. py:method:: reshape(*shape)

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray

      :returns: a pdarray with the same data, reshaped to the new shape
      :rtype: pdarray

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.reshape((3,2))
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape(3,2)
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape((6,1))
      array([array([3]) array([2]) array([1]) array([2]) array([3]) array([1])])

      .. rubric:: Notes

      only available as a method, not as a standalone function, i.e.,
      a.reshape(compatibleShape) is valid, but ak.reshape(a,compatibleShape) is not.



   .. py:method:: rotl(other) -> pdarray

      Rotate bits left by <other>.



   .. py:method:: rotr(other) -> pdarray

      Rotate bits right by <other>.



   .. py:method:: save(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.save('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.save('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving with an extension (Parquet)
      >>> a.save('path/prefix.parquet', dataset='array', file_format='Parquet')
      Saves the array in numLocales Parquet files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:property:: shape

      Return the shape of an array.

      :returns: The elements of the shape tuple give the lengths of the corresponding array dimensions.
      :rtype: tuple of int


   .. py:attribute:: size


   .. py:method:: slice_bits(low, high) -> pdarray

      Returns a pdarray containing only bits from low to high of self.

      This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
      pda.slice_bits(0, 63)

      :param low: The lowest bit included in the slice (inclusive)
                  zero indexed, so the first bit is 0
      :type low: int
      :param high: The highest bit included in the slice (inclusive)
      :type high: int

      :returns: A new pdarray containing the bits of self from low to high
      :rtype: pdarray

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> p = ak.array([2**65 + (2**64 - 1)])
      >>> bin(p[0])
      '0b101111111111111111111111111111111111111111111111111111111111111111'
      >>> bin(p.slice_bits(64, 65)[0])
      '0b10'
      >>> a = ak.array([143,15])
      >>> a.slice_bits(1,3)
      array([7 7])
      >>> a.slice_bits(4,9)
      array([8 0])
      >>> a.slice_bits(1,9)
      array([71 7])



   .. py:method:: std(ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.



   .. py:method:: sum(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return sum of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.sum(ak.array([1,2,3,4,5]))
      15
      >>> ak.sum(ak.array([5.5,4.5,3.5,2.5,1.5]))
      17.5
      >>> ak.array([[1,2,3],[5,4,3]]).sum(axis=1)
      array([6 12])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.sum()) or a standalone function (e.g. ak.sum(a))



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'array', col_delim: str = ',', overwrite: bool = False)

      Write pdarry to CSV file(s).  File will contain a single column
      with the pdarray data.  All CSV files written by Arkouda include
      a header denoting data types of the columns.

      :param prefix_path: filename prefix to be used for saving files.  Files will have
                          _LOCALE#### appended when they are written to disk.
      :type prefix_path: str
      :param dataset: column name to save the pdarray under.
      :type dataset: str, defaults to "array"
      :param col_delim: value to be used to separate columns within the file.  Please
                        be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, defaults to ","
      :param overwrite: If True, existing files matching the provided path will be overwritten.
                        if False and existing files are found, an error will be returned.
      :type overwrite: bool, defaults to False

      :returns: **response message**
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one
          or more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          if 'allow_errors' is true, this may be raised if no values are returned
          from the server.
      :raises TypeError: Raise if the server returns an unknown arkouda_type

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for all column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline ("\n") at this time.



   .. py:method:: to_cuda()

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_cuda())
      numpy.devicendarray



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute') -> str

      Save the pdarray to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_hdf('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_hdf('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving to a single file
      >>> a.to_hdf('path/prefix.hdf5', dataset='array', file_type='single')
      Saves the array in to single hdf5 file on the root node.
      ``cwd/path/name_prefix.hdf5``



   .. py:method:: to_list() -> List

      Convert the array to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the pdarray
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_list()
      [0, 1, 2, 3, 4]
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the pdarray to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_parquet('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_parqet('path/prefix.parquet', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: transfer(hostname: str, port: arkouda.numpy.dtypes.int_scalars)

      Sends a pdarray to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the pdarray is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Overwrite the dataset with the name provided with this pdarray. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: value_counts()

      Count the occurrences of the unique values of self.

      :returns: * **unique_values** (*pdarray*) -- The unique values, sorted in ascending order
                * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

      .. rubric:: Examples

      >>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
      (array([0, 2, 4]), array([3, 2, 1]))



   .. py:method:: var(ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.



.. py:class:: pdarray(name: str, mydtype: Union[numpy.dtype, str], size: arkouda.numpy.dtypes.int_scalars, ndim: arkouda.numpy.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.numpy.dtypes.int_scalars, max_bits: Optional[int] = None)

   The basic arkouda array class. This class contains only the
   attributes of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars


   .. py:attribute:: BinOps


   .. py:attribute:: OpEqOps


   .. py:method:: all(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff all elements of the array along the given axis evaluate to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.all(ak.array([True,False,False]))
      False
      >>> ak.all(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([False True False])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([False False False])])
      >>> ak.all(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).all()
      False

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.all(a))



   .. py:method:: any(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff any element of the array along the given axis evaluates to True.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      .. rubric:: Examples

      >>> ak.any(ak.array([True,False,False]))
      True
      >>> ak.any(ak.array([[True,True,False],[False,True,True]]),axis=0)
      array([True True True])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=0,keepdims=True)
      array([array([True True True])])
      >>> ak.any(ak.array([[True,True,True],[False,False,False]]),axis=1,keepdims=True)
      array([array([True]) array([False])])
      >>> ak.array([True,False,False]).any()
      True

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.any()) or a standalone function (e.g. ak.any(a))



   .. py:method:: argmax(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[numpy.int64, numpy.uint64, pdarray]

      Return index of the first occurrence of the maximum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmax(ak.array([1,2,3,4,5]))
      4
      >>> ak.argmax(ak.array([5.5,4.5,3.5,2.5,1.5]))
      0
      >>> ak.array([[1,2,3],[5,4,3]]).argmax(axis=1)
      array([2 0])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmax()) or a standalone function (e.g. ak.argmax(a))



   .. py:method:: argmaxk(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the `k` maximum values of an array.
      See ``arkouda.argmaxk`` for details.



   .. py:method:: argmin(axis: Optional[Union[int, None]] = None, keepdims: bool = False) -> Union[numpy.int64, numpy.uint64, pdarray]

      Return index of the first occurrence of the minimum along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: int64 or uint64 if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: int64, uint64 or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.argmin(ak.array([1,2,3,4,5]))
      0
      >>> ak.argmin(ak.array([5.5,4.5,3.5,2.5,1.5]))
      4
      >>> ak.array([[1,2,3],[5,4,3]]).argmin(axis=1)
      array([0 2])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.argmin()) or a standalone function (e.g. ak.argmin(a))



   .. py:method:: argmink(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the `k` minimum values of an array.
      See ``arkouda.argmink`` for details.



   .. py:method:: astype(dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      .. rubric:: Examples

      >>> ak.array([1,2,3]).astype(ak.float64)
      array([1.00000000000000000 2.00000000000000000 3.00000000000000000])
      >>> ak.array([1.5,2.5]).astype(ak.int64)
      array([1 2])
      >>> ak.array([True,False]).astype(ak.int64)
      array([1 0])

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:


      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to the corresponding server side component which was registered
                with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: bigint_to_uint_arrays() -> List[pdarray]

      Creates a list of uint pdarrays from a bigint pdarray.
      The first item in return will be the highest 64 bits of the
      bigint pdarray and the last item will be the lowest 64 bits.

      :returns: A list of uint pdarrays where:
                The first item in return will be the highest 64 bits of the
                bigint pdarray and the last item will be the lowest 64 bits.
      :rtype: List[pdarrays]

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`pdarraycreation.bigint_from_uint_arrays`

      .. rubric:: Examples

      >>> a = ak.arange(2**64, 2**64 + 5)
      >>> a
      array([18446744073709551616 18446744073709551617 18446744073709551618
      18446744073709551619 18446744073709551620])
      >>> a.bigint_to_uint_arrays()
      [array([1 1 1 1 1]), array([0 1 2 3 4])]



   .. py:method:: clz() -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.



   .. py:method:: corr(y: pdarray) -> numpy.float64

      Compute the correlation between self and y using pearson correlation coefficient.
      See ``arkouda.corr`` for details.



   .. py:method:: cov(y: pdarray) -> numpy.float64

      Compute the covariance between self and y.



   .. py:method:: ctz() -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.



   .. py:attribute:: dtype


   .. py:method:: equals(other) -> arkouda.numpy.dtypes.bool_scalars

      Whether pdarrays are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the pdarrays are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> a = ak.array([1, 2, 3])
      >>> a_cpy = ak.array([1, 2, 3])
      >>> a.equals(a_cpy)
      True
      >>> a2 = ak.array([1, 2, 5)
      >>> a.equals(a2)
      False



   .. py:method:: fill(value: arkouda.numpy.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64



   .. py:method:: flatten()

      Return a copy of the array collapsed into one dimension.

      :rtype: A copy of the input array, flattened to one dimension.

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.flatten()
      array([3 2 1 2 3 1])



   .. py:method:: format_other(other) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype



   .. py:property:: inferred_type
      :type: Union[str, None]


      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. note::

         This will return True if the object is registered itself or as a component
         of another object



   .. py:method:: is_sorted(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.bool_scalars, pdarray]

      Return True iff the array (or given axis of the array) is monotonically non-decreasing.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: boolean if axis is omitted, else pdarray if axis is supplied
      :rtype: boolean or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.is_sorted(ak.array([1,2,3,4,5]))
      True
      >>> ak.is_sorted(ak.array([5,4,3,2,1]))
      False
      >>> ak.array([[1,2,3],[5,4,3]]).is_sorted(axis=1)
      array([True False])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.is_sorted()) or a
      standalone function (e.g. ak.is_sorted(a))



   .. py:attribute:: itemsize


   .. py:method:: max(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return max of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.max(ak.array([1,2,3,4,5]))
      5
      >>> ak.max(ak.array([5.5,4.5,3.5,2.5,1.5]))
      5.5
      >>> ak.array([[1,2,3],[5,4,3]]).max(axis=1)
      array([3 5])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.max()) or a standalone function (e.g. ak.max(a))



   .. py:property:: max_bits


   .. py:method:: maxk(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.  See ``arkouda.maxk`` for details.



   .. py:method:: mean() -> numpy.float64

      Compute the mean.  See ``arkouda.mean`` for details.



   .. py:method:: min(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return min of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.min(ak.array([1,2,3,4,5]))
      1
      >>> ak.min(ak.array([5.5,4.5,3.5,2.5,1.5]))
      1.5
      >>> ak.array([[1,2,3],[5,4,3]]).min(axis=1)
      array([1 3])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.min()) or a standalone function (e.g. ak.min(a))



   .. py:method:: mink(k: arkouda.numpy.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.  See ``arkouda.mink`` for details.



   .. py:attribute:: name


   .. py:property:: nbytes

      The size of the pdarray in bytes.

      :returns: The size of the pdarray in bytes.
      :rtype: int


   .. py:attribute:: ndim


   .. py:attribute:: objType
      :value: 'pdarray'



   .. py:method:: opeq(other, op)


   .. py:method:: parity() -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.



   .. py:method:: popcount() -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: prod(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return prod of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, defalt = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.prod(ak.array([1,2,3,4,5]))
      120
      >>> ak.prod(ak.array([5.5,4.5,3.5,2.5,1.5]))
      324.84375
      >>> ak.array([[1,2,3],[5,4,3]]).prod(axis=1)
      array([6 60])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.prod()) or a standalone function (e.g. ak.prod(a))



   .. py:method:: register(user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:attribute:: registered_name
      :type:  Optional[str]
      :value: None



   .. py:method:: reshape(*shape)

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray

      :returns: a pdarray with the same data, reshaped to the new shape
      :rtype: pdarray

      .. rubric:: Examples

      >>> a = ak.array([[3,2,1],[2,3,1]])
      >>> a.reshape((3,2))
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape(3,2)
      array([array([3 2]) array([1 2]) array([3 1])])
      >>> a.reshape((6,1))
      array([array([3]) array([2]) array([1]) array([2]) array([3]) array([1])])

      .. rubric:: Notes

      only available as a method, not as a standalone function, i.e.,
      a.reshape(compatibleShape) is valid, but ak.reshape(a,compatibleShape) is not.



   .. py:method:: rotl(other) -> pdarray

      Rotate bits left by <other>.



   .. py:method:: rotr(other) -> pdarray

      Rotate bits right by <other>.



   .. py:method:: save(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.save('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.save('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving with an extension (Parquet)
      >>> a.save('path/prefix.parquet', dataset='array', file_format='Parquet')
      Saves the array in numLocales Parquet files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:property:: shape

      Return the shape of an array.

      :returns: The elements of the shape tuple give the lengths of the corresponding array dimensions.
      :rtype: tuple of int


   .. py:attribute:: size


   .. py:method:: slice_bits(low, high) -> pdarray

      Returns a pdarray containing only bits from low to high of self.

      This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
      pda.slice_bits(0, 63)

      :param low: The lowest bit included in the slice (inclusive)
                  zero indexed, so the first bit is 0
      :type low: int
      :param high: The highest bit included in the slice (inclusive)
      :type high: int

      :returns: A new pdarray containing the bits of self from low to high
      :rtype: pdarray

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> p = ak.array([2**65 + (2**64 - 1)])
      >>> bin(p[0])
      '0b101111111111111111111111111111111111111111111111111111111111111111'
      >>> bin(p.slice_bits(64, 65)[0])
      '0b10'
      >>> a = ak.array([143,15])
      >>> a.slice_bits(1,3)
      array([7 7])
      >>> a.slice_bits(4,9)
      array([8 0])
      >>> a.slice_bits(1,9)
      array([71 7])



   .. py:method:: std(ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.



   .. py:method:: sum(axis: Optional[Union[int, Tuple[int, Ellipsis]]] = None, keepdims: bool = False) -> Union[arkouda.numpy.dtypes.numpy_scalars, pdarray]

      Return sum of array elements along the given axis.

      :param axis: The axis or axes along which to do the operation
                   If None, the computation is done across the entire array.
      :type axis: int, Tuple[int, ...], optional, default = None
      :param keepdims: Whether to keep the singleton dimension(s) along `axis` in the result.
      :type keepdims: bool, optional, default = False

      :returns: numpy_scalar if axis is omitted, in which case operation is done over entire array
                pdarray if axis is supplied, in which case the operation is done along that axis
      :rtype: numpy_scalar or pdarray

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown

      .. rubric:: Examples

      >>> ak.sum(ak.array([1,2,3,4,5]))
      15
      >>> ak.sum(ak.array([5.5,4.5,3.5,2.5,1.5]))
      17.5
      >>> ak.array([[1,2,3],[5,4,3]]).sum(axis=1)
      array([6 12])

      .. rubric:: Notes

      Works as a method of a pdarray (e.g. a.sum()) or a standalone function (e.g. ak.sum(a))



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'array', col_delim: str = ',', overwrite: bool = False)

      Write pdarry to CSV file(s).  File will contain a single column
      with the pdarray data.  All CSV files written by Arkouda include
      a header denoting data types of the columns.

      :param prefix_path: filename prefix to be used for saving files.  Files will have
                          _LOCALE#### appended when they are written to disk.
      :type prefix_path: str
      :param dataset: column name to save the pdarray under.
      :type dataset: str, defaults to "array"
      :param col_delim: value to be used to separate columns within the file.  Please
                        be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str, defaults to ","
      :param overwrite: If True, existing files matching the provided path will be overwritten.
                        if False and existing files are found, an error will be returned.
      :type overwrite: bool, defaults to False

      :returns: **response message**
      :rtype: str

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one
          or more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          if 'allow_errors' is true, this may be raised if no values are returned
          from the server.
      :raises TypeError: Raise if the server returns an unknown arkouda_type

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for all column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline ("\n") at this time.



   .. py:method:: to_cuda()

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_cuda())
      numpy.devicendarray



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute') -> str

      Save the pdarray to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_hdf('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_hdf('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving to a single file
      >>> a.to_hdf('path/prefix.hdf5', dataset='array', file_type='single')
      Saves the array in to single hdf5 file on the root node.
      ``cwd/path/name_prefix.hdf5``



   .. py:method:: to_list() -> List

      Convert the array to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the pdarray
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_list()
      [0, 1, 2, 3, 4]
      >>> type(a.to_list())
      <class 'list'>



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])
      >>> type(a.to_ndarray())
      <class 'numpy.ndarray'>



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the pdarray to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_parquet('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_parqet('path/prefix.parquet', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: transfer(hostname: str, port: arkouda.numpy.dtypes.int_scalars)

      Sends a pdarray to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the pdarray is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Overwrite the dataset with the name provided with this pdarray. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: value_counts()

      Count the occurrences of the unique values of self.

      :returns: * **unique_values** (*pdarray*) -- The unique values, sorted in ascending order
                * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

      .. rubric:: Examples

      >>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
      (array([0, 2, 4]), array([3, 2, 1]))



   .. py:method:: var(ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.



.. py:function:: popcount(pda: pdarray) -> pdarray

   Find the population (number of bits set) for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64, bigint

   :returns: **population** -- The number of bits set (1) in each element
   :rtype: pdarray

   :raises TypeError: If input array is not int64, uint64, or bigint

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.popcount(A)
   array([0, 1, 1, 2, 1, 2, 2, 3, 1, 2])


.. py:function:: power(pda: pdarray, pwr: Union[int, float, pdarray], where: Union[arkouda.numpy.dtypes.bool_scalars, pdarray] = True) -> pdarray

   Raises an array to a power. If where is given, the operation will only take place in the positions
   where the where condition is True.

   Note:
   Our implementation of the where argument deviates from numpy. The difference in behavior occurs
   at positions where the where argument contains a False. In numpy, these position will have
   uninitialized memory (which can contain anything and will vary between runs). We have chosen to
   instead return the value of the original array in these positions.

   :param pda: A pdarray of values that will be raised to a power (pwr)
   :type pda: pdarray
   :param pwr: The power(s) that pda is raised to
   :type pwr: integer, float, or pdarray
   :param where: This condition is broadcast over the input. At locations where the condition is True, the
                 corresponding value will be raised to the respective power. Elsewhere, it will retain its
                 original value. Default set to True.
   :type where: Boolean or pdarray

   :returns: a pdarray of values raised to a power, under the boolean where condition.
   :rtype: pdarray

   .. rubric:: Examples

   >>> a = ak.arange(5)
   >>> ak.power(a, 3)
   array([0, 1, 8, 27, 64])
   >>> ak.power(a), 3, a % 2 == 0)
   array([0, 1, 8, 3, 64])

   :raises TypeError: raised if pda is not a pdarray, or if pwe is not an int, float, or pdarray
   :raises ValueError: raised if pda and power are of incompatible dimensions


.. py:function:: promote_to_common_dtype(arrays: List[arkouda.numpy.pdarrayclass.pdarray]) -> Tuple[Any, List[arkouda.numpy.pdarrayclass.pdarray]]

   Promote a list of pdarrays to a common dtype.

   :param arrays: List of pdarrays to promote
   :type arrays: List[pdarray]

   :returns: The common dtype of the pdarrays and the list of pdarrays promoted to that dtype
   :rtype: dtype, List[pdarray]

   :raises TypeError: Raised if any pdarray is a non-numeric type

   .. seealso:: :obj:`pdarray.promote_dtype`

   .. rubric:: Examples

   >>> a = ak.arange(5)
   >>> b = ak.ones(5, dtype=ak.float64)
   >>> dtype, promoted = ak.promote_to_common_dtype([a, b])
   >>> dtype
   dtype('float64')
   >>> all(isinstance(p, ak.pdarray) and p.dtype == dtype for p in promoted)
   True


.. py:function:: randint(low: arkouda.numpy.dtypes.numeric_scalars, high: arkouda.numpy.dtypes.numeric_scalars, size: Union[arkouda.numpy.dtypes.int_scalars, Tuple[arkouda.numpy.dtypes.int_scalars, Ellipsis]] = 1, dtype=akint64, seed: Optional[arkouda.numpy.dtypes.int_scalars] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Generate a pdarray of randomized int, float, or bool values in a
   specified range bounded by the low and high parameters.

   :param low: The low value (inclusive) of the range
   :type low: numeric_scalars
   :param high: The high value (exclusive for int, inclusive for float) of the range
   :type high: numeric_scalars
   :param size: The size or shape of the returned array
   :type size: int_scalars or tuple of int_scalars
   :param dtype: The dtype of the array
   :type dtype: Union[int64, float64, bool]
   :param seed: Index for where to pull the first returned value
   :type seed: int_scalars, optional

   :returns: Values drawn uniformly from the specified range having the desired dtype
   :rtype: pdarray

   :raises TypeError: Raised if dtype.name not in DTypes, size is not an int, low or high is
       not an int or float, or seed is not an int
   :raises ValueError: Raised if size < 0 or if high < low

   .. rubric:: Notes

   Calling randint with dtype=float64 will result in uniform non-integral
   floating point values.

   Ranges >= 2**64 in size is undefined behavior because
   it exceeds the maximum value that can be stored on the server (uint64)

   .. rubric:: Examples

   >>> ak.randint(0, 10, 5, seed=1701)
   array([6 5 1 6 3])

   >>> ak.randint(0, 1, 3, seed=1701, dtype=ak.float64)
   array([0.011410423448327005 0.73618171558685619 0.12367222192448891])

   >>> ak.randint(0, 1, 5, seed=1701, dtype=ak.bool_)
   array([False True False True False])


.. py:function:: random_strings_lognormal(logmean: arkouda.numpy.dtypes.numeric_scalars, logstd: arkouda.numpy.dtypes.numeric_scalars, size: arkouda.numpy.dtypes.int_scalars, characters: str = 'uppercase', seed: Optional[arkouda.numpy.dtypes.int_scalars] = None) -> arkouda.numpy.strings.Strings

   Generate random strings with log-normally distributed lengths and
   with characters drawn from a specified set.

   :param logmean: The log-mean of the length distribution
   :type logmean: numeric_scalars
   :param logstd: The log-standard-deviation of the length distribution
   :type logstd: numeric_scalars
   :param size: The number of strings to generate
   :type size: int_scalars
   :param characters: The set of characters to draw from
   :type characters: (uppercase, lowercase, numeric, printable, binary)
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars, optional

   :returns: The Strings object encapsulating a pdarray of random strings
   :rtype: Strings

   :raises TypeError: Raised if logmean is neither a float nor a int, logstd is not a float,
       seed is not an int, size is not an int, or if characters is not a str
   :raises ValueError: Raised if logstd <= 0 or size < 0

   .. seealso:: :obj:`random_strings_lognormal`, :obj:`randint`

   .. rubric:: Notes

   The lengths of the generated strings are distributed $Lognormal(\mu, \sigma^2)$,
   with :math:`\mu = logmean` and :math:`\sigma = logstd`. Thus, the strings will
   have an average length of :math:`exp(\mu + 0.5*\sigma^2)`, a minimum length of
   zero, and a heavy tail towards longer strings.

   .. rubric:: Examples

   >>> ak.random_strings_lognormal(2, 0.25, 5, seed=1)
   array(['VWHJEX', 'BEBBXJHGM', 'RWOVKBUR', 'LNJCSDXD', 'NKEDQC'])

   >>> ak.random_strings_lognormal(2, 0.25, 5, seed=1, characters='printable')
   array(['eL96<O', ')o-GOe lR', ')PV yHf(', '._b3Yc&K', ',7Wjef'])


.. py:function:: random_strings_uniform(minlen: arkouda.numpy.dtypes.int_scalars, maxlen: arkouda.numpy.dtypes.int_scalars, size: arkouda.numpy.dtypes.int_scalars, characters: str = 'uppercase', seed: Union[None, arkouda.numpy.dtypes.int_scalars] = None) -> arkouda.numpy.strings.Strings

   Generate random strings with lengths uniformly distributed between
   minlen and maxlen, and with characters drawn from a specified set.

   :param minlen: The minimum allowed length of string
   :type minlen: int_scalars
   :param maxlen: The maximum allowed length of string
   :type maxlen: int_scalars
   :param size: The number of strings to generate
   :type size: int_scalars
   :param characters: The set of characters to draw from
   :type characters: (uppercase, lowercase, numeric, printable, binary)
   :param seed: Value used to initialize the random number generator
   :type seed: Union[None, int_scalars], optional

   :returns: The array of random strings
   :rtype: Strings

   :raises ValueError: Raised if minlen < 0, maxlen < minlen, or size < 0

   .. seealso:: :obj:`random_strings_lognormal`, :obj:`randint`

   .. rubric:: Examples

   >>> ak.random_strings_uniform(minlen=1, maxlen=5, seed=8675309, size=5)
   array(['ECWO', 'WSS', 'TZG', 'RW', 'C'])

   >>> ak.random_strings_uniform(minlen=1, maxlen=5, seed=8675309, size=5,
   ... characters='printable')
   array(['2 .z', 'aom', '2d|', 'o(', 'M'])


.. py:function:: register_all(data: dict)

   Register all objects in the provided dictionary

   :param data: Maps name to register the object to the object. For example, {"MyArray": ak.array([0, 1, 2])
   :type data: dict

   :rtype: None


.. py:function:: resolve_scalar_dtype(val: object) -> str

   Try to infer what dtype arkouda_server should treat val as.

   :param val: The object to determine the dtype of.
   :type val: object

   :returns: The dtype name, if it can be resolved, otherwise the type (as str).
   :rtype: str

   .. rubric:: Examples

   >>> ak.resolve_scalar_dtype(1)
   'int64'
   >>> ak.resolve_scalar_dtype(2.0)
   'float64'


.. py:function:: rotl(x, rot) -> pdarray

   Rotate bits of <x> to the left by <rot>.

   :param x: Value(s) to rotate left.
   :type x: pdarray(int64/uint64) or integer
   :param rot: Amount(s) to rotate by.
   :type rot: pdarray(int64/uint64) or integer

   :returns: **rotated** -- The rotated elements of x.
   :rtype: pdarray(int64/uint64)

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.rotl(A, A)
   array([0, 2, 8, 24, 64, 160, 384, 896, 2048, 4608])


.. py:function:: rotr(x, rot) -> pdarray

   Rotate bits of <x> to the left by <rot>.

   :param x: Value(s) to rotate left.
   :type x: pdarray(int64/uint64) or integer
   :param rot: Amount(s) to rotate by.
   :type rot: pdarray(int64/uint64) or integer

   :returns: **rotated** -- The rotated elements of x.
   :rtype: pdarray(int64/uint64)

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.rotr(1024 * A, A)
   array([0, 512, 512, 384, 256, 160, 96, 56, 32, 18])


.. py:function:: scalar_array(value: arkouda.numpy.dtypes.numeric_scalars, dtype: Optional[Union[numpy.dtype, type, str, arkouda.numpy.dtypes.bigint]] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Create a pdarray from a single scalar value.

   :param value: Value to create pdarray from
   :type value: numeric_scalars

   :returns: pdarray with a single element
   :rtype: pdarray

   .. rubric:: Examples

   >>> ak.scalar_array(5)
   array([5])

   >>> ak.scalar_array(7.0)
   array([7.00000000000000000])

   :raises RuntimeError: Raised if value cannot be cast as dtype


.. py:function:: segarray(segments: arkouda.numpy.pdarrayclass.pdarray, values: arkouda.numpy.pdarrayclass.pdarray, lengths=None, grouping=None)

   Alias for the from_parts function. Prevents user from needing to call `ak.SegArray` constructor
   DEPRECATED


.. py:function:: setdiff1d(A: arkouda.groupbyclass.groupable, B: arkouda.groupbyclass.groupable, assume_unique: bool = False) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.groupbyclass.groupable]

   Find the set difference of two arrays.

   Return the sorted, unique values in `A` that are not in `B`.

   :param A:
   :type A: list of pdarrays, pdarray, Strings, or Categorical
   :param B:
   :type B: list of pdarrays, pdarray, Strings, or Categorical
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array/List of sorted pdarrays of values in `A` that are not in `B`.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either A or B is not a pdarray
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. seealso:: :obj:`arkouda.groupbyclass.unique`, :obj:`setxor1d`

   .. rubric:: Notes

   ak.setdiff1d is not supported for bool pdarrays

   .. rubric:: Examples

   >>> a = ak.array([1, 2, 3, 2, 4, 1])
   >>> b = ak.array([3, 4, 5, 6])
   >>> ak.setdiff1d(a, b)
   array([1 2])

   Multi-Array Example

   >>> a = ak.arange(1, 6)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.setdiff1d(multia, multib)
   [array([2 4 5]), array([2 4 5]), array([2 4 5])]


.. py:function:: setxor1d(A: arkouda.groupbyclass.groupable, B: arkouda.groupbyclass.groupable, assume_unique: bool = False) -> Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.groupbyclass.groupable]

   Find the set exclusive-or (symmetric difference) of two arrays.

   Return the sorted, unique values that are in only one (not both) of the
   input arrays.

   :param A:
   :type A: list of pdarrays, pdarray, Strings, or Categorical
   :param B:
   :type B: list of pdarrays, pdarray, Strings, or Categorical
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array/List of sorted pdarrays of unique values that are in only one of the input
             arrays.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either A or B is not a groupable
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. rubric:: Examples

   >>> a = ak.array([1, 2, 3, 2, 4])
   >>> b = ak.array([2, 3, 5, 7, 5])
   >>> ak.setxor1d(a,b)
   array([1 4 5 7])

   Multi-Array Example

   >>> a = ak.arange(1, 6)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.setxor1d(multia, multib)
   [array([2 2 4 4 5 5]), array([2 5 2 4 4 5]), array([2 4 5 4 2 5])]


.. py:function:: shape(a: Union[arkouda.numpy.pdarrayclass.pdarray, arkouda.numpy.strings.Strings, bool, numpy.bool_, float, numpy.float64, numpy.float32, int, numpy.int8, numpy.int16, numpy.int32, numpy.int64, numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64, numpy.str_, str]) -> Tuple

   Return the shape of an array.

   :param a: Input array.
   :type a: pdarray

   :returns: **shape** -- The elements of the shape tuple give the lengths of the
             corresponding array dimensions.
   :rtype: tuple of ints

   .. rubric:: Examples

   >>> import arkouda as ak
   >>> ak.shape(ak.eye(3,2))
   (3, 2)
   >>> ak.shape([[1, 3]])
   (1, 2)
   >>> ak.shape([0])
   (1,)
   >>> ak.shape(0)
   ()


.. py:function:: sort(pda: arkouda.numpy.pdarrayclass.pdarray, algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD, axis: arkouda.numpy.dtypes.int_scalars = -1) -> arkouda.numpy.pdarrayclass.pdarray

   Return a sorted copy of the array. Only sorts numeric arrays;
   for Strings, use argsort.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray
   :param algorithm: The algorithm to be used for sorting the arrays.
   :type algorithm: SortingAlgorithm, default=SortingAlgorithm.RadixSortLSD
   :param axis: The axis to sort over. Setting to -1 means that it will sort over axis = ndim - 1.
   :type axis: int_scalars, default=-1

   :returns: The sorted copy of pda
   :rtype: pdarray of int64, uint64, or float64

   :raises TypeError: Raised if the parameter is not a pdarray
   :raises ValueError: Raised if sort attempted on a pdarray with an unsupported dtype
       such as bool

   .. seealso:: :obj:`argsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and resilient
   to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> sorted = ak.sort(a)
   >>> sorted
   array([0 1 1 3 4 5 7 8 8 9])


.. py:function:: sqrt(pda: pdarray, where: Union[arkouda.numpy.dtypes.bool_scalars, pdarray] = True) -> pdarray

   Takes the square root of array. If where is given, the operation will only take place in
   the positions where the where condition is True.

   :param pda: A pdarray of values the square roots of which will be computed
   :type pda: pdarray
   :param where: This condition is broadcast over the input. At locations where the condition is True, the
                 corresponding value will be square rooted. Elsewhere, it will retain its original value.
                 Default set to True.
   :type where: Boolean or pdarray

   :returns: a pdarray of square roots of the original values, or the original values themselves,
             subject to the boolean where condition.
   :rtype: pdarray

   .. rubric:: Examples

   >>> a = ak.arange(5)
   >>> ak.sqrt(a)
   array([0.00000000000000000 1.00000000000000000 1.4142135623730951
            1.7320508075688772 2.00000000000000000])
   >>> ak.sqrt(a, ak.array([True, True, False, False, True]))
   array([0.00000000000000000 1.00000000000000000 2.00000000000000000
            3.00000000000000000 2.00000000000000000])

   :raises TypeError: raised if pda is not a pdarray of ak.int64 or ak.float64

   .. rubric:: Notes

   Square roots of negative numbers are returned as nan.


.. py:function:: squeeze(x: Union[arkouda.numpy.pdarrayclass.pdarray, float, numpy.float64, numpy.float32, int, numpy.int8, numpy.int16, numpy.int32, numpy.int64, numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64, bool, numpy.bool_], /, axis: Union[NoneType, int, Tuple[int, Ellipsis]] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Remove degenerate (size one) dimensions from an array.

   :param x: The array to squeeze
   :type x: pdarray
   :param axis: The axis or axes to squeeze (must have a size of one).
                If axis = None, all dimensions of size 1 will be squeezed.
   :type axis: int or Tuple[int, ...]

   :returns: A copy of x with the dimensions specified in the axis argument removed.
   :rtype: pdarray

   .. rubric:: Examples

   >>> import arkouda as ak
   >>> ak.connect()
   >>> x = ak.arange(10).reshape((1, 10, 1))
   >>> x
   array([array([array([0]) array([1]) array([2]) array([3])....
    array([4]) array([5]) array([6]) array([7]) array([8]) array([9])])])
   >>> x.shape
   (1, 10, 1)
   >>> ak.squeeze(x,axis=None)
   array([0 1 2 3 4 5 6 7 8 9])
   >>> ak.squeeze(x,axis=None).shape
   (10,)
   >>> ak.squeeze(x,axis=2)
   array([array([0 1 2 3 4 5 6 7 8 9])])
   >>> ak.squeeze(x,axis=2).shape
   (1, 10)
   >>> ak.squeeze(x,axis=(0,2))
   array([0 1 2 3 4 5 6 7 8 9])
   >>> ak.squeeze(x,axis=(0,2)).shape
   (10,)


.. py:function:: standard_normal(size: arkouda.numpy.dtypes.int_scalars, seed: Union[None, arkouda.numpy.dtypes.int_scalars] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Draw real numbers from the standard normal distribution.

   :param size: The number of samples to draw (size of the returned array)
   :type size: int_scalars
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars

   :returns: The array of random numbers
   :rtype: pdarray, float64

   :raises TypeError: Raised if size is not an int
   :raises ValueError: Raised if size < 0

   .. seealso:: :obj:`randint`

   .. rubric:: Notes

   For random samples from :math:`N(\mu, \sigma^2)`, use:

   ``(sigma * standard_normal(size)) + mu``

   .. rubric:: Examples

   >>> ak.standard_normal(3,1)
   array([-0.68586185091150265 1.1723810583573377 0.567584107142031])


.. py:function:: std(pda: pdarray, ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

   Return the standard deviation of values in the array. The standard
   deviation is implemented as the square root of the variance.

   :param pda: values for which to calculate the standard deviation
   :type pda: pdarray
   :param ddof: "Delta Degrees of Freedom" used in calculating std
   :type ddof: int_scalars

   :returns: The scalar standard deviation of the array
   :rtype: np.float64

   .. rubric:: Examples

   >>> a = ak.arange(10)
   >>> ak.std(a)
   2.8722813232690143
   >>> a.std()
   2.8722813232690143

   :raises TypeError: Raised if pda is not a pdarray instance or ddof is not an integer
   :raises ValueError: Raised if ddof is an integer < 0
   :raises RuntimeError: Raised if there's a server-side error thrown

   .. seealso:: :obj:`mean`, :obj:`var`

   .. rubric:: Notes

   The standard deviation is the square root of the average of the squared
   deviations from the mean, i.e., ``std = sqrt(mean((x - x.mean())**2))``.

   The average squared deviation is normally calculated as
   ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is specified,
   the divisor ``N - ddof`` is used instead. In standard statistical
   practice, ``ddof=1`` provides an unbiased estimator of the variance
   of the infinite population. ``ddof=0`` provides a maximum likelihood
   estimate of the variance for normally distributed variables. The
   standard deviation computed in this function is the square root of
   the estimated variance, so even with ``ddof=1``, it will not be an
   unbiased estimate of the standard deviation per se.


.. py:data:: str_scalars

.. py:function:: tile(A: arkouda.numpy.pdarrayclass.pdarray, /, reps: Union[int, Tuple[int, Ellipsis]]) -> arkouda.numpy.pdarrayclass.pdarray

   Construct an array by repeating A the number of times given by reps.

   If reps has length ``d``, the result will have dimension of ``max(d, A.ndim)``.

   If ``A.ndim < d``, A is promoted to be d-dimensional by prepending new axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication, or shape (1, 1, 3) for 3-D replication. If this is not the desired behavior, promote A to d-dimensions manually before calling this function.

   If ``A.ndim > d``, reps is promoted to A.ndim by prepending 1’s to it. Thus for an A of shape (2, 3, 4, 5), a reps of (2, 2) is treated as (1, 1, 2, 2).

   :param A: The input pdarray to be tiled
   :type A: pdarray
   :param reps: The number of repetitions of A along each axis.
   :type reps: int or Tuple of int

   :returns: A new pdarray with the tiled data.
   :rtype: pdarray

   .. rubric:: Examples

   >>> a = ak.array([0, 1, 2])
   >>> ak.tile(a, 2)
   array([0 1 2 0 1 2])
   >>> ak.tile(a, (2, 2))
   array([array([0 1 2 0 1 2]) array([0 1 2 0 1 2])])
   >>> ak.tile(a, (2, 1, 2))
   array([array([array([0 1 2 0 1 2])]) array([array([0 1 2 0 1 2])])])

   >>> b = ak.array([[1, 2], [3, 4]])
   >>> ak.tile(b, 2)
   array([array([1 2 1 2]) array([3 4 3 4])])
   >>> ak.tile(b, (2, 1))
   array([array([1 2]) array([3 4]) array([1 2]) array([3 4])])

   >>> c = ak.array([1, 2, 3, 4])
   >>> ak.tile(c, (4, 1))
   array([array([1 2 3 4]) array([1 2 3 4]) array([1 2 3 4]) array([1 2 3 4])])


.. py:function:: timedelta_range(start=None, end=None, periods=None, freq=None, name=None, closed=None, **kwargs)

   Return a fixed frequency TimedeltaIndex, with day as the default
   frequency. Alias for ``ak.Timedelta(pd.timedelta_range(args))``.
   Subject to size limit imposed by client.maxTransferBytes.

   :param start: Left bound for generating timedeltas.
   :type start: str or timedelta-like, default None
   :param end: Right bound for generating timedeltas.
   :type end: str or timedelta-like, default None
   :param periods: Number of periods to generate.
   :type periods: int, default None
   :param freq: Frequency strings can have multiples, e.g. '5H'.
   :type freq: str or DateOffset, default 'D'
   :param name: Name of the resulting TimedeltaIndex.
   :type name: str, default None
   :param closed: Make the interval closed with respect to the given frequency to
                  the 'left', 'right', or both sides (None).
   :type closed: str, default None

   :returns: **rng**
   :rtype: TimedeltaIndex

   .. rubric:: Notes

   Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,
   exactly three must be specified. If ``freq`` is omitted, the resulting
   ``TimedeltaIndex`` will have ``periods`` linearly spaced elements between
   ``start`` and ``end`` (closed on both sides).

   To learn more about the frequency strings, please see `this link
   <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.


.. py:function:: typechecked(func=None, *, always=False, _localns: Optional[Dict[str, Any]] = None)

   Perform runtime type checking on the arguments that are passed to the wrapped function.

   The return value is also checked against the return annotation if any.

   If the ``__debug__`` global variable is set to ``False``, no wrapping and therefore no type
   checking is done, unless ``always`` is ``True``.

   This can also be used as a class decorator. This will wrap all type annotated methods in the
   class with this decorator.

   :param func: the function or class to enable type checking for
   :param always: ``True`` to enable type checks even in optimized mode




.. py:function:: uniform(size: arkouda.numpy.dtypes.int_scalars, low: arkouda.numpy.dtypes.numeric_scalars = float(0.0), high: arkouda.numpy.dtypes.numeric_scalars = 1.0, seed: Union[None, arkouda.numpy.dtypes.int_scalars] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Generate a pdarray with uniformly distributed random float values
   in a specified range.

   :param low: The low value (inclusive) of the range, defaults to 0.0
   :type low: float_scalars
   :param high: The high value (inclusive) of the range, defaults to 1.0
   :type high: float_scalars
   :param size: The length of the returned array
   :type size: int_scalars
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars, optional

   :returns: Values drawn uniformly from the specified range
   :rtype: pdarray, float64

   :raises TypeError: Raised if dtype.name not in DTypes, size is not an int, or if
       either low or high is not an int or float
   :raises ValueError: Raised if size < 0 or if high < low

   .. rubric:: Notes

   The logic for uniform is delegated to the ak.randint method which
   is invoked with a dtype of float64

   .. rubric:: Examples

   >>> ak.uniform(3,seed=1701)
   array([0.011410423448327005 0.73618171558685619 0.12367222192448891])

   >>> ak.uniform(size=3,low=0,high=5,seed=0)
   array([0.30013431967121934 0.47383036230759112 1.0441791878997098])


.. py:function:: union1d(A: arkouda.groupbyclass.groupable, B: arkouda.groupbyclass.groupable) -> arkouda.groupbyclass.groupable

   Find the union of two arrays/List of Arrays.

   Return the unique, sorted array of values that are in either
   of the two input arrays.

   :param A:
   :type A: list of pdarrays, pdarray, Strings, or Categorical
   :param B:
   :type B: list of pdarrays, pdarray, Strings, or Categorical

   :returns: Unique, sorted union of the input arrays.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either A or B is not a groupable
   :raises RuntimeError: Raised if the dtype of either input is not supported

   .. seealso:: :obj:`intersect1d`, :obj:`arkouda.groupbyclass.unique`

   .. rubric:: Examples

   1D Example

   >>> ak.union1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([-2 -1 0 1 2])

   Multi-Array Example

   >>> a = ak.arange(1, 6)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.union1d(multia, multib)
   [array([1 2 2 3 4 4 5 5]), array([1 2 5 3 2 4 4 5]), array([1 2 4 3 5 4 2 5])]


.. py:function:: unregister(name: str) -> str

.. py:function:: unregister_all(names: list)

   Unregister all names provided

   :param names: List of names used to register objects to be unregistered
   :type names: list

   :rtype: None


.. py:function:: unregister_pdarray_by_name(user_defined_name: str) -> None

   Unregister a named pdarray in the arkouda server which was previously
   registered using register() and/or attahced to using attach_pdarray()

   :param user_defined_name: user defined name which array was registered under
   :type user_defined_name: str

   :rtype: None

   :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

   .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`attach`

   .. rubric:: Notes

   Registered names/pdarrays in the server are immune to deletion until
   they are unregistered.

   .. rubric:: Examples

   >>> a = zeros(100)
   >>> a.register("my_zeros")
   >>> # potentially disconnect from server and reconnect to server
   >>> b = ak.attach_pdarray("my_zeros")
   >>> # ...other work...
   >>> ak.unregister_pdarray_by_name(b)


.. py:function:: var(pda: pdarray, ddof: arkouda.numpy.dtypes.int_scalars = 0) -> numpy.float64

   Return the variance of values in the array.

   :param pda: Values for which to calculate the variance
   :type pda: pdarray
   :param ddof: "Delta Degrees of Freedom" used in calculating var
   :type ddof: int_scalars

   :returns: The scalar variance of the array
   :rtype: np.float64

   .. rubric:: Examples

   >>> a = ak.arange(10)
   >>> ak.var(a)
   8.25
   >>> a.var()
   8.25

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises ValueError: Raised if the ddof >= pdarray size
   :raises RuntimeError: Raised if there's a server-side error thrown

   .. seealso:: :obj:`mean`, :obj:`std`

   .. rubric:: Notes

   The variance is the average of the squared deviations from the mean,
   i.e.,  ``var = mean((x - x.mean())**2)``.

   The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
   If, however, `ddof` is specified, the divisor ``N - ddof`` is used
   instead.  In standard statistical practice, ``ddof=1`` provides an
   unbiased estimator of the variance of a hypothetical infinite population.
   ``ddof=0`` provides a maximum likelihood estimate of the variance for
   normally distributed variables.


.. py:function:: vstack(tup: Union[Tuple[arkouda.numpy.pdarrayclass.pdarray], List[arkouda.numpy.pdarrayclass.pdarray]], *, dtype: Optional[Union[type, str]] = None, casting: Literal['no', 'equiv', 'safe', 'same_kind', 'unsafe'] = 'same_kind') -> arkouda.numpy.pdarrayclass.pdarray

   Stack a sequence of arrays vertically (row-wise).

   This is equivalent to concatenation along the first axis after 1-D arrays of
   shape `(N,)` have been reshaped to `(1,N)`.

   :param tup: The arrays to be stacked
   :type tup: Tuple[pdarray]
   :param dtype: The data-type of the output array. If not provided, the output
                 array will be determined using `np.common_type` on the
                 input arrays Defaults to None
   :type dtype: Optional[Union[type, str]], optional
   :param casting: Controls what kind of data casting may occur - currently unused
   :type casting: {"no", "equiv", "safe", "same_kind", "unsafe"], optional

   :returns: *
             * *pdarray* -- The stacked array


.. py:function:: zeros(size: Union[arkouda.numpy.dtypes.int_scalars, Tuple[arkouda.numpy.dtypes.int_scalars, Ellipsis], str], dtype: Union[numpy.dtype, type, str, arkouda.numpy.dtypes.bigint] = float64, max_bits: Optional[int] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size or shape of the array
   :type size: int_scalars or tuple of int_scalars
   :param dtype: Type of resulting array, default ak.float64
   :type dtype: all_scalars
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
                    Included for consistency, as zeros are represented as all zeros, regardless
                    of the value of max_bits
   :type max_bits: int

   :returns: Zeros of the requested size or shape and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported
   :raises RuntimeError: Raised if the size parameter is neither an int nor a str that is parseable to an int.
   :raises ValueError: Raised if the rank of the given shape is not in get_array_ranks() or is empty

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0 0 0 0 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0.00000000000000000 0.00000000000000000 0.00000000000000000
          0.00000000000000000 0.00000000000000000])

   >>> ak.zeros(5, dtype=ak.bool_)
   array([False False False False False])


.. py:function:: zeros(size: Union[arkouda.numpy.dtypes.int_scalars, Tuple[arkouda.numpy.dtypes.int_scalars, Ellipsis], str], dtype: Union[numpy.dtype, type, str, arkouda.numpy.dtypes.bigint] = float64, max_bits: Optional[int] = None) -> arkouda.numpy.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size or shape of the array
   :type size: int_scalars or tuple of int_scalars
   :param dtype: Type of resulting array, default ak.float64
   :type dtype: all_scalars
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
                    Included for consistency, as zeros are represented as all zeros, regardless
                    of the value of max_bits
   :type max_bits: int

   :returns: Zeros of the requested size or shape and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported
   :raises RuntimeError: Raised if the size parameter is neither an int nor a str that is parseable to an int.
   :raises ValueError: Raised if the rank of the given shape is not in get_array_ranks() or is empty

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0 0 0 0 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0.00000000000000000 0.00000000000000000 0.00000000000000000
          0.00000000000000000 0.00000000000000000])

   >>> ak.zeros(5, dtype=ak.bool_)
   array([False False False False False])


.. py:function:: zeros_like(pda: arkouda.numpy.pdarrayclass.pdarray) -> arkouda.numpy.pdarrayclass.pdarray

   Create a zero-filled pdarray of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray

   :returns: Equivalent to ak.zeros(pda.size, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.zeros_like(ak.ones(5,dtype=ak.int64))
   array([0 0 0 0 0])

   >>> ak.zeros_like(ak.ones(5,dtype=ak.float64))
   array([0.00000000000000000 0.00000000000000000 0.00000000000000000
          0.00000000000000000 0.00000000000000000])

   >>> ak.zeros_like(ak.ones(5,dtype=ak.bool_))
   array([False False False False False])


