arkouda.client_dtypes
=====================

.. py:module:: arkouda.client_dtypes


Attributes
----------

.. autoapisummary::

   arkouda.client_dtypes.akuint64
   arkouda.client_dtypes.bitType
   arkouda.client_dtypes.intTypes


Exceptions
----------

.. autoapisummary::

   arkouda.client_dtypes.RegistrationError


Classes
-------

.. autoapisummary::

   arkouda.client_dtypes.BitVector
   arkouda.client_dtypes.Fields
   arkouda.client_dtypes.GroupBy
   arkouda.client_dtypes.IPv4
   arkouda.client_dtypes.Strings
   arkouda.client_dtypes.pdarray


Functions
---------

.. autoapisummary::

   arkouda.client_dtypes.BitVectorizer
   arkouda.client_dtypes.akcast
   arkouda.client_dtypes.arange
   arkouda.client_dtypes.array
   arkouda.client_dtypes.broadcast
   arkouda.client_dtypes.create_pdarray
   arkouda.client_dtypes.ip_address
   arkouda.client_dtypes.isSupportedInt
   arkouda.client_dtypes.is_ipv4
   arkouda.client_dtypes.is_ipv6
   arkouda.client_dtypes.where
   arkouda.client_dtypes.zeros


Module Contents
---------------

.. py:class:: BitVector(values, width=64, reverse=False)

   Bases: :py:obj:`arkouda.pdarrayclass.pdarray`


   Represent integers as bit vectors, e.g. a set of flags.

   :param values: The integers to represent as bit vectors
   :type values: pdarray, int64
   :param width: The number of bit fields in the vector
   :type width: int
   :param reverse: If True, display bits from least significant (left) to most
                   significant (right). By default, the most significant bit
                   is the left-most bit.
   :type reverse: bool

   :returns: **bitvectors** -- The array of binary vectors
   :rtype: BitVector

   .. rubric:: Notes

   This class is a thin wrapper around pdarray that mostly affects
   how values are displayed to the user. Operators and methods will
   typically treat this class like a uint64 pdarray.


   .. py:attribute:: conserves


   .. py:method:: format(x)

      Format a single binary vector as a string.



   .. py:method:: from_return_msg(rep_msg)
      :classmethod:



   .. py:method:: opeq(other, op)


   .. py:method:: register(user_defined_name)

      Register this BitVector object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the BitVector is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same BitVector which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different BitVectors with the same name.
      :rtype: BitVector

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the BitVector with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:attribute:: special_objType
      :value: 'BitVector'



   .. py:method:: to_list()

      Export data to a list of string-formatted bit vectors.



   .. py:method:: to_ndarray()

      Export data to a numpy array of string-formatted bit vectors.



.. py:function:: BitVectorizer(width=64, reverse=False)

   Make a callback (i.e. function) that can be called on an
   array to create a BitVector.

   :param width: The number of bit fields in the vector
   :type width: int
   :param reverse: If True, display bits from least significant (left) to most
                   significant (right). By default, the most significant bit
                   is the left-most bit.
   :type reverse: bool

   :returns: **bitvectorizer** -- A function that takes an array and returns a BitVector instance
   :rtype: callable


.. py:class:: Fields(values, names, MSB_left=True, pad='-', separator='', show_int=True)

   Bases: :py:obj:`BitVector`


   An integer-backed representation of a set of named binary fields, e.g. flags.

   :param values: The array of field values. If (u)int64, the values are used as-is for the
                  binary representation of fields. If Strings, the values are converted
                  to binary according to the mapping defined by the names and MSB_left
                  arguments.
   :type values: pdarray or Strings
   :param names: The names of the fields, in order. A string will be treated as a list
                 of single-character field names. Multi-character field names are allowed,
                 but must be passed as a list or tuple and user must specify a separator.
   :type names: str or sequence of str
   :param MSB_left: Controls how field names are mapped to binary values. If True (default),
                    the left-most field name corresponds to the most significant bit in the
                    binary representation. If False, the left-most field name corresponds to
                    the least significant bit.
   :type MSB_left: bool
   :param pad: Character to display when field is not present. Use empty string if no
               padding is desired.
   :type pad: str
   :param separator: Substring that separates fields. Used to parse input values (if ak.Strings)
                     and to display output.
   :type separator: str
   :param show_int: If True (default), display the integer value of the binary fields in output.
   :type show_int: bool

   :returns: **fields** -- The array of field values
   :rtype: Fields

   .. rubric:: Notes

   This class is a thin wrapper around pdarray that mostly affects
   how values are displayed to the user. Operators and methods will
   typically treat this class like an int64 pdarray.


   .. py:method:: format(x)

      Format a single binary value as a string of named fields.



   .. py:method:: opeq(other, op)


.. py:class:: GroupBy

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. attribute:: dropna

      If True, and the groupby keys contain NaN values,
      the NaN values together with the corresponding row will be dropped.
      Otherwise, the rows corresponding to NaN values will be kept.

      :type: bool (default=True)

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Integral pdarrays, Strings, and Categoricals are natively supported, but
   float64 and bool arrays are not.

   For a user-defined class to be groupable, it must inherit from pdarray
   and define or overload the grouping API:
     1) a ._get_grouping_keys() method that returns a list of pdarrays
        that can be (co)argsorted.
     2) (Optional) a .group() method that returns the permutation that
        groups the array
   If the input is a single array with a .group() method defined, method 2
   will be used; otherwise, method 1 will be used.


   .. py:method:: AND(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: OR(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: Reductions(*args, **kwargs)

      frozenset() -> empty frozenset object
      frozenset(iterable) -> frozenset object

      Build an immutable unordered collection of unique elements.




   .. py:method:: XOR(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: aggregate(values: groupable, operator: str, skipna: bool = True, ddof: int_scalars = 1) -> Tuple[groupable, groupable]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool
      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))



   .. py:method:: all(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype



   .. py:method:: any(values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array



   .. py:method:: argmax(values: pdarray) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))



   .. py:method:: argmin(values: pdarray) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))



   .. py:method:: attach(user_defined_name: str) -> GroupBy

      Function to return a GroupBy object attached to the registered name in the
      arkouda server which was registered using register()

      :param user_defined_name: user defined name which GroupBy object was registered under
      :type user_defined_name: str

      :returns: The GroupBy object created by re-attaching to the corresponding server components
      :rtype: GroupBy

      :raises RegistrationError: if user_defined_name is not registered

      .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_groupby_by_name`



   .. py:method:: broadcast(values: Union[pdarray, Strings], permute: bool = True) -> Union[pdarray, Strings]

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray, Strings
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcasted values
      :rtype: pdarray, Strings

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])
      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]
      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.size()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



   .. py:method:: build_from_components(user_defined_name: Optional[str] = None, **kwargs) -> GroupBy

      function to build a new GroupBy object from component keys and permutation.

      :param user_defined_name: and assign it the given name
      :type user_defined_name: str (Optional) Passing a name will init the new GroupBy
      :param kwargs: Expected keys are "orig_keys", "permutation", "unique_keys", and "segments"
      :type kwargs: dict Dictionary of components required for rebuilding the GroupBy.

      :returns: The GroupBy object created by using the given components
      :rtype: GroupBy



   .. py:method:: count(values: pdarray) -> Tuple[groupable, pdarray]

      Count the number of elements in each group.  NaN values will be excluded from the total.

      :param values: The values to be count by group (excluding NaN values).
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears (excluding NaN values).

      .. rubric:: Examples

      >>> a = ak.array([1, 0, -1, 1, 0, -1])
      >>> a
      array([1 0 -1 1 0 -1])
      >>> b = ak.array([1, np.nan, -1, np.nan, np.nan, -1], dtype = "float64")
      >>> b
      array([1.00000000000000000 nan -1.00000000000000000 nan nan -1.00000000000000000])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count(b)
      >>> keys
      array([-1 0 1])
      >>> counts
      array([2 0 1])



   .. py:method:: first(values: groupable_element_type) -> Tuple[groupable, groupable_element_type]

      First value in each group.

      :param values: The values from which to take the first of each group
      :type values: pdarray-like

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*pdarray-like*) -- The first value of each group



   .. py:method:: from_return_msg(rep_msg)


   .. py:method:: is_registered() -> bool

      Return True if the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RegistrationError: Raised if there's a server-side error or a mismatch of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_groupby_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: max(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))



   .. py:method:: mean(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))



   .. py:method:: median(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the median of each group's
      values.

      :param values: The values to group and find median
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_medians** (*pdarray, float64*) -- One median value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,9)
      >>> a
      array([4 1 4 3 2 2 2 3 3])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([4 1 4 3 2 2 2 3 3])
      >>> b = ak.linspace(-5,5,9)
      >>> b
      array([-5 -3.75 -2.5 -1.25 0 1.25 2.5 3.75 5])
      >>> g.median(b)
      (array([1 2 3 4]), array([-3.75 1.25 3.75 -3.75]))



   .. py:method:: min(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))



   .. py:method:: mode(values: groupable) -> Tuple[groupable, groupable]

      Most common value in each group. If a group is multi-modal, return the
      modal value that occurs first.

      :param values: The values from which to take the mode of each group
      :type values: (list of) pdarray-like

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*(list of) pdarray-like*) -- The most common value of each group



   .. py:method:: most_common(values)

      (Deprecated) See `GroupBy.mode()`.




   .. py:method:: nunique(values: groupable) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value



   .. py:method:: objType(*args, **kwargs)

      str(object='') -> str
      str(bytes_or_buffer[, encoding[, errors]]) -> str

      Create a new string object from the given object. If encoding or
      errors is specified, then the object must expose a data buffer
      that will be decoded using the given encoding and error handler.
      Otherwise, returns the result of object.__str__() (if defined)
      or repr(object).
      encoding defaults to sys.getdefaultencoding().
      errors defaults to 'strict'.




   .. py:method:: prod(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))



   .. py:method:: register(user_defined_name: str) -> GroupBy

      Register this GroupBy object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the GroupBy is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same GroupBy which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different GroupBys with the same name.
      :rtype: GroupBy

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the GroupBy with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_groupby_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: sample(values: groupable, n=None, frac=None, replace=False, weights=None, random_state=None, return_indices=False, permute_samples=False)

      Return a random sample from each group. You can either specify the number of elements
      or the fraction of elements to be sampled. random_state can be used for reproducibility

      :param values: The values from which to sample, according to their group membership.
      :type values: (list of) pdarray-like
      :param n: Number of items to return for each group.
                Cannot be used with frac and must be no larger than
                the smallest group unless replace is True.
                Default is one if frac is None.
      :type n: int, optional
      :param frac: Fraction of items to return. Cannot be used with n.
      :type frac: float, optional
      :param replace: Allow or disallow sampling of the value more than once.
      :type replace: bool, default False
      :param weights: Default None results in equal probability weighting.
                      If passed a pdarray, then values must have the same length as the groupby keys
                      and will be used as sampling probabilities after normalization within each group.
                      Weights must be non-negative with at least one positive element within each group.
      :type weights: pdarray, optional
      :param random_state: If int, seed for random number generator.
                           If ak.random.Generator, use as given.
      :type random_state: int or ak.random.Generator, optional
      :param return_indices: if True, return the indices of the sampled values.
                             Otherwise, return the sample values.
      :type return_indices: bool, default False
      :param permute_samples: if True, return permute the samples according to group
                              Otherwise, keep samples in original order.
      :type permute_samples: bool, default False

      :returns: if return_indices is True, return the indices of the sampled values.
                Otherwise, return the sample values.
      :rtype: pdarray



   .. py:method:: size() -> Tuple[groupable, pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.  This counts the total number of rows (including NaN values).

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. seealso:: :obj:`count`

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.size()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])



   .. py:method:: std(values: pdarray, skipna: bool = True, ddof: int_scalars = 1) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the standard deviation of
      each group's values.

      :param values: The values to group and find standard deviation
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool
      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_stds** (*pdarray, float64*) -- One std value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      The standard deviation is the square root of the average of the squared
      deviations from the mean, i.e., ``std = sqrt(mean((x - x.mean())**2))``.

      The average squared deviation is normally calculated as
      ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is specified,
      the divisor ``N - ddof`` is used instead. In standard statistical
      practice, ``ddof=1`` provides an unbiased estimator of the variance
      of the infinite population. ``ddof=0`` provides a maximum likelihood
      estimate of the variance for normally distributed variables. The
      standard deviation computed in this function is the square root of
      the estimated variance, so even with ``ddof=1``, it will not be an
      unbiased estimate of the standard deviation per se.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.std(b)
      (array([2 3 4]), array([1.5275252316519465 1.0954451150103321 0]))



   .. py:method:: sum(values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))



   .. py:method:: to_hdf(prefix_path, dataset='groupby', mode='truncate', file_type='distribute')

      Save the GroupBy to HDF5. The result is a collection of HDF5 files, one file
      per locale of the arkouda server, where each filename starts with prefix_path.

      :param prefix_path: Directory and filename prefix that all output files will share
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 file
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', add data as a new column to existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :returns: * *None*
                * *GroupBy is not currently supported by Parquet*



   .. py:method:: unique(values: groupable)

      Return the set of unique values in each group, as a SegArray.

      :param values: The values to unique
      :type values: (list of) pdarray-like

      :returns: * **unique_keys** (*(list of) pdarray-like*) -- The unique keys, in grouped order
                * **result** (*(list of) SegArray*) -- The unique values of each group

      :raises TypeError: Raised if values is or contains Strings or Categorical



   .. py:method:: unregister()

      Unregister this GroupBy object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_groupby_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_groupby_by_name(user_defined_name: str) -> None

      Function to unregister GroupBy object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the GroupBy object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'groupby', repack: bool = True)


   .. py:method:: var(values: pdarray, skipna: bool = True, ddof: int_scalars = 1) -> Tuple[groupable, pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the variance of
      each group's values.

      :param values: The values to group and find variance
      :type values: pdarray
      :param skipna: boolean which determines if NANs should be skipped
      :type skipna: bool
      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_vars** (*pdarray, float64*) -- One var value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      The variance is the average of the squared deviations from the mean,
      i.e.,  ``var = mean((x - x.mean())**2)``.

      The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
      If, however, `ddof` is specified, the divisor ``N - ddof`` is used
      instead.  In standard statistical practice, ``ddof=1`` provides an
      unbiased estimator of the variance of a hypothetical infinite population.
      ``ddof=0`` provides a maximum likelihood estimate of the variance for
      normally distributed variables.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.var(b)
      (array([2 3 4]), array([2.333333333333333 1.2 0]))



.. py:class:: IPv4(values)

   Bases: :py:obj:`arkouda.pdarrayclass.pdarray`


   Represent integers as IPv4 addresses.

   :param values: The integer IP addresses
   :type values: pdarray, int64

   :returns: The same IP addresses
   :rtype: IPv4

   .. rubric:: Notes

   This class is a thin wrapper around pdarray that mostly affects
   how values are displayed to the user. Operators and methods will
   typically treat this class like an int64 pdarray.


   .. py:method:: export_uint()


   .. py:method:: format(x)

      Format a single integer IP address as a string.



   .. py:method:: normalize(x)

      Take in an IP address as a string, integer, or IPAddress object,
      and convert it to an integer.



   .. py:method:: opeq(other, op)


   .. py:method:: register(user_defined_name)

      Register this IPv4 object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the IPv4 is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same IPv4 which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different IPv4s with the same name.
      :rtype: IPv4

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the IPv4 with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:attribute:: special_objType
      :value: 'IPv4'



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute')

      Override of the pdarray to_hdf to store the special object type



   .. py:method:: to_list()

      Export array as a list of integers.



   .. py:method:: to_ndarray()

      Export array as a numpy array of integers.



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Override the pdarray implementation so that the special object type will be used.



.. py:exception:: RegistrationError

   Bases: :py:obj:`Exception`


   Error/Exception used when the Arkouda Server cannot register an object


.. py:class:: Strings(strings_pdarray: arkouda.pdarrayclass.pdarray, bytes_size: arkouda.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.


   .. py:attribute:: BinOps


   .. py:method:: astype(dtype) -> arkouda.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:


      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: cached_regex_patterns() -> List

      Returns the regex patterns for which Match objects have been cached



   .. py:method:: capitalize() -> Strings

      Returns a new Strings from the original replaced with the first letter capitilzed
      and the remaining letters lowercase.

      :returns: Strings from the original replaced with the capitalized equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`, :obj:`String.title`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS aRe Here {i}' for i in range(5)])
      >>> strings
      array(['StrINgS aRe Here 0', 'StrINgS aRe Here 1', 'StrINgS aRe Here 2', 'StrINgS aRe Here 3',
      ... 'StrINgS aRe Here 4'])
      >>> strings.title()
      array(['Strings are here 0', 'Strings are here 1', 'Strings are here 2', 'Strings are here 3',
      ... 'Strings are here 4'])



   .. py:method:: contains(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True, True, True, True, True])
      >>> strings.contains('string \d', regex=True)
      array([True, True, True, True, True])



   .. py:method:: decode(fromEncoding, toEncoding='UTF-8')

      Return a new strings object in `fromEncoding`, expecting that the
      current Strings is encoded in `toEncoding`

      :param fromEncoding: The current encoding of the strings object
      :type fromEncoding: str
      :param toEncoding: The encoding that the strings will be converted to,
                         default to UTF-8
      :type toEncoding: str

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: encode(toEncoding: str, fromEncoding: str = 'UTF-8')

      Return a new strings object in `toEncoding`, expecting that the
      current Strings is encoded in `fromEncoding`

      :param toEncoding: The encoding that the strings will be converted to
      :type toEncoding: str
      :param fromEncoding: The current encoding of the strings object, default to
                           UTF-8
      :type fromEncoding: str

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: endswith(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True, True, True, True, True])
      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True, True, True, True, True])



   .. py:method:: find_locations(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions,
      and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2, 2, 2, 2, 2])
      >>> starts
      array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
      >>> lens
      array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))



   .. py:method:: findall(pattern: Union[bytes, arkouda.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each
                                   pattern match is from
      :type return_match_origins: bool

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))



   .. py:method:: flatten(delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.flatten('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, map = orig.flatten('|', return_segments=True)
      >>> map
      array([0, 2, 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_flat, under_map = under.flatten('_+', return_segments=True, regex=True)
      >>> under_flat
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0, 2, 5])



   .. py:method:: from_parts(offset_attrib: Union[arkouda.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: Union[pdarray, str]
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: Union[pdarray, str]

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.



   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.



   .. py:method:: fullmatch(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the whole string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=False; matched=False>



   .. py:method:: get_bytes()

      Getter for the bytes component (uint8 pdarray) of this Strings.

      :returns: Pdarray of bytes of the string accessed
      :rtype: pdarray, uint8

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_bytes()
      [111 110 101 0 116 119 111 0 116 104 114 101 101 0]



   .. py:method:: get_lengths() -> arkouda.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: get_offsets()

      Getter for the offsets component (int64 pdarray) of this Strings.

      :returns: Pdarray of offsets of the string accessed
      :rtype: pdarray, int64

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_offsets()
      [0 4 8]



   .. py:method:: get_prefixes(n: arkouda.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.pdarrayclass.pdarray]]

      Return the n-long prefix of each string, where possible

      :param n: Length of prefix
      :type n: int
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-prefix
      :type return_origins: bool
      :param proper: If True, only return proper prefixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a prefix.
      :type proper: bool

      :returns: * **prefixes** (*Strings*) -- The array of n-character prefixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character prefix, False otherwise.



   .. py:method:: get_suffixes(n: arkouda.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.pdarrayclass.pdarray]]

      Return the n-long suffix of each string, where possible

      :param n: Length of suffix
      :type n: int
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-suffix
      :type return_origins: bool
      :param proper: If True, only return proper suffixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a suffix.
      :type proper: bool

      :returns: * **suffixes** (*Strings*) -- The array of n-character suffixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character suffix, False otherwise.



   .. py:method:: group() -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedString.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message



   .. py:method:: hash() -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:property:: inferred_type
      :type: str

      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: isalnum() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphanumeric.

      :returns: True for elements that are alphanumeric, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_alnum = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alnum = ak.array([f'Strings{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_alnum, alnum])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'Strings0', 'Strings1', 'Strings2'])
      >>> strings.isalnum()
      array([False False False True True True])



   .. py:method:: isalpha() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphabetic.  This means there is at least one character,
      and all the characters are alphabetic.

      :returns: True for elements that are alphabetic, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`, :obj:`Strings.isalnum`

      .. rubric:: Examples

      >>> not_alpha = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alpha = ak.array(['StringA','StringB','StringC'])
      >>> strings = ak.concatenate([not_alpha, alpha])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'StringA','StringB','StringC'])
      >>> strings.isalpha()
      array([False False False True True True])



   .. py:method:: isdecimal() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all decimal characters.

      :returns: True for elements that are decimals, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isdigit`

      .. rubric:: Examples

      >>> not_decimal = ak.array([f'Strings {i}' for i in range(3)])
      >>> decimal = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_decimal, decimal])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdecimal()
      array([False False False True True True])
      Special Character Examples
      >>> special_strings = ak.array(["3.14", "0", "", "2", "2x"])
      >>> special_strings
      array(['3.14', '0', '', '2', '2x'])
      >>> special_strings.isdecimal()
      array([False True False False False])



   .. py:method:: isdigit() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all digit characters.

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_digit = ak.array([f'Strings {i}' for i in range(3)])
      >>> digit = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_digit, digit])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdigit()
      array([False False False True True True])
      Special Character Examples
      >>> special_strings = ak.array(["3.14", "0", "", "2", "2x"])
      >>> special_strings
      array(['3.14', '0', '', '2', '2x'])
      >>> special_strings.isdigit()
      array([False True True True False])



   .. py:method:: isempty() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is empty.


      True for elements that are the empty string, False otherwise

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_empty = ak.array([f'Strings {i}' for i in range(3)])
      >>> empty = ak.array(['' for i in range(3)])
      >>> strings = ak.concatenate([not_empty, empty])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', '', '', ''])
      >>> strings.isempty()



   .. py:method:: islower() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.islower()
      array([True True True False False False])



   .. py:method:: isspace() -> arkouda.pdarrayclass.pdarray

              Returns a boolean pdarray where index i indicates whether string i has all
              whitespace characters ( ,    , 
      , 
      , 
      , 
      ).

              Returns
              -------
              pdarray, bool
                  True for elements that are whitespace, False otherwise

              Raises
              ------
              RuntimeError
                  Raised if there is a server-side error thrown

              See Also
              --------
              Strings.islower
              Strings.isupper
              Strings.istitle

              Examples
              --------
              >>> not_space = ak.array([f'Strings {i}' for i in range(3)])
              >>> space = ak.array([' ', '    ', '
      ', '
      ', '
      ', '
      ', '



      '])
              >>> strings = ak.concatenate([not_space, space])
              >>> strings
              array(['Strings 0', 'Strings 1', 'Strings 2', ' ',
              ... 'u0009', 'n', 'u000B', 'u000C', 'u000D', ' u0009nu000Bu000Cu000D'])
              >>> strings.isspace()
              array([False False False True True True True True True True])




   .. py:method:: istitle() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is titlecase

      :returns: True for elements that are titlecase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> mixed = ak.array([f'sTrINgs {i}' for i in range(3)])
      >>> title = ak.array([f'Strings {i}' for i in range(3)])
      >>> strings = ak.concatenate([mixed, title])
      >>> strings
      array(['sTrINgs 0', 'sTrINgs 1', 'sTrINgs 2', 'Strings 0', 'Strings 1', 'Strings 2'])
      >>> strings.istitle()
      array([False False False True True True])



   .. py:method:: isupper() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.isupper()
      array([False False False True True True])



   .. py:method:: lower() -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with
      their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with
                their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])



   .. py:method:: lstick(other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: Union[bytes,str_scalars]

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])



   .. py:method:: match(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the beginning of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=True, span=(0, 2); matched=False>



   .. py:attribute:: objType
      :value: 'Strings'



   .. py:method:: peel(delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: purge_cached_regex_patterns() -> None

      purges cached regex patterns



   .. py:method:: register(user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and
                has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: rpeel(delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False)

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))
      # Compared against peel
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))



   .. py:method:: save(prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the Strings object to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: str ("single" | "distribute")

      :rtype: String message indicating result of save operation

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter. (3) Parquet files do not store the segments,
      only the values.



   .. py:method:: search(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match if any part of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4);
      matched=False; matched=True, span=(0, 2); matched=False>



   .. py:method:: split(pattern: Union[bytes, arkouda.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern.
      If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: str
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))



   .. py:method:: startswith(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True, True, True, True, True])
      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True, True, True, True, True])



   .. py:method:: stick(other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: str
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])



   .. py:method:: strip(chars: Optional[Union[bytes, arkouda.dtypes.str_scalars]] = '') -> Strings

      Returns a new Strings object with all leading and trailing occurrences of characters contained
      in chars removed. The chars argument is a string specifying the set of characters to be removed.
      If omitted, the chars argument defaults to removing whitespace. The chars argument is not a
      prefix or suffix; rather, all combinations of its values are stripped.

      :param chars: the set of characters to be removed

      :returns: Strings object with the leading and trailing characters matching the set of characters in
                the chars argument removed
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> strings = ak.array(['Strings ', '  StringS  ', 'StringS   '])
      >>> s = strings.strip()
      >>> s
      array(['Strings', 'StringS', 'StringS'])

      >>> strings = ak.array(['Strings 1', '1 StringS  ', '  1StringS  12 '])
      >>> s = strings.strip(' 12')
      >>> s
      array(['Strings', 'StringS', 'StringS'])



   .. py:method:: sub(pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the
      replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])



   .. py:method:: subn(pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))



   .. py:method:: title() -> Strings

      Returns a new Strings from the original replaced with their titlecase equivalent.

      :returns: Strings from the original replaced with their titlecase equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.title()
      array(['Strings 0', 'Strings 1', 'Strings 2', 'Strings 3', 'Strings 4'])



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'strings_array', col_delim: str = ',', overwrite: bool = False)

      Write Strings to CSV file(s). File will contain a single column with the Strings data.
      All CSV Files written by Arkouda include a header denoting data types of the columns.
      Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing
      bytes as uint(8).

      :param prefix_path: The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                          when they are written to disk.
      :type prefix_path: str
      :param dataset: Column name to save the Strings under. Defaults to "strings_array".
      :type dataset: str
      :param col_delim: Defaults to ",". Value to be used to separate columns within the file.
                        Please be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str
      :param overwrite: Defaults to False. If True, any existing files matching your provided prefix_path will
                        be overwritten. If False, an error will be returned if existing files are found.
      :type overwrite: bool

      :rtype: str reponse message

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one or
          more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          If `allow_errors` is true this may be raised if no values are returned
          from the server.
      :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline (``\n``) at this time.



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, file_type: str = 'distribute') -> str

      Save the Strings object to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: str ("single" | "distribute")

      :rtype: String message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - Parquet files do not store the segments, only the values.
      - Strings state is saved as two datasets within an hdf5 group:
        one for the string characters and one for the
        segments corresponding to the start of each string
      - the hdf5 group is named via the dataset parameter.
      - The prefix_path must be visible to the arkouda server and the user must
        have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
        ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
        the file name will be `prefix_path`.
      - If any of the output files already exist and
        the mode is 'truncate', they will be overwritten. If the mode is 'append'
        and the number of output files is less than the number of locales or a
        dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
        determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_list() -> list

      Convert the SegString to a list, transferring data from the
      arkouda server to Python. If the SegString exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A list with the same strings as this SegString
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_list()
      ['hello', 'my', 'world']
      >>> type(a.to_list())
      list



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      numpy.ndarray



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the Strings object to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.



   .. py:method:: transfer(hostname: str, port: arkouda.dtypes.int_scalars)

      Sends a Strings object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Strings object is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:


      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'strings_array', save_offsets: bool = True, repack: bool = True)

      Overwrite the dataset with the name provided with this Strings object. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the Strings object

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: upper() -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with
      their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with
                their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])



.. py:function:: akcast(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], dt: Union[numpy.dtype, type, str, arkouda.dtypes.BigInt], errors: ErrorMode = ErrorMode.strict) -> Union[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]]

   Cast an array to another dtype.

   :param pda: The array of values to cast
   :type pda: pdarray or Strings
   :param dt: The target dtype to cast values to
   :type dt: np.dtype, type, or str
   :param errors: Controls how errors are handled when casting strings to a numeric type
                  (ignored for casts from numeric types).
                      - strict: raise RuntimeError if *any* string cannot be converted
                      - ignore: never raise an error. Uninterpretable strings get
                          converted to NaN (float64), -2**63 (int64), zero (uint64 and
                          uint8), or False (bool)
                      - return_validity: in addition to returning the same output as
                        "ignore", also return a bool array indicating where the cast
                        was successful.
   :type errors: {strict, ignore, return_validity}

   :returns: * *pdarray or Strings* -- Array of values cast to desired dtype
             * **[validity** (*pdarray(bool)]*) -- If errors="return_validity" and input is Strings, a second array is
               returned with True where the cast succeeded and False where it failed.

   .. rubric:: Notes

   The cast is performed according to Chapel's casting rules and is NOT safe
   from overflows or underflows. The user must ensure that the target dtype
   has the precision and capacity to hold the desired result.

   .. rubric:: Examples

   >>> ak.cast(ak.linspace(1.0,5.0,5), dt=ak.int64)
   array([1, 2, 3, 4, 5])

   >>> ak.cast(ak.arange(0,5), dt=ak.float64).dtype
   dtype('float64')

   >>> ak.cast(ak.arange(0,5), dt=ak.bool)
   array([False, True, True, True, True])

   >>> ak.cast(ak.linspace(0,4,5), dt=ak.bool)
   array([False, True, True, True, True])


.. py:data:: akuint64

.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str, None] = None, max_bits: int = -1) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `ak.client.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.client.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array([f'string {i}' for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:data:: bitType

.. py:function:: broadcast(segments: pdarray, values: Union[pdarray, Strings], size: Union[int, np.int64, np.uint64] = -1, permutation: Union[pdarray, None] = None)

   Broadcast a dense column vector to the rows of a sparse matrix or grouped array.

   :param segments: Offsets of the start of each row in the sparse matrix or grouped array.
                    Must be sorted in ascending order.
   :type segments: pdarray, int64
   :param values: The values to broadcast, one per row (or group)
   :type values: pdarray, Strings
   :param size: The total number of nonzeros in the matrix. If permutation is given, this
                argument is ignored and the size is inferred from the permutation array.
   :type size: int
   :param permutation: The permutation to go from the original ordering of nonzeros to the ordering
                       grouped by row. To broadcast values back to the original ordering, this
                       permutation will be inverted. If no permutation is supplied, it is assumed
                       that the original nonzeros were already grouped by row. In this case, the
                       size argument must be given.
   :type permutation: pdarray, int64

   :returns: The broadcast values, one per nonzero
   :rtype: pdarray, Strings

   :raises ValueError: - If segments and values are different sizes
       - If segments are empty
       - If number of nonzeros (either user-specified or inferred from permutation)
         is less than one

   .. rubric:: Examples

   >>>
   # Define a sparse matrix with 3 rows and 7 nonzeros
   >>> row_starts = ak.array([0, 2, 5])
   >>> nnz = 7
   # Broadcast the row number to each nonzero element
   >>> row_number = ak.arange(3)
   >>> ak.broadcast(row_starts, row_number, nnz)
   array([0 0 1 1 1 2 2])
   # If the original nonzeros were in reverse order...
   >>> permutation = ak.arange(6, -1, -1)
   >>> ak.broadcast(row_starts, row_number, permutation=permutation)
   array([2 2 1 1 1 0 0])


.. py:function:: create_pdarray(repMsg: str, max_bits=None) -> pdarray

   Return a pdarray instance pointing to an array created by the arkouda server.
   The user should not call this function directly.

   :param repMsg: space-delimited string containing the pdarray name, datatype, size
                  dimension, shape,and itemsize
   :type repMsg: str

   :returns: A pdarray with the same attributes and data as the pdarray; on GPU
   :rtype: pdarray

   :raises ValueError: If there's an error in parsing the repMsg parameter into the six
       values needed to create the pdarray instance
   :raises RuntimeError: Raised if a server-side error is thrown in the process of creating
       the pdarray instance


.. py:data:: intTypes

.. py:function:: ip_address(values)

   Convert values to an Arkouda array of IP addresses.

   :param values: The integer IP addresses or IPv4 object.
   :type values: list-like, integer pdarray, or IPv4

   :returns: The same IP addresses as an Arkouda array
   :rtype: IPv4

   .. rubric:: Notes

   This helper is intended to help future proof changes made to
   accomodate IPv6 and to prevent errors if a user inadvertently
   casts a IPv4 instead of a int64 pdarray. It can also be used
   for importing Python lists of IP addresses into Arkouda.


.. py:function:: isSupportedInt(num)

.. py:function:: is_ipv4(ip: Union[arkouda.pdarrayclass.pdarray, IPv4], ip2: Optional[arkouda.pdarrayclass.pdarray] = None) -> arkouda.pdarrayclass.pdarray

   Indicate which values are ipv4 when passed data containing IPv4 and IPv6 values.

   :param ip:
   :type ip: pdarray (int64) or ak.IPv4
   :param IPv4 value. High Bits of IPv6 if IPv6 is passed in.:
   :param ip2:
   :type ip2: pdarray (int64), Optional
   :param Low Bits of IPv6. This is added for support when dealing with data that contains IPv6 as well.:

   :rtype: pdarray of bools indicating which indexes are IPv4.

   .. seealso:: :obj:`ak.is_ipv6`


.. py:function:: is_ipv6(ip: Union[arkouda.pdarrayclass.pdarray, IPv4], ip2: Optional[arkouda.pdarrayclass.pdarray] = None) -> arkouda.pdarrayclass.pdarray

   Indicate which values are ipv6 when passed data containing IPv4 and IPv6 values.

   :param ip:
   :type ip: pdarray (int64) or ak.IPv4
   :param High Bits of IPv6.:
   :param ip2:
   :type ip2: pdarray (int64), Optional
   :param Low Bits of IPv6:

   :rtype: pdarray of bools indicating which indexes are IPv6.

   .. seealso:: :obj:`ak.is_ipv4`


.. py:class:: pdarray(name: str, mydtype: Union[numpy.dtype, str], size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars, max_bits: Optional[int] = None)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars


   .. py:attribute:: BinOps


   .. py:attribute:: OpEqOps


   .. py:method:: all() -> numpy.bool_

      Return True iff all elements of the array evaluate to True.



   .. py:method:: any() -> numpy.bool_

      Return True iff any element of the array evaluates to True.



   .. py:method:: argmax() -> Union[numpy.int64, numpy.uint64]

      Return the index of the first occurrence of the array max value.



   .. py:method:: argmaxk(k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:method:: argmin() -> Union[numpy.int64, numpy.uint64]

      Return the index of the first occurrence of the array min value



   .. py:method:: argmink(k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:method:: astype(dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:


      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to the corresponding server side component which was registered
                with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: bigint_to_uint_arrays() -> List[pdarray]

      Creates a list of uint pdarrays from a bigint pdarray.
      The first item in return will be the highest 64 bits of the
      bigint pdarray and the last item will be the lowest 64 bits.

      :returns: A list of uint pdarrays where:
                The first item in return will be the highest 64 bits of the
                bigint pdarray and the last item will be the lowest 64 bits.
      :rtype: List[pdarrays]

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`pdarraycreation.bigint_from_uint_arrays`

      .. rubric:: Examples

      >>> a = ak.arange(2**64, 2**64 + 5)
      >>> a
      array(["18446744073709551616" "18446744073709551617" "18446744073709551618"
      "18446744073709551619" "18446744073709551620"])

      >>> a.bigint_to_uint_arrays()
      [array([1 1 1 1 1]), array([0 1 2 3 4])]



   .. py:method:: clz() -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.



   .. py:method:: corr(y: pdarray) -> numpy.float64

      Compute the correlation between self and y using pearson correlation coefficient.

      :param y: Other pdarray used to calculate correlation
      :type y: pdarray

      :returns: The scalar correlation of the two arrays
      :rtype: np.float64

      :raises TypeError: Raised if y is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: cov(y: pdarray) -> numpy.float64

      Compute the covariance between self and y.

      :param y: Other pdarray used to calculate covariance
      :type y: pdarray

      :returns: The scalar covariance of the two arrays
      :rtype: np.float64

      :raises TypeError: Raised if y is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: ctz() -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.



   .. py:method:: fill(value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64



   .. py:method:: format_other(other) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype



   .. py:property:: inferred_type
      :type: Union[str, None]

      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. note::

         This will return True if the object is registered itself or as a component
         of another object



   .. py:method:: is_sorted() -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: max() -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.



   .. py:property:: max_bits


   .. py:method:: maxk(k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:method:: mean() -> numpy.float64

      Return the mean of the array.



   .. py:method:: min() -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.



   .. py:method:: mink(k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:property:: nbytes
      The size of the pdarray in bytes.

      :returns: The size of the pdarray in bytes.
      :rtype: int


   .. py:attribute:: objType
      :value: 'pdarray'



   .. py:method:: opeq(other, op)


   .. py:method:: parity() -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.



   .. py:method:: popcount() -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: prod() -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.



   .. py:method:: register(user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: reshape(*shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index
                    changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the
                    first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView



   .. py:method:: rotl(other) -> pdarray

      Rotate bits left by <other>.



   .. py:method:: rotr(other) -> pdarray

      Rotate bits right by <other>.



   .. py:method:: save(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.save('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.save('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving with an extension (Parquet)
      >>> a.save('path/prefix.parquet', dataset='array', file_format='Parquet')
      Saves the array in numLocales Parquet files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: slice_bits(low, high) -> pdarray

      Returns a pdarray containing only bits from low to high of self.

      This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
      pda.slice_bits(0, 63)

      :param low: The lowest bit included in the slice (inclusive)
                  zero indexed, so the first bit is 0
      :type low: int
      :param high: The highest bit included in the slice (inclusive)
      :type high: int

      :returns: A new pdarray containing the bits of self from low to high
      :rtype: pdarray

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> p = ak.array([2**65 + (2**64 - 1)])
      >>> bin(p[0])
      '0b101111111111111111111111111111111111111111111111111111111111111111'

      >>> bin(p.slice_bits(64, 65)[0])
      '0b10'



   .. py:method:: std(ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: sum() -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'array', col_delim: str = ',', overwrite: bool = False)

              Write pdarray to CSV file(s). File will contain a single column with the pdarray data.
              All CSV Files written by Arkouda include a header denoting data types of the columns.

              Parameters
              -----------
              prefix_path: str
                  The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                  when they are written to disk.
              dataset: str
                  Column name to save the pdarray under. Defaults to "array".
              col_delim: str
                  Defaults to ",". Value to be used to separate columns within the file.
                  Please be sure that the value used DOES NOT appear in your dataset.
              overwrite: bool
                  Defaults to False. If True, any existing files matching your provided prefix_path will
                  be overwritten. If False, an error will be returned if existing files are found.

              Returns
              --------
              str reponse message

              Raises
              ------
              ValueError
                  Raised if all datasets are not present in all parquet files or if one or
                  more of the specified files do not exist
              RuntimeError
                  Raised if one or more of the specified files cannot be opened.
                  If `allow_errors` is true this may be raised if no values are returned
                  from the server.
              TypeError
                  Raised if we receive an unknown arkouda_type returned from the server

              Notes
              ------
              - CSV format is not currently supported by load/load_all operations
              - The column delimiter is expected to be the same for column names and data
              - Be sure that column delimiters are not found within your data.
              - All CSV files must delimit rows using newline (`
      `) at this time.




   .. py:method:: to_cuda()

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute') -> str

      Save the pdarray to HDF5.
      The object can be saved to a collection of files or single file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_hdf('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_hdf('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving to a single file
      >>> a.to_hdf('path/prefix.hdf5', dataset='array', file_type='single')
      Saves the array in to single hdf5 file on the root node.
      ``cwd/path/name_prefix.hdf5``



   .. py:method:: to_list() -> List

      Convert the array to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the pdarray
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_list()
      [0, 1, 2, 3, 4]

      >>> type(a.to_list())
      list



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the pdarray to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_parquet('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_parqet('path/prefix.parquet', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: transfer(hostname: str, port: arkouda.dtypes.int_scalars)

      Sends a pdarray to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the pdarray is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Overwrite the dataset with the name provided with this pdarray. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: value_counts()

      Count the occurrences of the unique values of self.

      :returns: * **unique_values** (*pdarray*) -- The unique values, sorted in ascending order
                * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

      .. rubric:: Examples

      >>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
      (array([0, 2, 4]), array([3, 2, 1]))



   .. py:method:: var(ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown



.. py:function:: where(condition: arkouda.pdarrayclass.pdarray, A: Union[str, arkouda.dtypes.numeric_scalars, arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], B: Union[str, arkouda.dtypes.numeric_scalars, arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical]) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical]

   Returns an array with elements chosen from A and B based upon a
   conditioning array. As is the case with numpy.where, the return array
   consists of values from the first array (A) where the conditioning array
   elements are True and from the second array (B) where the conditioning
   array elements are False.

   :param condition: Used to choose values from A or B
   :type condition: pdarray
   :param A: Value(s) used when condition is True
   :type A: Union[numeric_scalars, str, pdarray, Strings, Categorical]
   :param B: Value(s) used when condition is False
   :type B: Union[numeric_scalars, str, pdarray, Strings, Categorical]

   :returns: Values chosen from A where the condition is True and B where
             the condition is False
   :rtype: pdarray

   :raises TypeError: Raised if the condition object is not a pdarray, if A or B is not
       an int, np.int64, float, np.float64, pdarray, str, Strings, Categorical
       if pdarray dtypes are not supported or do not match, or multiple
       condition clauses (see Notes section) are applied
   :raises ValueError: Raised if the shapes of the condition, A, and B pdarrays are unequal

   .. rubric:: Examples

   >>> a1 = ak.arange(1,10)
   >>> a2 = ak.ones(9, dtype=np.int64)
   >>> cond = a1 < 5
   >>> ak.where(cond,a1,a2)
   array([1, 2, 3, 4, 1, 1, 1, 1, 1])

   >>> a1 = ak.arange(1,10)
   >>> a2 = ak.ones(9, dtype=np.int64)
   >>> cond = a1 == 5
   >>> ak.where(cond,a1,a2)
   array([1, 1, 1, 1, 5, 1, 1, 1, 1])

   >>> a1 = ak.arange(1,10)
   >>> a2 = 10
   >>> cond = a1 < 5
   >>> ak.where(cond,a1,a2)
   array([1, 2, 3, 4, 10, 10, 10, 10, 10])

   >>> s1 = ak.array([f'str {i}' for i in range(10)])
   >>> s2 = 'str 21'
   >>> cond = (ak.arange(10) % 2 == 0)
   >>> ak.where(cond,s1,s2)
   array(['str 0', 'str 21', 'str 2', 'str 21', 'str 4', 'str 21', 'str 6', 'str 21', 'str 8','str 21'])

   >>> c1 = ak.Categorical(ak.array([f'str {i}' for i in range(10)]))
   >>> c2 = ak.Categorical(ak.array([f'str {i}' for i in range(9, -1, -1)]))
   >>> cond = (ak.arange(10) % 2 == 0)
   >>> ak.where(cond,c1,c2)
   array(['str 0', 'str 8', 'str 2', 'str 6', 'str 4', 'str 4', 'str 6', 'str 2', 'str 8', 'str 0'])

   .. rubric:: Notes

   A and B must have the same dtype and only one conditional clause
   is supported e.g., n < 5, n > 1, which is supported in numpy
   is not currently supported in Arkouda


.. py:function:: zeros(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str, arkouda.dtypes.BigInt] = float64, max_bits: Optional[int] = None) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Type of resulting array, default float64
   :type dtype: all_scalars
   :param max_bits: Specifies the maximum number of bits; only used for bigint pdarrays
   :type max_bits: int

   :returns: Zeros of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.bool)
   array([False, False, False, False, False])


