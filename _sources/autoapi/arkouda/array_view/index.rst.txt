:py:mod:`arkouda.array_view`
============================

.. py:module:: arkouda.array_view


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   arkouda.array_view.ArrayView




.. py:class:: ArrayView(base: arkouda.pdarrayclass.pdarray, shape, order='row_major')

   A multi-dimensional view of a pdarray. Arkouda ``ArraryView`` behaves similarly to numpy's ndarray.
   The base pdarray is stored in 1-dimension but can be indexed and treated logically
   as if it were multi-dimensional

   .. attribute:: base

      The base pdarray that is being viewed as a multi-dimensional object

      :type: pdarray

   .. attribute:: dtype

      The element type of the base pdarray (equivalent to base.dtype)

      :type: dtype

   .. attribute:: size

      The number of elements in the base pdarray (equivalent to base.size)

      :type: int_scalars

   .. attribute:: shape

      A pdarray specifying the sizes of each dimension of the array

      :type: pdarray[int]

   .. attribute:: ndim

      Number of dimensions (equivalent to shape.size)

      :type: int_scalars

   .. attribute:: itemsize

      The size in bytes of each element (equivalent to base.itemsize)

      :type: int_scalars

   .. attribute:: order

      Index order to read and write the elements.
      By default or if 'C'/'row_major', read and write data in row_major order
      If 'F'/'column_major', read and write data in column_major order

      :type: str {'C'/'row_major' | 'F'/'column_major'}

   .. py:attribute:: objType
      :value: 'ArrayView'

      

   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the ArrayView to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the ArrayView size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the ArrayView
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the ArrayView size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(6).reshape(2,3)
      >>> a.to_ndarray()
      array([[0, 1, 2],
             [3, 4, 5]])
      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_list() -> list

      Convert the ArrayView to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the ArrayView size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the ArrayView
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the ArrayView size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(6).reshape(2,3)
      >>> a.to_list()
      [[0, 1, 2], [3, 4, 5]]
      >>> type(a.to_list())
      list


   .. py:method:: to_hdf(filepath: str, dset: str = 'ArrayView', mode: str = 'truncate', file_type: str = 'distribute')

      Save the current ArrayView object to hdf5 file

      :param filepath: Path to the file to write the dataset to
      :type filepath: str
      :param dset: Name of the dataset to write
      :type dset: str
      :param mode: Default: truncate
                   Mode to write the dataset in. Truncate will overwrite any existing files.
                   Append will add the dataset to an existing file.
      :type mode: str (truncate | append)
      :param file_type: Default: distribute
                        Indicates the format to save the file. Single will store in a single file.
                        Distribute will store the date in a file per locale.
      :type file_type: str (single|distribute)


   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'ArrayView', repack: bool = True)

      Overwrite the dataset with the name provided with this array view object. If
      the dataset does not exist it is added.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the array view

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added
      - Because HDF5 deletes do not release memory, this will create a copy of the
        file with the new data



