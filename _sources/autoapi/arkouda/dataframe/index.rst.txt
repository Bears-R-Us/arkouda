:py:mod:`arkouda.dataframe`
===========================

.. py:module:: arkouda.dataframe


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   arkouda.dataframe.DataFrame



Functions
~~~~~~~~~

.. autoapisummary::

   arkouda.dataframe.sorted
   arkouda.dataframe.intx
   arkouda.dataframe.intersect
   arkouda.dataframe.invert_permutation



.. py:class:: DataFrame(initialdata=None, index=None)

   Bases: :py:obj:`collections.UserDict`

   A DataFrame structure based on arkouda arrays.

   .. rubric:: Examples

   Create an empty DataFrame and add a column of data:

   >>> import arkouda as ak
   >>> import numpy as np
   >>> import pandas as pd
   >>> df = ak.DataFrame()
   >>> df['a'] = ak.array([1,2,3])

   Create a new DataFrame using a dictionary of data:

   >>> userName = ak.array(['Alice', 'Bob', 'Alice', 'Carol', 'Bob', 'Alice'])
   >>> userID = ak.array([111, 222, 111, 333, 222, 111])
   >>> item = ak.array([0, 0, 1, 1, 2, 0])
   >>> day = ak.array([5, 5, 6, 5, 6, 6])
   >>> amount = ak.array([0.5, 0.6, 1.1, 1.2, 4.3, 0.6])
   >>> df = ak.DataFrame({'userName': userName, 'userID': userID,
   >>>            'item': item, 'day': day, 'amount': amount})
   >>> df
   DataFrame(['userName', 'userID', 'item', 'day', 'amount'] [6 rows : 224 B])

   Indexing works slightly differently than with pandas:
   >>> df[0]
   {'userName': 'Alice', 'userID': 111, 'item': 0, 'day': 5, 'amount': 0.5}
   >>> df['userID']
   array([111, 222, 111, 333, 222, 111])
   >>> df['userName']
   array(['Alice', 'Bob', 'Alice', 'Carol', 'Bob', 'Alice'])
   >>> df[[1,5,7]]
     userName  userID  item  day  amount
   1      Bob     222     0    5     0.6
   2    Alice     111     1    6     1.1
   3    Carol     333     1    5     1.2

   Note that strides are not implemented except for stride = 1.
   >>> df[1:5:1]
   DataFrame(['userName', 'userID', 'item', 'day', 'amount'] [4 rows : 148 B])
   >>> df[ak.array([1,2,3])]
   DataFrame(['userName', 'userID', 'item', 'day', 'amount'] [3 rows : 112 B])
   >>> df[['userID', 'day']]
   DataFrame(['userID', 'day'] [6 rows : 96 B])

   .. py:property:: size

      Returns the number of bytes on the arkouda server.

   .. py:property:: dtypes


   .. py:property:: empty


   .. py:property:: shape


   .. py:property:: columns


   .. py:property:: index


   .. py:property:: info

      Returns a summary string of this dataframe.

   .. py:attribute:: COLUMN_CLASSES
      

      

   .. py:method:: __getattr__(key)


   .. py:method:: __dir__()

      Default dir() implementation.


   .. py:method:: __delitem__(key)


   .. py:method:: __getitem__(key)


   .. py:method:: __setitem__(key, value)


   .. py:method:: __len__()

      Return the number of rows


   .. py:method:: _ncols()

      Number of columns.
      If index appears, we now want to utilize this
      because the actual index has been moved to a property


   .. py:method:: __str__()

      Returns a summary string of this dataframe.


   .. py:method:: _get_head_tail()


   .. py:method:: _get_head_tail_server()


   .. py:method:: _shape_str()


   .. py:method:: __repr__()

      Return ascii-formatted version of the dataframe.


   .. py:method:: _repr_html_()

      Return html-formatted version of the dataframe.


   .. py:method:: _ipython_key_completions_()


   .. py:method:: from_pandas(pd_df)
      :classmethod:


   .. py:method:: _drop_column(keys)

      Drop a column or columns from the dataframe, in-place.

      keys : list
          The labels to be dropped on the given axis


   .. py:method:: _drop_row(keys)

      Drop a row or rows from the dataframe, in-place.

      keys : list
          The indexes to be dropped on the given axis


   .. py:method:: drop(keys: Union[str, int, List[Union[str, int]]], axis: Union[str, int] = 0, inplace: bool = False) -> Union[None, DataFrame]

      Drop column/s or row/s from the dataframe.

      :param keys: The labels to be dropped on the given axis
      :type keys: str, int or list
      :param axis: The axis on which to drop from. 0/'index' - drop rows, 1/'columns' - drop columns
      :type axis: int or str
      :param inplace: Default False. When True, perform the operation on the calling object.
                      When False, return a new object.
      :type inplace: bool

      :returns: * DateFrame when `inplace=False`
                * None when `inplace=True`

      .. rubric:: Examples

      Drop column
      >>> df.drop('col_name', axis=1)

      Drop Row
      >>> df.drop(1)
      or
      >>> df.drop(1, axis=0)


   .. py:method:: drop_duplicates(subset=None, keep='first')

      Drops duplcated rows and returns resulting DataFrame.

      If a subset of the columns are provided then only one instance of each
      duplicated row will be returned (keep determines which row).

      :param subset:
      :type subset: Iterable of column names to use to dedupe.
      :param keep: Determines which duplicates (if any) to keep.
      :type keep: {'first', 'last'}, default 'first'

      :returns: DataFrame with duplicates removed.
      :rtype: DataFrame


   .. py:method:: _set_index(value)


   .. py:method:: reset_index(size: bool = False, inplace: bool = False) -> Union[None, DataFrame]

      Set the index to an integer range.

      Useful if this dataframe is the result of a slice operation from
      another dataframe, or if you have permuted the rows and no longer need
      to keep that ordering on the rows.

      :param size: If size is passed, do not attempt to determine size based on
                   existing column sizes. Assume caller handles consistency correctly.
      :type size: int
      :param inplace: Default False. When True, perform the operation on the calling object.
                      When False, return a new object.
      :type inplace: bool

      :returns: * DateFrame when `inplace=False`
                * None when `inplace=True`

      .. note::

         Pandas adds a column 'index' to indicate the original index. Arkouda does not currently
         support this behavior.


   .. py:method:: update_size()

      Computes the number of bytes on the arkouda server.


   .. py:method:: _rename_column(mapper: Union[Callable, Dict], inplace: bool = False) -> Optional[DataFrame]

      Rename columns within the dataframe

      :param mapper: Function or dictionary mapping existing columns to new columns.
                     Nonexistent names will not raise an error.
      :type mapper: callable or dict-like
      :param inplace: Default False. When True, perform the operation on the calling object.
                      When False, return a new object.
      :type inplace: bool

      :returns: * DateFrame when `inplace=False`
                * None when `inplace=True`

      .. seealso:: :obj:`ak.DataFrame._rename_index`, :obj:`ak.DataFrame.rename`


   .. py:method:: _rename_index(mapper: Union[Callable, Dict], inplace: bool = False) -> Optional[DataFrame]

      Rename indexes within the dataframe

      :param mapper: Function or dictionary mapping existing indexes to new indexes.
                     Nonexistent names will not raise an error.
      :type mapper: callable or dict-like
      :param inplace: Default False. When True, perform the operation on the calling object.
                      When False, return a new object.
      :type inplace: bool

      :returns: * DateFrame when `inplace=False`
                * None when `inplace=True`

      .. rubric:: Notes

      This does not function exactly like pandas. The replacement value here must be
      the same type as the existing value.


   .. py:method:: rename(mapper: Optional[Union[Callable, Dict]] = None, index: Optional[Union[Callable, Dict]] = None, column: Optional[Union[Callable, Dict]] = None, axis: Union[str, int] = 0, inplace: bool = False) -> Optional[DataFrame]

      Rename indexes or columns according to a mapping.

      :param mapper: Function or dictionary mapping existing values to new values.
                     Nonexistent names will not raise an error.
                     Uses the value of axis to determine if renaming column or index
      :type mapper: callable or dict-like, Optional
      :param column: Function or dictionary mapping existing column names to
                     new column names. Nonexistent names will not raise an
                     error.
                     When this is set, axis is ignored.
      :type column: callable or dict-like, Optional
      :param index: Function or dictionary mapping existing index names to
                    new index names. Nonexistent names will not raise an
                    error.
                    When this is set, axis is ignored
      :type index: callable or dict-like, Optional
      :param axis: Default 0.
                   Indicates which axis to perform the rename.
                   0/"index" - Indexes
                   1/"column" - Columns
      :type axis: int or str
      :param inplace: Default False. When True, perform the operation on the calling object.
                      When False, return a new object.
      :type inplace: bool

      :returns: * DateFrame when `inplace=False`
                * None when `inplace=True`

      .. rubric:: Examples

      >>> df = ak.DataFrame({"A": ak.array([1, 2, 3]), "B": ak.array([4, 5, 6])})
      Rename columns using a mapping
      >>> df.rename(columns={'A':'a', 'B':'c'})
          a   c
      0   1   4
      1   2   5
      2   3   6

      Rename indexes using a mapping
      >>> df.rename(index={0:99, 2:11})
           A   B
      99   1   4
      1   2   5
      11   3   6

      Rename using an axis style parameter
      >>> df.rename(str.lower, axis='column')
          a   b
      0   1   4
      1   2   5
      2   3   6


   .. py:method:: append(other, ordered=True)

      Concatenate data from 'other' onto the end of this DataFrame, in place.

      Explicitly, use the arkouda concatenate function to append the data
      from each column in other to the end of self. This operation is done
      in place, in the sense that the underlying pdarrays are updated from
      the result of the arkouda concatenate function, rather than returning
      a new DataFrame object containing the result.

      :param other: The DataFrame object whose data will be appended to this DataFrame.
      :type other: DataFrame
      :param ordered: If False, allow rows to be interleaved for better performance (but
                      data within a row remains together). By default, append all rows
                      to the end, in input order.
      :type ordered: bool

      :returns: Appending occurs in-place, but result is returned for compatibility.
      :rtype: self


   .. py:method:: concat(items, ordered=True)
      :classmethod:

      Essentially an append, but diffenent formatting


   .. py:method:: head(n=5)

      Return the first `n` rows.

      This function returns the first `n` rows of the the dataframe. It is
      useful for quickly verifying data, for example, after sorting or
      appending rows.

      :param n: Number of rows to select.
      :type n: int

      :returns: The first `n` rows of the DataFrame.
      :rtype: ak.DataFrame

      .. seealso:: :obj:`tail`


   .. py:method:: tail(n=5)

      Return the last `n` rows.

      This function returns the last `n` rows for the dataframe. It is
      useful for quickly testing if your object has the right type of data in
      it.

      :param n: Number of rows to select.
      :type n: int (default=5)

      :returns: The last `n` rows of the DataFrame.
      :rtype: ak.DataFrame

      .. seealso:: :obj:`ak.dataframe.head`


   .. py:method:: sample(n=5)

      Return a random sample of `n` rows.

      :param n: Number of rows to return.
      :type n: int (default=5)

      :returns: The sampled `n` rows of the DataFrame.
      :rtype: ak.DataFrame


   .. py:method:: GroupBy(keys, use_series=False)

      Group the dataframe by a column or a list of columns.

      :param keys: An (ordered) list of column names or a single string to group by.
      :type keys: string or list
      :param use_series:
      :type use_series: If True, returns an ak.GroupBy oject. Otherwise an arkouda GroupBy object

      :returns: Either an ak GroupBy or an arkouda GroupBy object.
      :rtype: GroupBy

      .. seealso:: :obj:`arkouda.GroupBy`


   .. py:method:: memory_usage(unit='GB')

      Print the size of this DataFrame.

      :param unit: Unit to return. One of {'KB', 'MB', 'GB'}.
      :type unit: str

      :returns: The number of bytes used by this DataFrame in [unit]s.
      :rtype: int


   .. py:method:: to_pandas(datalimit=maxTransferBytes, retain_index=False)

      Send this DataFrame to a pandas DataFrame.

      :param datalimit: The maximum number size, in megabytes to transfer. The requested
                        DataFrame will be converted to a pandas DataFrame only if the
                        estimated size of the DataFrame does not exceed this value.
      :type datalimit: int (default=arkouda.client.maxTransferBytes)
      :param retain_index: Normally, to_pandas() creates a new range index object. If you want
                           to keep the index column, set this to True.
      :type retain_index: book (default=False)

      :returns: The result of converting this DataFrame to a pandas DataFrame.
      :rtype: pandas.DataFrame


   .. py:method:: _prep_data(index=False, columns=None)


   .. py:method:: to_hdf(path, index=False, columns=None, file_type='distribute')

      Save DataFrame to disk as hdf5, preserving column names.

      :param path: File path to save data
      :type path: str
      :param index: If True, save the index column. By default, do not save the index.
      :type index: bool
      :param columns: List of columns to include in the file. If None, writes out all columns
      :type columns: List
      :param file_type: Default: distribute
                        Whether to save to a single file or distribute across Locales
      :type file_type: str (single | distribute)

      :rtype: None

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      This method saves one file per locale of the arkouda server. All
      files are prefixed by the path argument and suffixed by their
      locale number.

      .. seealso:: :obj:`to_parquet`, :obj:`load`


   .. py:method:: to_parquet(path, index=False, columns=None, compression: Optional[str] = None)

      Save DataFrame to disk as parquet, preserving column names.

      :param path: File path to save data
      :type path: str
      :param index: If True, save the index column. By default, do not save the index.
      :type index: bool
      :param columns: List of columns to include in the file. If None, writes out all columns
      :type columns: List
      :param compression: Default None
                          Provide the compression type to use when writing the file.
                          Supported values: snappy, gzip, brotli, zstd, lz4
      :type compression: str (Optional)

      :rtype: None

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      This method saves one file per locale of the arkouda server. All
      files are prefixed by the path argument and suffixed by their
      locale number.

      .. seealso:: :obj:`to_hdf`, :obj:`load`


   .. py:method:: save(path, index=False, columns=None, file_format='HDF5', file_type='distribute', compression: Optional[str] = None)

      DEPRECATED
      Save DataFrame to disk, preserving column names.
      :param path: File path to save data
      :type path: str
      :param index: If True, save the index column. By default, do not save the index.
      :type index: bool
      :param columns: List of columns to include in the file. If None, writes out all columns
      :type columns: List
      :param file_format: 'HDF5' or 'Parquet'. Defaults to 'HDF5'
      :type file_format: str
      :param file_type: ("single" | "distribute")
                        Defaults to distribute.
                        If single, will right a single file to locale 0
      :type file_type: str
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Compression type. Only used for Parquet
      :type compression: str (Optional)

      .. rubric:: Notes

      This method saves one file per locale of the arkouda server. All
      files are prefixed by the path argument and suffixed by their
      locale number.

      .. seealso:: :obj:`to_parquet`, :obj:`to_hdf`


   .. py:method:: load(prefix_path, file_format='INFER')
      :classmethod:

      Load dataframe from file
      file_format needed for consistency with other load functions


   .. py:method:: argsort(key, ascending=True)

      Return the permutation that sorts the dataframe by `key`.

      :param key: The key to sort on.
      :type key: str

      :returns: The permutation array that sorts the data on `key`.
      :rtype: ak.pdarray


   .. py:method:: coargsort(keys, ascending=True)

      Return the permutation that sorts the dataframe by `keys`.

      Sorting using Strings may not yield correct results

      :param keys: The keys to sort on.
      :type keys: list

      :returns: The permutation array that sorts the data on `keys`.
      :rtype: ak.pdarray


   .. py:method:: sort_values(by=None, ascending=True)

      Sort the DataFrame by one or more columns.

      If no column is specified, all columns are used.

      Note: Fails on sorting ak.Strings when multiple columns being sorted

      :param by: The name(s) of the column(s) to sort by.
      :type by: str or list/tuple of str
      :param ascending: Sort values in ascending (default) or descending order.
      :type ascending: bool

      .. seealso:: :obj:`apply_permutation`, :obj:`sorted`


   .. py:method:: apply_permutation(perm)

      Apply a permutation to an entire DataFrame.

      This may be useful if you want to unsort an DataFrame, or even to
      apply an arbitrary permutation such as the inverse of a sorting
      permutation.

      :param perm: A permutation array. Should be the same size as the data
                   arrays, and should consist of the integers [0,size-1] in
                   some order. Very minimal testing is done to ensure this
                   is a permutation.
      :type perm: ak.pdarray

      .. seealso:: :obj:`sort`


   .. py:method:: filter_by_range(keys, low=1, high=None)

      Find all rows where the value count of the items in a given set of
      columns (keys) is within the range [low, high].

      To filter by a specific value, set low == high.

      :param keys: The names of the columns to group by
      :type keys: list or str
      :param low: The lowest value count.
      :type low: int (default=1)
      :param high: The highest value count, default to unlimited.
      :type high: int (default=None)

      :returns: An array of boolean values for qualified rows in this DataFrame.
      :rtype: pdarray

      .. seealso:: :obj:`filter_by_count`


   .. py:method:: copy(deep=True)

      Make a copy of this object's data.

      When `deep = True` (default), a new object will be created with a copy of
      the calling object's data. Modifications to the data of the copy will not
      be reflected in the original object.


      When `deep = False` a new object will be created without copying the
      calling object's data. Any changes to the data of the original object will
      be reflected in the shallow copy, and vice versa.

      :param deep: When True, return a deep copy. Otherwise, return a shallow copy.
      :type deep: bool (default=True)

      :returns: A deep or shallow copy according to caller specification.
      :rtype: aku.DataFrame


   .. py:method:: groupby(keys, use_series=True)

      Group the dataframe by a column or a list of columns.  Alias for GroupBy

      :param keys:
      :type keys: a single column name or a list of column names
      :param use_series:
      :type use_series: Change return type to Arkouda Groupby object.

      :rtype: An arkouda Groupby instance


   .. py:method:: isin(values: Union[arkouda.pdarrayclass.pdarray, Dict, arkouda.series.Series, DataFrame]) -> DataFrame

      Determine whether each element in the DataFrame is contained in values.

      :param values: The values to check for in DataFrame. Series can only have a single index.
      :type values: pdarray, dict, Series, or DataFrame

      :returns: Arkouda DataFrame of booleans showing whether each element in the DataFrame is
                contained in values
      :rtype: DataFrame

      .. seealso:: :obj:`ak.Series.isin`

      .. rubric:: Notes

      - Pandas supports values being an iterable type. In arkouda, we replace this with pdarray
      - Pandas supports ~ operations. Currently, ak.DataFrame does not support this.

      .. rubric:: Examples

      >>> df = ak.DataFrame({'col_A': ak.array([7, 3]), 'col_B':ak.array([1, 9])})
      >>> df
          col_A  col_B
      0      7      1
      1      3      9 (2 rows x 2 columns)

      When `values` is a pdarray, check every value in the DataFrame to determine if
      it exists in values
      >>> df.isin(ak.array([0, 1]))
         col_A  col_B
      0  False   True
      1  False  False (2 rows x 2 columns)

      When `values` is a dict, the values in the dict are passed to check the column
      indicated by the key
      >>> df.isin({'col_A': ak.array([0, 3])})
          col_A  col_B
      0  False  False
      1   True  False (2 rows x 2 columns)

      When `values` is a Series, each column is checked if values is present positionally.
      This means that for `True` to be returned, the indexes must be the same.
      >>> i = ak.Index(ak.arange(2))
      >>> s = ak.Series(data=[3, 9], index=i)
      >>> df.isin(s)
          col_A  col_B
      0  False  False
      1  False   True (2 rows x 2 columns)

      When `values` is a DataFrame, the index and column must match.
      Note that 9 is not found because the column name does not match.
      >>> other_df = ak.DataFrame({'col_A':ak.array([7, 3]), 'col_C':ak.array([0, 9])})
      >>> df.isin(other_df)
          col_A  col_B
      0   True  False
      1   True  False (2 rows x 2 columns)


   .. py:method:: corr() -> DataFrame

      Return new DataFrame with pairwise correlation of columns

      :returns: Arkouda DataFrame containing correlation matrix of all columns
      :rtype: DataFrame

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. seealso:: :obj:`pdarray.corr`

      .. rubric:: Notes

      Generates the correlation matrix using Pearson R for all columns

      Attempts to convert to numeric values where possible for inclusion in the matrix.


   .. py:method:: register(user_defined_name: str) -> DataFrame

      Register this DataFrame object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the DataFrame is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same DataFrame which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different DataFrames with the same name.
      :rtype: DataFrame

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the DataFrame with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_dataframe_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.

      Any changes made to a DataFrame object after registering with the server may not be reflected
      in attached copies.


   .. py:method:: unregister()

      Unregister this DataFrame object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_dataframe_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: is_registered() -> bool

      Return True if the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RegistrationError: Raised if there's a server-side error or a mismatch of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_dataframe_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: attach(user_defined_name: str) -> DataFrame
      :staticmethod:

      Function to return a DataFrame object attached to the registered name in the
      arkouda server which was registered using register()

      :param user_defined_name: user defined name which DataFrame object was registered under
      :type user_defined_name: str

      :returns: The DataFrame object created by re-attaching to the corresponding server components
      :rtype: DataFrame

      :raises RegistrationError: if user_defined_name is not registered

      .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_groupby_by_name`


   .. py:method:: unregister_dataframe_by_name(user_defined_name: str) -> None
      :staticmethod:

      Function to unregister DataFrame object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the DataFrame object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`


   .. py:method:: _parse_col_name(entryName, dfName)
      :staticmethod:

      Helper method used by from_return_msg to parse the registered name of the data component
      and pull out the column type and column name

      :param entryName: The full registered name of the data component
      :type entryName: string
      :param dfName: The name of the DataFrame
      :type dfName: string

      :rtype: Tuple (columnName, columnType)


   .. py:method:: from_return_msg(repMsg)
      :staticmethod:

      Creates and returns a DataFrame based on return components from ak.util.attach

      :param repMsg: A '+' delimited string of the DataFrame components to parse.
      :type repMsg: string

      :returns: A DataFrame representing a set of DataFrame components on the server
      :rtype: DataFrame

      :raises RuntimeError: Raised if a server-side error is thrown in the process of creating
          the DataFrame instance



.. py:function:: sorted(df, column=False)

   Analogous to other python 'sorted(obj)' functions in that it returns
   a sorted copy of the DataFrame.

   If no sort key is specified, sort by the first key returned.

   Note: This fails on sorting ak.Strings, as does DataFrame.sort().

   :param df: The DataFrame to sort.
   :type df: ak.dataframe.DataFrame
   :param column: The name of the column to sort by.
   :type column: str

   :returns: A sorted copy of the original DataFrame.
   :rtype: ak.dataframe.DataFrame


.. py:function:: intx(a, b)

   Find all the rows that are in both dataframes. Columns should be in
   identical order.

   Note: does not work for columns of floating point values, but does work for
   Strings, pdarrays of int64 type, and Categorical *should* work.


.. py:function:: intersect(a, b, positions=True, unique=False)

   Find the intersection of two arkouda arrays.

   This function can be especially useful when `positions=True` so
   that the caller gets the indices of values present in both arrays.

   :param a: An array of strings
   :type a: ak.Strings or ak.pdarray
   :param b: An array of strings
   :type b: ak.Strings or ak.pdarray
   :param positions: Return tuple of boolean pdarrays that indicate positions in a and b
                     where the values are in the intersection.
   :type positions: bool (default=True)
   :param unique: If the number of distinct values in `a` (and `b`) is equal to the size of
                  `a` (and `b`), there is a more efficient method to compute the intersection.
   :type unique: bool (default=False)

   :returns: The indices of `a` and `b` where any element occurs at least once in both
             arrays.
   :rtype: (ak.pdarray, ak.pdarray)


.. py:function:: invert_permutation(perm)

   Find the inverse of a permutation array.

   :param perm: The permutation array.
   :type perm: ak.pdarray

   :returns: The inverse of the permutation array.
   :rtype: ak.pdarray


