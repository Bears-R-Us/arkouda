arkouda.timeclass
=================

.. py:module:: arkouda.timeclass


Attributes
----------

.. autoapisummary::

   arkouda.timeclass.int64
   arkouda.timeclass.intTypes
   arkouda.timeclass.int_scalars


Exceptions
----------

.. autoapisummary::

   arkouda.timeclass.RegistrationError


Classes
-------

.. autoapisummary::

   arkouda.timeclass.Datetime
   arkouda.timeclass.Timedelta
   arkouda.timeclass.pdarray


Functions
---------

.. autoapisummary::

   arkouda.timeclass.akabs
   arkouda.timeclass.cast
   arkouda.timeclass.create_pdarray
   arkouda.timeclass.date_range
   arkouda.timeclass.from_series
   arkouda.timeclass.isSupportedInt
   arkouda.timeclass.timedelta_range


Module Contents
---------------

.. py:class:: Datetime(pda, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`


   Represents a date and/or time.

   Datetime is the Arkouda analog to pandas DatetimeIndex and
   other timeseries data types.

   :param pda:
   :type pda: int64 pdarray, pd.DatetimeIndex, pd.Series, or np.datetime64 array
   :param unit: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type unit: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.


   .. py:property:: date


   .. py:property:: day


   .. py:property:: day_of_week


   .. py:property:: day_of_year


   .. py:property:: dayofweek


   .. py:property:: dayofyear


   .. py:property:: hour


   .. py:property:: is_leap_year


   .. py:method:: is_registered() -> numpy.bool_

       Return True iff the object is contained in the registry or is a component of a
       registered object.

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: isocalendar()


   .. py:property:: microsecond


   .. py:property:: millisecond


   .. py:property:: minute


   .. py:property:: month


   .. py:property:: nanosecond


   .. py:method:: register(user_defined_name)

      Register this Datetime object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Datetime is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Datetime which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different Datetimes with the same name.
      :rtype: Datetime

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Datetimes with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: second


   .. py:attribute:: special_objType
      :value: 'Datetime'



   .. py:method:: sum()

      Return the sum of all elements in the array.



   .. py:attribute:: supported_opeq


   .. py:attribute:: supported_with_datetime


   .. py:attribute:: supported_with_pdarray


   .. py:attribute:: supported_with_r_datetime


   .. py:attribute:: supported_with_r_pdarray


   .. py:attribute:: supported_with_r_timedelta


   .. py:attribute:: supported_with_timedelta


   .. py:method:: to_pandas()

      Convert array to a pandas DatetimeIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`



   .. py:method:: unregister()

      Unregister this Datetime object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: week


   .. py:property:: weekday


   .. py:property:: weekofyear


   .. py:property:: year


.. py:exception:: RegistrationError

   Bases: :py:obj:`Exception`


   Error/Exception used when the Arkouda Server cannot register an object


.. py:class:: Timedelta(pda, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`


   Represents a duration, the difference between two dates or times.

   Timedelta is the Arkouda equivalent of pandas.TimedeltaIndex.

   :param pda:
   :type pda: int64 pdarray, pd.TimedeltaIndex, pd.Series, or np.timedelta64 array
   :param unit: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type unit: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.


   .. py:method:: abs()

      Absolute value of time interval.



   .. py:property:: components


   .. py:property:: days


   .. py:method:: is_registered() -> numpy.bool_

       Return True iff the object is contained in the registry or is a component of a
       registered object.

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: microseconds


   .. py:property:: nanoseconds


   .. py:method:: register(user_defined_name)

      Register this Timedelta object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the timedelta is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Timedelta which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different Timedeltas with the same name.
      :rtype: Timedelta

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the timedelta with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: seconds


   .. py:attribute:: special_objType
      :value: 'Timedelta'



   .. py:method:: std(ddof: arkouda.dtypes.int_scalars = 0)

      Returns the standard deviation as a pd.Timedelta object



   .. py:method:: sum()

      Return the sum of all elements in the array.



   .. py:attribute:: supported_opeq


   .. py:attribute:: supported_with_datetime


   .. py:attribute:: supported_with_pdarray


   .. py:attribute:: supported_with_r_datetime


   .. py:attribute:: supported_with_r_pdarray


   .. py:attribute:: supported_with_r_timedelta


   .. py:attribute:: supported_with_timedelta


   .. py:method:: to_pandas()

      Convert array to a pandas TimedeltaIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`



   .. py:method:: total_seconds()


   .. py:method:: unregister()

      Unregister this timedelta object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



.. py:function:: akabs(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the element-wise absolute value of the array.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing absolute values of the input array elements
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray

   .. rubric:: Examples

   >>> ak.abs(ak.arange(-5,-1))
   array([5, 4, 3, 2])

   >>> ak.abs(ak.linspace(-5,-1,5))
   array([5, 4, 3, 2, 1])


.. py:function:: cast(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], dt: Union[numpy.dtype, type, str, arkouda.dtypes.BigInt], errors: ErrorMode = ErrorMode.strict) -> Union[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]]

   Cast an array to another dtype.

   :param pda: The array of values to cast
   :type pda: pdarray or Strings
   :param dt: The target dtype to cast values to
   :type dt: np.dtype, type, or str
   :param errors: Controls how errors are handled when casting strings to a numeric type
                  (ignored for casts from numeric types).
                      - strict: raise RuntimeError if *any* string cannot be converted
                      - ignore: never raise an error. Uninterpretable strings get
                          converted to NaN (float64), -2**63 (int64), zero (uint64 and
                          uint8), or False (bool)
                      - return_validity: in addition to returning the same output as
                        "ignore", also return a bool array indicating where the cast
                        was successful.
   :type errors: {strict, ignore, return_validity}

   :returns: * *pdarray or Strings* -- Array of values cast to desired dtype
             * **[validity** (*pdarray(bool)]*) -- If errors="return_validity" and input is Strings, a second array is
               returned with True where the cast succeeded and False where it failed.

   .. rubric:: Notes

   The cast is performed according to Chapel's casting rules and is NOT safe
   from overflows or underflows. The user must ensure that the target dtype
   has the precision and capacity to hold the desired result.

   .. rubric:: Examples

   >>> ak.cast(ak.linspace(1.0,5.0,5), dt=ak.int64)
   array([1, 2, 3, 4, 5])

   >>> ak.cast(ak.arange(0,5), dt=ak.float64).dtype
   dtype('float64')

   >>> ak.cast(ak.arange(0,5), dt=ak.bool)
   array([False, True, True, True, True])

   >>> ak.cast(ak.linspace(0,4,5), dt=ak.bool)
   array([False, True, True, True, True])


.. py:function:: create_pdarray(repMsg: str, max_bits=None) -> pdarray

   Return a pdarray instance pointing to an array created by the arkouda server.
   The user should not call this function directly.

   :param repMsg: space-delimited string containing the pdarray name, datatype, size
                  dimension, shape,and itemsize
   :type repMsg: str

   :returns: A pdarray with the same attributes and data as the pdarray; on GPU
   :rtype: pdarray

   :raises ValueError: If there's an error in parsing the repMsg parameter into the six
       values needed to create the pdarray instance
   :raises RuntimeError: Raised if a server-side error is thrown in the process of creating
       the pdarray instance


.. py:function:: date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, inclusive='both', **kwargs)

   Creates a fixed frequency Datetime range. Alias for
   ``ak.Datetime(pd.date_range(args))``. Subject to size limit
   imposed by client.maxTransferBytes.

   :param start: Left bound for generating dates.
   :type start: str or datetime-like, optional
   :param end: Right bound for generating dates.
   :type end: str or datetime-like, optional
   :param periods: Number of periods to generate.
   :type periods: int, optional
   :param freq: Frequency strings can have multiples, e.g. '5H'. See
                timeseries.offset_aliases for a list of
                frequency aliases.
   :type freq: str or DateOffset, default 'D'
   :param tz: Time zone name for returning localized DatetimeIndex, for example
              'Asia/Hong_Kong'. By default, the resulting DatetimeIndex is
              timezone-naive.
   :type tz: str or tzinfo, optional
   :param normalize: Normalize start/end dates to midnight before generating date range.
   :type normalize: bool, default False
   :param name: Name of the resulting DatetimeIndex.
   :type name: str, default None
   :param closed: Make the interval closed with respect to the given frequency to
                  the 'left', 'right', or both sides (None, the default).
                  *Deprecated*
   :type closed: {None, 'left', 'right'}, optional
   :param inclusive: Include boundaries. Whether to set each bound as closed or open.
   :type inclusive: {"both", "neither", "left", "right"}, default "both"
   :param \*\*kwargs: For compatibility. Has no effect on the result.

   :returns: **rng**
   :rtype: DatetimeIndex

   .. rubric:: Notes

   Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,
   exactly three must be specified. If ``freq`` is omitted, the resulting
   ``DatetimeIndex`` will have ``periods`` linearly spaced elements between
   ``start`` and ``end`` (closed on both sides).

   To learn more about the frequency strings, please see `this link
   <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.


.. py:function:: from_series(series: pandas.Series, dtype: Optional[Union[type, str]] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Converts a Pandas Series to an Arkouda pdarray or Strings object. If
   dtype is None, the dtype is inferred from the Pandas Series. Otherwise,
   the dtype parameter is set if the dtype of the Pandas Series is to be
   overridden or is  unknown (for example, in situations where the Series
   dtype is object).

   :param series: The Pandas Series with a dtype of bool, float64, int64, or string
   :type series: Pandas Series
   :param dtype: The valid dtype types are np.bool, np.float64, np.int64, and np.str
   :type dtype: Optional[type]

   :rtype: Union[pdarray,Strings]

   :raises TypeError: Raised if series is not a Pandas Series object
   :raises ValueError: Raised if the Series dtype is not bool, float64, int64, string, datetime, or timedelta

   .. rubric:: Examples

   >>> ak.from_series(pd.Series(np.random.randint(0,10,5)))
   array([9, 0, 4, 7, 9])

   >>> ak.from_series(pd.Series(['1', '2', '3', '4', '5']),dtype=np.int64)
   array([1, 2, 3, 4, 5])

   >>> ak.from_series(pd.Series(np.random.uniform(low=0.0,high=1.0,size=3)))
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(['0.57600036956445599', '0.41619265571741659',
                      '0.6615356693784662']), dtype=np.float64)
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(np.random.choice([True, False],size=5)))
   array([True, False, True, True, True])

   >>> ak.from_series(pd.Series(['True', 'False', 'False', 'True', 'True']), dtype=np.bool)
   array([True, True, True, True, True])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e'], dtype="string"))
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e']),dtype=np.str)
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01')])))
   array([1514764800000000000, 1514764800000000000])

   .. rubric:: Notes

   The supported datatypes are bool, float64, int64, string, and datetime64[ns]. The
   data type is either inferred from the the Series or is set via the dtype parameter.

   Series of datetime or timedelta are converted to Arkouda arrays of dtype int64 (nanoseconds)

   A Pandas Series containing strings has a dtype of object. Arkouda assumes the Series
   contains strings and sets the dtype to str


.. py:data:: int64

.. py:data:: intTypes

.. py:data:: int_scalars

.. py:function:: isSupportedInt(num)

.. py:class:: pdarray(name: str, mydtype: Union[numpy.dtype, str], size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars, max_bits: Optional[int] = None)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars


   .. py:attribute:: BinOps


   .. py:attribute:: OpEqOps


   .. py:method:: all() -> numpy.bool_

      Return True iff all elements of the array evaluate to True.



   .. py:method:: any() -> numpy.bool_

      Return True iff any element of the array evaluates to True.



   .. py:method:: argmax() -> Union[numpy.int64, numpy.uint64]

      Return the index of the first occurrence of the array max value.



   .. py:method:: argmaxk(k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:method:: argmin() -> Union[numpy.int64, numpy.uint64]

      Return the index of the first occurrence of the array min value



   .. py:method:: argmink(k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:method:: astype(dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:


      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to the corresponding server side component which was registered
                with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: bigint_to_uint_arrays() -> List[pdarray]

      Creates a list of uint pdarrays from a bigint pdarray.
      The first item in return will be the highest 64 bits of the
      bigint pdarray and the last item will be the lowest 64 bits.

      :returns: A list of uint pdarrays where:
                The first item in return will be the highest 64 bits of the
                bigint pdarray and the last item will be the lowest 64 bits.
      :rtype: List[pdarrays]

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`pdarraycreation.bigint_from_uint_arrays`

      .. rubric:: Examples

      >>> a = ak.arange(2**64, 2**64 + 5)
      >>> a
      array(["18446744073709551616" "18446744073709551617" "18446744073709551618"
      "18446744073709551619" "18446744073709551620"])

      >>> a.bigint_to_uint_arrays()
      [array([1 1 1 1 1]), array([0 1 2 3 4])]



   .. py:method:: clz() -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.



   .. py:method:: corr(y: pdarray) -> numpy.float64

      Compute the correlation between self and y using pearson correlation coefficient.

      :param y: Other pdarray used to calculate correlation
      :type y: pdarray

      :returns: The scalar correlation of the two arrays
      :rtype: np.float64

      :raises TypeError: Raised if y is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: cov(y: pdarray) -> numpy.float64

      Compute the covariance between self and y.

      :param y: Other pdarray used to calculate covariance
      :type y: pdarray

      :returns: The scalar covariance of the two arrays
      :rtype: np.float64

      :raises TypeError: Raised if y is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: ctz() -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.



   .. py:method:: equals(other) -> bool

      Whether pdarrays are the same size and all entries are equal.



   .. py:method:: fill(value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64



   .. py:method:: format_other(other) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype



   .. py:property:: inferred_type
      :type: Union[str, None]

      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown

      .. note::

         This will return True if the object is registered itself or as a component
         of another object



   .. py:method:: is_sorted() -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: max() -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.



   .. py:property:: max_bits


   .. py:method:: maxk(k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:method:: mean() -> numpy.float64

      Return the mean of the array.



   .. py:method:: min() -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.



   .. py:method:: mink(k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



   .. py:property:: nbytes
      The size of the pdarray in bytes.

      :returns: The size of the pdarray in bytes.
      :rtype: int


   .. py:attribute:: objType
      :value: 'pdarray'



   .. py:method:: opeq(other, op)


   .. py:method:: parity() -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.



   .. py:method:: popcount() -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: prod() -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.



   .. py:method:: register(user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: reshape(*shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index
                    changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the
                    first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView



   .. py:method:: rotl(other) -> pdarray

      Rotate bits left by <other>.



   .. py:method:: rotr(other) -> pdarray

      Rotate bits right by <other>.



   .. py:method:: save(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.save('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.save('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving with an extension (Parquet)
      >>> a.save('path/prefix.parquet', dataset='array', file_format='Parquet')
      Saves the array in numLocales Parquet files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: slice_bits(low, high) -> pdarray

      Returns a pdarray containing only bits from low to high of self.

      This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
      pda.slice_bits(0, 63)

      :param low: The lowest bit included in the slice (inclusive)
                  zero indexed, so the first bit is 0
      :type low: int
      :param high: The highest bit included in the slice (inclusive)
      :type high: int

      :returns: A new pdarray containing the bits of self from low to high
      :rtype: pdarray

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> p = ak.array([2**65 + (2**64 - 1)])
      >>> bin(p[0])
      '0b101111111111111111111111111111111111111111111111111111111111111111'

      >>> bin(p.slice_bits(64, 65)[0])
      '0b10'



   .. py:method:: std(ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: sum() -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'array', col_delim: str = ',', overwrite: bool = False)

              Write pdarray to CSV file(s). File will contain a single column with the pdarray data.
              All CSV Files written by Arkouda include a header denoting data types of the columns.

              Parameters
              -----------
              prefix_path: str
                  The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                  when they are written to disk.
              dataset: str
                  Column name to save the pdarray under. Defaults to "array".
              col_delim: str
                  Defaults to ",". Value to be used to separate columns within the file.
                  Please be sure that the value used DOES NOT appear in your dataset.
              overwrite: bool
                  Defaults to False. If True, any existing files matching your provided prefix_path will
                  be overwritten. If False, an error will be returned if existing files are found.

              Returns
              --------
              str reponse message

              Raises
              ------
              ValueError
                  Raised if all datasets are not present in all parquet files or if one or
                  more of the specified files do not exist
              RuntimeError
                  Raised if one or more of the specified files cannot be opened.
                  If `allow_errors` is true this may be raised if no values are returned
                  from the server.
              TypeError
                  Raised if we receive an unknown arkouda_type returned from the server

              Notes
              ------
              - CSV format is not currently supported by load/load_all operations
              - The column delimiter is expected to be the same for column names and data
              - Be sure that column delimiters are not found within your data.
              - All CSV files must delimit rows using newline (`
      `) at this time.




   .. py:method:: to_cuda()

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', file_type: str = 'distribute') -> str

      Save the pdarray to HDF5.
      The object can be saved to a collection of files or single file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
      the file name will be `prefix_path`.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_hdf('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_hdf('path/prefix.h5', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number
      >>> # Saving to a single file
      >>> a.to_hdf('path/prefix.hdf5', dataset='array', file_type='single')
      Saves the array in to single hdf5 file on the root node.
      ``cwd/path/name_prefix.hdf5``



   .. py:method:: to_list() -> List

      Convert the array to a list, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A list with the same data as the pdarray
      :rtype: list

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_list()
      [0, 1, 2, 3, 4]

      >>> type(a.to_list())
      list



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the pdarray to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. rubric:: Examples

      >>> a = ak.arange(25)
      >>> # Saving without an extension
      >>> a.to_parquet('path/prefix', dataset='array')
      Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``
      >>> # Saving with an extension (HDF5)
      >>> a.to_parqet('path/prefix.parquet', dataset='array')
      Saves the array to numLocales HDF5 files with the name
      ``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number



   .. py:method:: transfer(hostname: str, port: arkouda.dtypes.int_scalars)

      Sends a pdarray to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the pdarray is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'array', repack: bool = True)

      Overwrite the dataset with the name provided with this pdarray. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: value_counts()

      Count the occurrences of the unique values of self.

      :returns: * **unique_values** (*pdarray*) -- The unique values, sorted in ascending order
                * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

      .. rubric:: Examples

      >>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
      (array([0, 2, 4]), array([3, 2, 1]))



   .. py:method:: var(ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown



.. py:function:: timedelta_range(start=None, end=None, periods=None, freq=None, name=None, closed=None, **kwargs)

   Return a fixed frequency TimedeltaIndex, with day as the default
   frequency. Alias for ``ak.Timedelta(pd.timedelta_range(args))``.
   Subject to size limit imposed by client.maxTransferBytes.

   :param start: Left bound for generating timedeltas.
   :type start: str or timedelta-like, default None
   :param end: Right bound for generating timedeltas.
   :type end: str or timedelta-like, default None
   :param periods: Number of periods to generate.
   :type periods: int, default None
   :param freq: Frequency strings can have multiples, e.g. '5H'.
   :type freq: str or DateOffset, default 'D'
   :param name: Name of the resulting TimedeltaIndex.
   :type name: str, default None
   :param closed: Make the interval closed with respect to the given frequency to
                  the 'left', 'right', or both sides (None).
   :type closed: str, default None

   :returns: **rng**
   :rtype: TimedeltaIndex

   .. rubric:: Notes

   Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,
   exactly three must be specified. If ``freq`` is omitted, the resulting
   ``TimedeltaIndex`` will have ``periods`` linearly spaced elements between
   ``start`` and ``end`` (closed on both sides).

   To learn more about the frequency strings, please see `this link
   <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.


