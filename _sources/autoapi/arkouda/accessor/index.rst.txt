arkouda.accessor
================

.. py:module:: arkouda.accessor


Classes
-------

.. autoapisummary::

   arkouda.accessor.CachedAccessor
   arkouda.accessor.Categorical
   arkouda.accessor.Datetime
   arkouda.accessor.DatetimeAccessor
   arkouda.accessor.Properties
   arkouda.accessor.StringAccessor
   arkouda.accessor.Strings


Functions
---------

.. autoapisummary::

   arkouda.accessor.date_operators
   arkouda.accessor.string_operators


Module Contents
---------------

.. py:class:: CachedAccessor(name: str, accessor)

   Custom property-like object.
   A descriptor for caching accessors.
   :param name: Namespace that will be accessed under, e.g. ``df.foo``.
   :type name: str
   :param accessor: Class with the extension methods.
   :type accessor: cls

   .. rubric:: Notes

   For accessor, The class's __init__ method assumes that one of
   ``Series``, ``DataFrame`` or ``Index`` as the
   single argument ``data``.


.. py:class:: Categorical(values, **kwargs)

   Represents an array of values belonging to named categories. Converting a
   Strings object to Categorical often saves memory and speeds up operations,
   especially if there are many repeated values, at the cost of some one-time
   work in initialization.

   :param values: String values to convert to categories
   :type values: Strings
   :param NAvalue: The value to use to represent missing/null data
   :type NAvalue: str scalar

   .. attribute:: categories

      The set of category labels (determined automatically)

      :type: Strings

   .. attribute:: codes

      The category indices of the values or -1 for N/A

      :type: pdarray, int64

   .. attribute:: permutation

      The permutation that groups the values in the same order as categories

      :type: pdarray, int64

   .. attribute:: segments

      When values are grouped, the starting offset of each group

      :type: pdarray, int64

   .. attribute:: size

      The number of items in the array

      :type: Union[int,np.int64]

   .. attribute:: nlevels

      The number of distinct categories

      :type: Union[int,np.int64]

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: Union[int,np.int64]

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple


   .. py:attribute:: BinOps


   .. py:attribute:: RegisterablePieces


   .. py:attribute:: RequiredPieces


   .. py:method:: argsort()


   .. py:method:: attach(user_defined_name: str) -> Categorical
      :staticmethod:


      DEPRECATED
      Function to return a Categorical object attached to the registered name in the
      arkouda server which was registered using register()

      :param user_defined_name: user defined name which Categorical object was registered under
      :type user_defined_name: str

      :returns: The Categorical object created by re-attaching to the corresponding server components
      :rtype: Categorical

      :raises TypeError: if user_defined_name is not a string

      .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_categorical_by_name`



   .. py:method:: concatenate(others: Sequence[Categorical], ordered: bool = True) -> Categorical

      Merge this Categorical with other Categorical objects in the array,
      concatenating the arrays and synchronizing the categories.

      :param others: The Categorical arrays to concatenate and merge with this one
      :type others: Sequence[Categorical]
      :param ordered: If True (default), the arrays will be appended in the
                      order given. If False, array data may be interleaved
                      in blocks, which can greatly improve performance but
                      results in non-deterministic ordering of elements.
      :type ordered: bool

      :returns: The merged Categorical object
      :rtype: Categorical

      :raises TypeError: Raised if any others array objects are not Categorical objects

      .. rubric:: Notes

      This operation can be expensive -- slower than concatenating Strings.



   .. py:method:: contains(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.endswith`

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.



   .. py:attribute:: dtype


   .. py:method:: endswith(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The substring to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.contains`

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.



   .. py:method:: equals(other) -> bool

      Whether Categoricals are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the Categoricals are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> c = Categorical(ak.array(["a", "b", "c"]))
      >>> c_cpy = Categorical(ak.array(["a", "b", "c"]))
      >>> c.equals(c_cpy)
      True
      >>> c2 = Categorical(ak.array(["a", "x", "c"]))
      >>> c.equals(c2)
      False



   .. py:method:: from_codes(codes: arkouda.pdarrayclass.pdarray, categories: arkouda.strings.Strings, permutation=None, segments=None, **kwargs) -> Categorical
      :classmethod:


      Make a Categorical from codes and categories arrays. If codes and
      categories have already been pre-computed, this constructor saves
      time. If not, please use the normal constructor.

      :param codes: Category indices of each value
      :type codes: pdarray, int64
      :param categories: Unique category labels
      :type categories: Strings
      :param permutation: The permutation that groups the values in the same order
                          as categories
      :type permutation: pdarray, int64
      :param segments: When values are grouped, the starting offset of each group
      :type segments: pdarray, int64

      :returns: The Categorical object created from the input parameters
      :rtype: Categorical

      :raises TypeError: Raised if codes is not a pdarray of int64 objects or if
          categories is not a Strings object



   .. py:method:: from_return_msg(rep_msg) -> Categorical
      :classmethod:


      Create categorical from return message from server

      .. rubric:: Notes

      This is currently only used when reading a Categorical from HDF5 files.



   .. py:method:: group() -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      categories together. All instances of the same category are guaranteed
      to lie in one contiguous block of the permuted array, but the blocks
      are not necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      This method is faster than the corresponding Strings method. If the
      Categorical was created from a Strings object, then this function
      simply returns the cached permutation. Even if the Categorical was
      created using from_codes(), this function will be faster than
      Strings.group() because it sorts dense integer values, rather than
      128-bit hash values.



   .. py:method:: hash() -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each element of the Categorical.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:method:: in1d(test: Union[arkouda.strings.Strings, Categorical]) -> arkouda.pdarrayclass.pdarray

      Test whether each element of the Categorical object is
      also present in the test Strings or Categorical object.

      Returns a boolean array the same length as `self` that is True
      where an element of `self` is in `test` and False otherwise.

      :param test: The values against which to test each value of 'self`.
      :type test: Union[Strings,Categorical]

      :returns: The values `self[in1d]` are in the `test` Strings or Categorical object.
      :rtype: pdarray, bool

      :raises TypeError: Raised if test is not a Strings or Categorical object

      .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

      .. rubric:: Notes

      `in1d` can be considered as an element-wise function version of the
      python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
      equivalent to ``ak.array([item in b for item in a])``, but is much
      faster and scales to arbitrarily large ``a``.

      .. rubric:: Examples

      >>> strings = ak.array([f'String {i}' for i in range(0,5)])
      >>> cat = ak.Categorical(strings)
      >>> ak.in1d(cat,strings)
      array([True, True, True, True, True])
      >>> strings = ak.array([f'String {i}' for i in range(5,9)])
      >>> catTwo = ak.Categorical(strings)
      >>> ak.in1d(cat,catTwo)
      array([False, False, False, False, False])



   .. py:property:: inferred_type
      :type: str

      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

       Return True iff the object is contained in the registry or is a component of a
       registered object.

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_categorical_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: isna()

      Find where values are missing or null (as defined by self.NAvalue)



   .. py:property:: nbytes
      The size of the Categorical in bytes.

      :returns: The size of the Categorical in bytes.
      :rtype: int


   .. py:attribute:: objType
      :value: 'Categorical'



   .. py:method:: parse_hdf_categoricals(d: Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]) -> Tuple[List[str], Dict[str, Categorical]]
      :staticmethod:


      This function should be used in conjunction with the load_all function which reads hdf5 files
      and reconstitutes Categorical objects.
      Categorical objects use a naming convention and HDF5 structure so they can be identified and
      constructed for the user.

      In general you should not call this method directly

      :param d:
      :type d: Dictionary of String to either Pdarray or Strings object

      :returns: * *2-Tuple of List of strings containing key names which should be removed and Dictionary of*
                * *base name to Categorical object*

      .. seealso:: :obj:`Categorical.save`, :obj:`load_all`



   .. py:attribute:: permutation
      :value: None



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: register(user_defined_name: str) -> Categorical

      Register this Categorical object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Categorical is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Categorical which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different Categoricals with the same name.
      :rtype: Categorical

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Categorical with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: reset_categories() -> Categorical

      Recompute the category labels, discarding any unused labels. This
      method is often useful after slicing or indexing a Categorical array,
      when the resulting array only contains a subset of the original
      categories. In this case, eliminating unused categories can speed up
      other operations.

      :returns: A Categorical object generated from the current instance
      :rtype: Categorical



   .. py:method:: save(prefix_path: str, dataset: str = 'categorical_array', file_format: str = 'HDF5', mode: str = 'truncate', file_type: str = 'distribute', compression: Optional[str] = None) -> str

      DEPRECATED
      Save the Categorical object to HDF5 or Parquet. The result is a collection of HDF5/Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path and dataset. Each locale saves its chunk of the Strings array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param file_format: The format to save the file to.
      :type file_format: str {'HDF5 | 'Parquet'}
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")
      :param compression: {None | 'snappy' | 'gzip' | 'brotli' | 'zstd' | 'lz4'}
                          The compression type to use when writing.
                          This is only supported for Parquet files and will not be used with HDF5.
      :type compression: str (Optional)

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.

      .. seealso:: :obj:`-`, :obj:`-`



   .. py:attribute:: segments
      :value: None



   .. py:method:: set_categories(new_categories, NAvalue=None)

      Set categories to user-defined values.

      :param new_categories: The array of new categories to use. Must be unique.
      :type new_categories: Strings
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A new Categorical with the user-defined categories. Old values present
                in new categories will appear unchanged. Old values not present will
                be assigned the NA value.
      :rtype: Categorical



   .. py:method:: sort_values()


   .. py:method:: standardize_categories(arrays, NAvalue='N/A')
      :classmethod:


      Standardize an array of Categoricals so that they share the same categories.

      :param arrays: The Categoricals to standardize
      :type arrays: sequence of Categoricals
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A list of the original Categoricals remapped to the shared categories.
      :rtype: List of Categoricals



   .. py:method:: startswith(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The substring to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Categorical.contains`, :obj:`Categorical.endswith`

      .. rubric:: Notes

      This method can be significantly faster than the corresponding
      method on Strings objects, because it searches the unique category
      labels instead of the full array.



   .. py:method:: to_hdf(prefix_path, dataset='categorical_array', mode='truncate', file_type='distribute')

      Save the Categorical to HDF5. The result is a collection of HDF5 files, one file
      per locale of the arkouda server, where each filename starts with prefix_path.

      :param prefix_path: Directory and filename prefix that all output files will share
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 file
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', add data as a new column to existing files.
      :type mode: str {'truncate' | 'append'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
      :type file_type: str ("single" | "distribute")

      :rtype: None

      .. seealso:: :obj:`load`



   .. py:method:: to_list() -> List

      Convert the Categorical to a list, transferring data from
      the arkouda server to Python. This conversion discards category
      information and produces a list of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A list of strings corresponding to the values in
                this Categorical
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the Categorical cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from
      the arkouda server to Python. This conversion discards category
      information and produces an ndarray of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A numpy ndarray of strings corresponding to the values in
                this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'categorical_array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      This functionality is currently not supported and will also raise a RuntimeError.
      Support is in development.
      Save the Categorical to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: Default None
                          Provide the compression type to use when writing the file.
                          Supported values: snappy, gzip, brotli, zstd, lz4
      :type compression: str (Optional)

      :rtype: String message indicating result of save operation

      :raises RuntimeError: On run due to compatability issues of Categorical with Parquet.

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_strings() -> List

      Convert the Categorical to Strings.

      :returns: A Strings object corresponding to the values in
                this Categorical.
      :rtype: arkouda.strings.Strings

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> a = ak.array(["a","b","c"])
      >>> a
      >>> c = ak.Categorical(a)
      >>>  c.to_strings()
      c.to_strings()

      >>> isinstance(c.to_strings(), ak.Strings)
      True



   .. py:method:: transfer(hostname: str, port: arkouda.dtypes.int_scalars)

      Sends a Categorical object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Categorical is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unique() -> Categorical


   .. py:method:: unregister() -> None

      Unregister this Categorical object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_categorical_by_name(user_defined_name: str) -> None
      :staticmethod:


      Function to unregister Categorical object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the Categorical object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path, dataset='categorical_array', repack=True)

      Overwrite the dataset with the name provided with this Categorical object. If
      the dataset does not exist it is added.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: None

      :raises RuntimeError: Raised if a server-side error is thrown saving the Categorical

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added
      - Because HDF5 deletes do not release memory, the repack option allows for
        automatic creation of a file without the inaccessible data.



.. py:class:: Datetime(pda, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`


   Represents a date and/or time.

   Datetime is the Arkouda analog to pandas DatetimeIndex and
   other timeseries data types.

   :param pda:
   :type pda: int64 pdarray, pd.DatetimeIndex, pd.Series, or np.datetime64 array
   :param unit: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type unit: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.


   .. py:property:: date


   .. py:property:: day


   .. py:property:: day_of_week


   .. py:property:: day_of_year


   .. py:property:: dayofweek


   .. py:property:: dayofyear


   .. py:property:: hour


   .. py:property:: is_leap_year


   .. py:method:: is_registered() -> numpy.bool_

       Return True iff the object is contained in the registry or is a component of a
       registered object.

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:method:: isocalendar()


   .. py:property:: microsecond


   .. py:property:: millisecond


   .. py:property:: minute


   .. py:property:: month


   .. py:property:: nanosecond


   .. py:method:: register(user_defined_name)

      Register this Datetime object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Datetime is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Datetime which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support
                a fluid programming style.
                Please note you cannot register two different Datetimes with the same name.
      :rtype: Datetime

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Datetimes with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: second


   .. py:attribute:: special_objType
      :value: 'Datetime'



   .. py:method:: sum()

      Return the sum of all elements in the array.



   .. py:attribute:: supported_opeq


   .. py:attribute:: supported_with_datetime


   .. py:attribute:: supported_with_pdarray


   .. py:attribute:: supported_with_r_datetime


   .. py:attribute:: supported_with_r_pdarray


   .. py:attribute:: supported_with_r_timedelta


   .. py:attribute:: supported_with_timedelta


   .. py:method:: to_pandas()

      Convert array to a pandas DatetimeIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`



   .. py:method:: unregister()

      Unregister this Datetime object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.



   .. py:property:: week


   .. py:property:: weekday


   .. py:property:: weekofyear


   .. py:property:: year


.. py:class:: DatetimeAccessor(series)

   Bases: :py:obj:`Properties`


.. py:class:: Properties

.. py:class:: StringAccessor(series)

   Bases: :py:obj:`Properties`


.. py:class:: Strings(strings_pdarray: arkouda.pdarrayclass.pdarray, bytes_size: arkouda.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.


   .. py:attribute:: BinOps


   .. py:method:: astype(dtype) -> arkouda.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.



   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:


      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: cached_regex_patterns() -> List

      Returns the regex patterns for which Match objects have been cached



   .. py:method:: capitalize() -> Strings

      Returns a new Strings from the original replaced with the first letter capitilzed
      and the remaining letters lowercase.

      :returns: Strings from the original replaced with the capitalized equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`, :obj:`String.title`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS aRe Here {i}' for i in range(5)])
      >>> strings
      array(['StrINgS aRe Here 0', 'StrINgS aRe Here 1', 'StrINgS aRe Here 2', 'StrINgS aRe Here 3',
      ... 'StrINgS aRe Here 4'])
      >>> strings.title()
      array(['Strings are here 0', 'Strings are here 1', 'Strings are here 2', 'Strings are here 3',
      ... 'Strings are here 4'])



   .. py:method:: contains(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True, True, True, True, True])
      >>> strings.contains('string \d', regex=True)
      array([True, True, True, True, True])



   .. py:method:: decode(fromEncoding, toEncoding='UTF-8')

      Return a new strings object in `fromEncoding`, expecting that the
      current Strings is encoded in `toEncoding`

      :param fromEncoding: The current encoding of the strings object
      :type fromEncoding: str
      :param toEncoding: The encoding that the strings will be converted to,
                         default to UTF-8
      :type toEncoding: str

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: encode(toEncoding: str, fromEncoding: str = 'UTF-8')

      Return a new strings object in `toEncoding`, expecting that the
      current Strings is encoded in `fromEncoding`

      :param toEncoding: The encoding that the strings will be converted to
      :type toEncoding: str
      :param fromEncoding: The current encoding of the strings object, default to
                           UTF-8
      :type fromEncoding: str

      :returns: A new Strings object in `toEncoding`
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: endswith(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True, True, True, True, True])
      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True, True, True, True, True])



   .. py:method:: equals(other) -> bool

      Whether Strings are the same size and all entries are equal.

      :param other: object to compare.
      :type other: object

      :returns: True if the Strings are the same, o.w. False.
      :rtype: bool

      .. rubric:: Examples

      >>> import arkouda as ak
      >>> ak.connect()
      >>> s = ak.array(["a", "b", "c"])
      >>> s_cpy = ak.array(["a", "b", "c"])
      >>> s.equals(s_cpy)
      True
      >>> s2 = ak.array(["a", "x", "c"])
      >>> s.equals(s2)
      False



   .. py:method:: find_locations(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions,
      and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2, 2, 2, 2, 2])
      >>> starts
      array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
      >>> lens
      array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))



   .. py:method:: findall(pattern: Union[bytes, arkouda.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each
                                   pattern match is from
      :type return_match_origins: bool

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))



   .. py:method:: flatten(delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.flatten('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, map = orig.flatten('|', return_segments=True)
      >>> map
      array([0, 2, 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_flat, under_map = under.flatten('_+', return_segments=True, regex=True)
      >>> under_flat
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0, 2, 5])



   .. py:method:: from_parts(offset_attrib: Union[arkouda.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: Union[pdarray, str]
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: Union[pdarray, str]

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.



   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:


      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.



   .. py:method:: fullmatch(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the whole string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=False; matched=False>



   .. py:method:: get_bytes()

      Getter for the bytes component (uint8 pdarray) of this Strings.

      :returns: Pdarray of bytes of the string accessed
      :rtype: pdarray, uint8

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_bytes()
      [111 110 101 0 116 119 111 0 116 104 114 101 101 0]



   .. py:method:: get_lengths() -> arkouda.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown



   .. py:method:: get_offsets()

      Getter for the offsets component (int64 pdarray) of this Strings.

      :returns: Pdarray of offsets of the string accessed
      :rtype: pdarray, int64

      .. rubric:: Example

      >>> x = ak.array(['one', 'two', 'three'])
      >>> x.get_offsets()
      [0 4 8]



   .. py:method:: get_prefixes(n: arkouda.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.pdarrayclass.pdarray]]

      Return the n-long prefix of each string, where possible

      :param n: Length of prefix
      :type n: int
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-prefix
      :type return_origins: bool
      :param proper: If True, only return proper prefixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a prefix.
      :type proper: bool

      :returns: * **prefixes** (*Strings*) -- The array of n-character prefixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character prefix, False otherwise.



   .. py:method:: get_suffixes(n: arkouda.dtypes.int_scalars, return_origins: bool = True, proper: bool = True) -> Union[Strings, Tuple[Strings, arkouda.pdarrayclass.pdarray]]

      Return the n-long suffix of each string, where possible

      :param n: Length of suffix
      :type n: int
      :param return_origins: If True, return a logical index indicating which strings
                             were long enough to return an n-suffix
      :type return_origins: bool
      :param proper: If True, only return proper suffixes, i.e. from strings
                     that are at least n+1 long. If False, allow the entire
                     string to be returned as a suffix.
      :type proper: bool

      :returns: * **suffixes** (*Strings*) -- The array of n-character suffixes; the number of elements is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the string was long enough to return
                  an n-character suffix, False otherwise.



   .. py:method:: group() -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedString.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message



   .. py:method:: hash() -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.



   .. py:property:: inferred_type
      :type: str

      Return a string of the type inferred from the values.


   .. py:method:: info() -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str



   .. py:method:: is_registered() -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown



   .. py:method:: isalnum() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphanumeric.

      :returns: True for elements that are alphanumeric, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_alnum = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alnum = ak.array([f'Strings{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_alnum, alnum])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'Strings0', 'Strings1', 'Strings2'])
      >>> strings.isalnum()
      array([False False False True True True])



   .. py:method:: isalpha() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is alphabetic.  This means there is at least one character,
      and all the characters are alphabetic.

      :returns: True for elements that are alphabetic, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`, :obj:`Strings.isalnum`

      .. rubric:: Examples

      >>> not_alpha = ak.array([f'%Strings {i}' for i in range(3)])
      >>> alpha = ak.array(['StringA','StringB','StringC'])
      >>> strings = ak.concatenate([not_alpha, alpha])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', 'StringA','StringB','StringC'])
      >>> strings.isalpha()
      array([False False False True True True])



   .. py:method:: isdecimal() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all decimal characters.

      :returns: True for elements that are decimals, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isdigit`

      .. rubric:: Examples

      >>> not_decimal = ak.array([f'Strings {i}' for i in range(3)])
      >>> decimal = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_decimal, decimal])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdecimal()
      array([False False False True True True])
      Special Character Examples
      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdecimal()
      array([False True False False False])



   .. py:method:: isdigit() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings has all digit characters.

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_digit = ak.array([f'Strings {i}' for i in range(3)])
      >>> digit = ak.array([f'12{i}' for i in range(3)])
      >>> strings = ak.concatenate([not_digit, digit])
      >>> strings
      array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
      >>> strings.isdigit()
      array([False False False True True True])
      Special Character Examples
      >>> special_strings = ak.array(["3.14", "0", "²", "2³₇", "2³x₇"])
      >>> special_strings
      array(['3.14', '0', '²', '2³₇', '2³x₇'])
      >>> special_strings.isdigit()
      array([False True True True False])



   .. py:method:: isempty() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is empty.


      True for elements that are the empty string, False otherwise

      :returns: True for elements that are digits, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`, :obj:`Strings.istitle`

      .. rubric:: Examples

      >>> not_empty = ak.array([f'Strings {i}' for i in range(3)])
      >>> empty = ak.array(['' for i in range(3)])
      >>> strings = ak.concatenate([not_empty, empty])
      >>> strings
      array(['%Strings 0', '%Strings 1', '%Strings 2', '', '', ''])
      >>> strings.isempty()



   .. py:method:: islower() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.islower()
      array([True True True False False False])



   .. py:method:: isspace() -> arkouda.pdarrayclass.pdarray

              Returns a boolean pdarray where index i indicates whether string i has all
              whitespace characters (‘ ‘, ‘   ’, ‘
      ’, ‘
      ’, ‘
      ’, ‘
      ’).

              Returns
              -------
              pdarray, bool
                  True for elements that are whitespace, False otherwise

              Raises
              ------
              RuntimeError
                  Raised if there is a server-side error thrown

              See Also
              --------
              Strings.islower
              Strings.isupper
              Strings.istitle

              Examples
              --------
              >>> not_space = ak.array([f'Strings {i}' for i in range(3)])
              >>> space = ak.array([' ', '    ', '
      ', '
      ', '
      ', '
      ', '



      '])
              >>> strings = ak.concatenate([not_space, space])
              >>> strings
              array(['Strings 0', 'Strings 1', 'Strings 2', ' ',
              ... 'u0009', 'n', 'u000B', 'u000C', 'u000D', ' u0009nu000Bu000Cu000D'])
              >>> strings.isspace()
              array([False False False True True True True True True True])




   .. py:method:: istitle() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is titlecase

      :returns: True for elements that are titlecase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`, :obj:`Strings.isupper`

      .. rubric:: Examples

      >>> mixed = ak.array([f'sTrINgs {i}' for i in range(3)])
      >>> title = ak.array([f'Strings {i}' for i in range(3)])
      >>> strings = ak.concatenate([mixed, title])
      >>> strings
      array(['sTrINgs 0', 'sTrINgs 1', 'sTrINgs 2', 'Strings 0', 'Strings 1', 'Strings 2'])
      >>> strings.istitle()
      array([False False False True True True])



   .. py:method:: isupper() -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the
      Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.islower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.isupper()
      array([False False False True True True])



   .. py:method:: lower() -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with
      their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with
                their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])



   .. py:method:: lstick(other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: Union[bytes,str_scalars]

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])



   .. py:method:: match(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the
      regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the beginning of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False;
      matched=True, span=(0, 2); matched=False>



   .. py:attribute:: objType
      :value: 'Strings'



   .. py:method:: peel(delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))



   .. py:method:: pretty_print_info() -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None



   .. py:method:: purge_cached_regex_patterns() -> None

      purges cached regex patterns



   .. py:method:: register(user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and
                has an updated name.
                This is an in-place modification, the original is returned to support a
                fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name,
          the former should be unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.



   .. py:method:: rpeel(delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False)

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))
      # Compared against peel
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))



   .. py:method:: save(prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the Strings object to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. HDF5 support single files, in which case the file name will
      only be that provided. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: str ("single" | "distribute")

      :rtype: String message indicating result of save operation

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter. (3) Parquet files do not store the segments,
      only the values.



   .. py:method:: search(pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match if any part of the string matches the
                regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4);
      matched=False; matched=True, span=(0, 2); matched=False>



   .. py:method:: split(pattern: Union[bytes, arkouda.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern.
      If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: str
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))



   .. py:method:: startswith(substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2
                    (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True, True, True, True, True])
      >>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True, True, True, True, True])



   .. py:method:: stick(other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: str
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])



   .. py:method:: strip(chars: Optional[Union[bytes, arkouda.dtypes.str_scalars]] = '') -> Strings

      Returns a new Strings object with all leading and trailing occurrences of characters contained
      in chars removed. The chars argument is a string specifying the set of characters to be removed.
      If omitted, the chars argument defaults to removing whitespace. The chars argument is not a
      prefix or suffix; rather, all combinations of its values are stripped.

      :param chars: the set of characters to be removed

      :returns: Strings object with the leading and trailing characters matching the set of characters in
                the chars argument removed
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. rubric:: Examples

      >>> strings = ak.array(['Strings ', '  StringS  ', 'StringS   '])
      >>> s = strings.strip()
      >>> s
      array(['Strings', 'StringS', 'StringS'])

      >>> strings = ak.array(['Strings 1', '1 StringS  ', '  1StringS  12 '])
      >>> s = strings.strip(' 12')
      >>> s
      array(['Strings', 'StringS', 'StringS'])



   .. py:method:: sub(pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the
      replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])



   .. py:method:: subn(pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))



   .. py:method:: title() -> Strings

      Returns a new Strings from the original replaced with their titlecase equivalent.

      :returns: Strings from the original replaced with their titlecase equivalent.
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown.

      .. seealso:: :obj:`Strings.lower`, :obj:`String.upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.title()
      array(['Strings 0', 'Strings 1', 'Strings 2', 'Strings 3', 'Strings 4'])



   .. py:method:: to_csv(prefix_path: str, dataset: str = 'strings_array', col_delim: str = ',', overwrite: bool = False)

      Write Strings to CSV file(s). File will contain a single column with the Strings data.
      All CSV Files written by Arkouda include a header denoting data types of the columns.
      Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing
      bytes as uint(8).

      :param prefix_path: The filename prefix to be used for saving files. Files will have _LOCALE#### appended
                          when they are written to disk.
      :type prefix_path: str
      :param dataset: Column name to save the Strings under. Defaults to "strings_array".
      :type dataset: str
      :param col_delim: Defaults to ",". Value to be used to separate columns within the file.
                        Please be sure that the value used DOES NOT appear in your dataset.
      :type col_delim: str
      :param overwrite: Defaults to False. If True, any existing files matching your provided prefix_path will
                        be overwritten. If False, an error will be returned if existing files are found.
      :type overwrite: bool

      :rtype: str reponse message

      :raises ValueError: Raised if all datasets are not present in all parquet files or if one or
          more of the specified files do not exist
      :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
          If `allow_errors` is true this may be raised if no values are returned
          from the server.
      :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

      .. rubric:: Notes

      - CSV format is not currently supported by load/load_all operations
      - The column delimiter is expected to be the same for column names and data
      - Be sure that column delimiters are not found within your data.
      - All CSV files must delimit rows using newline (``\n``) at this time.



   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, file_type: str = 'distribute') -> str

      Save the Strings object to HDF5.
      The object can be saved to a collection of files or single file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool
      :param file_type: Default: Distribute
                        Distribute the dataset over a file per locale.
                        Single file will save the dataset to one file
      :type file_type: str ("single" | "distribute")

      :rtype: String message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - Parquet files do not store the segments, only the values.
      - Strings state is saved as two datasets within an hdf5 group:
        one for the string characters and one for the
        segments corresponding to the start of each string
      - the hdf5 group is named via the dataset parameter.
      - The prefix_path must be visible to the arkouda server and the user must
        have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
        ranges from 0 to ``numLocales`` for `file_type='distribute'`. Otherwise,
        the file name will be `prefix_path`.
      - If any of the output files already exist and
        the mode is 'truncate', they will be overwritten. If the mode is 'append'
        and the number of output files is less than the number of locales or a
        dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
        determine the file format.

      .. seealso:: :obj:`to_hdf`



   .. py:method:: to_list() -> list

      Convert the SegString to a list, transferring data from the
      arkouda server to Python. If the SegString exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A list with the same strings as this SegString
      :rtype: list

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`to_ndarray`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_list()
      ['hello', 'my', 'world']
      >>> type(a.to_list())
      list



   .. py:method:: to_ndarray() -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`, :obj:`to_list`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      numpy.ndarray



   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', compression: Optional[str] = None) -> str

      Save the Strings object to Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray

      .. rubric:: Notes

      - The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      - Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales`` for `file_type='distribute'`.
      - 'append' write mode is supported, but is not efficient.
      - If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      - Any file extension can be used.The file I/O does not rely on the extension to
      determine the file format.



   .. py:method:: transfer(hostname: str, port: arkouda.dtypes.int_scalars)

      Sends a Strings object to a different Arkouda server

      :param hostname: The hostname where the Arkouda server intended to
                       receive the Strings object is running.
      :type hostname: str
      :param port: The port to send the array over. This needs to be an
                   open port (i.e., not one that the Arkouda server is
                   running on). This will open up `numLocales` ports,
                   each of which in succession, so will use ports of the
                   range {port..(port+numLocales)} (e.g., running an
                   Arkouda server of 4 nodes, port 1234 is passed as
                   `port`, Arkouda will use ports 1234, 1235, 1236,
                   and 1237 to send the array data).
                   This port much match the port passed to the call to
                   `ak.receive_array()`.
      :type port: int_scalars

      :rtype: A message indicating a complete transfer

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype



   .. py:method:: unregister() -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.



   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:


      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



   .. py:method:: update_hdf(prefix_path: str, dataset: str = 'strings_array', save_offsets: bool = True, repack: bool = True)

      Overwrite the dataset with the name provided with this Strings object. If
      the dataset does not exist it is added

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files
      :type dataset: str
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool
      :param repack: Default: True
                     HDF5 does not release memory on delete. When True, the inaccessible
                     data (that was overwritten) is removed. When False, the data remains, but is
                     inaccessible. Setting to false will yield better performance, but will cause
                     file sizes to expand.
      :type repack: bool

      :rtype: str - success message if successful

      :raises RuntimeError: Raised if a server-side error is thrown saving the Strings object

      .. rubric:: Notes

      - If file does not contain File_Format attribute to indicate how it was saved,
        the file name is checked for _LOCALE#### to determine if it is distributed.
      - If the dataset provided does not exist, it will be added



   .. py:method:: upper() -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with
      their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with
                their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])



.. py:function:: date_operators(cls)

.. py:function:: string_operators(cls)

