<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" />

    <!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>arkouda.io - arkouda documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">arkouda  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">arkouda  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../setup/REQUIREMENTS.html">Requirements</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../setup/install_menu.html">Installation</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Installation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../setup/LINUX_INSTALL.html">Linux</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/WINDOWS_INSTALL.html">Windows (WSL2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/MAC_INSTALL.html">MacOS</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../setup/BUILD.html">Building the Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../setup/MODULAR.html">Modular Server Builds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../setup/testing.html">Performance Testing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../file_io/io_menu.html">File I/O</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of File I/O</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../file_io/HDF5.html">HDF5</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../file_io/PARQUET.html">Parquet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../file_io/CSV.html">CSV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../file_io/IMPORT_EXPORT.html">Import/Export</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usage.html">Usage Guide</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Usage Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usage/startup.html">Startup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/pdarray.html">The <code class="docutils literal notranslate"><span class="pre">pdarray</span></code> class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/creation.html">Creating Arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/arithmetic.html">Arithmetic and Numeric Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/indexing.html">Indexing and Assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/histogram.html">Summarizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/argsort.html">Sorting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/setops.html">Array Set Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/groupby.html">GroupBy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/strings.html">Strings in Arkouda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/categorical.html">Categoricals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/random.html">Random in Arkouda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usage/segarray.html">SegArrays in Arkouda</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CONTRIBUTING_LINK.html">Contributing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../autoapi/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../autoapi/arkouda/index.html">arkouda</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of arkouda</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/accessor/index.html">arkouda.accessor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/alignment/index.html">arkouda.alignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/apply/index.html">arkouda.apply</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../autoapi/arkouda/array_api/index.html">arkouda.array_api</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of arkouda.array_api</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/array_object/index.html">arkouda.array_api.array_object</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/creation_functions/index.html">arkouda.array_api.creation_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/data_type_functions/index.html">arkouda.array_api.data_type_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/elementwise_functions/index.html">arkouda.array_api.elementwise_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/indexing_functions/index.html">arkouda.array_api.indexing_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/linalg/index.html">arkouda.array_api.linalg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/manipulation_functions/index.html">arkouda.array_api.manipulation_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/searching_functions/index.html">arkouda.array_api.searching_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/set_functions/index.html">arkouda.array_api.set_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/sorting_functions/index.html">arkouda.array_api.sorting_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/statistical_functions/index.html">arkouda.array_api.statistical_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/array_api/utility_functions/index.html">arkouda.array_api.utility_functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/categorical/index.html">arkouda.categorical</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/client/index.html">arkouda.client</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/client_dtypes/index.html">arkouda.client_dtypes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/comm_diagnostics/index.html">arkouda.comm_diagnostics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/dataframe/index.html">arkouda.dataframe</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/groupbyclass/index.html">arkouda.groupbyclass</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/history/index.html">arkouda.history</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/index/index.html">arkouda.index</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/infoclass/index.html">arkouda.infoclass</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/io/index.html">arkouda.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/io_util/index.html">arkouda.io_util</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/join/index.html">arkouda.join</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/logger/index.html">arkouda.logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/match/index.html">arkouda.match</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/matcher/index.html">arkouda.matcher</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../autoapi/arkouda/numpy/index.html">arkouda.numpy</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of arkouda.numpy</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/char/index.html">arkouda.numpy.char</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/ctypeslib/index.html">arkouda.numpy.ctypeslib</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/dtypes/index.html">arkouda.numpy.dtypes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/exceptions/index.html">arkouda.numpy.exceptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/fft/index.html">arkouda.numpy.fft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/imports/index.html">arkouda.numpy.imports</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../autoapi/arkouda/numpy/lib/index.html">arkouda.numpy.lib</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of arkouda.numpy.lib</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../autoapi/arkouda/numpy/lib/emath/index.html">arkouda.numpy.lib.emath</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../autoapi/arkouda/numpy/lib/npyio/index.html">arkouda.numpy.lib.npyio</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/linalg/index.html">arkouda.numpy.linalg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/ma/index.html">arkouda.numpy.ma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/manipulation_functions/index.html">arkouda.numpy.manipulation_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/numeric/index.html">arkouda.numpy.numeric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/pdarrayclass/index.html">arkouda.numpy.pdarrayclass</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/pdarraycreation/index.html">arkouda.numpy.pdarraycreation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/pdarraymanipulation/index.html">arkouda.numpy.pdarraymanipulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/pdarraysetops/index.html">arkouda.numpy.pdarraysetops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/polynomial/index.html">arkouda.numpy.polynomial</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../autoapi/arkouda/numpy/random/index.html">arkouda.numpy.random</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of arkouda.numpy.random</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../autoapi/arkouda/numpy/random/generator/index.html">arkouda.numpy.random.generator</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../autoapi/arkouda/numpy/random/legacy/index.html">arkouda.numpy.random.legacy</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/rec/index.html">arkouda.numpy.rec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/segarray/index.html">arkouda.numpy.segarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/sorting/index.html">arkouda.numpy.sorting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/strings/index.html">arkouda.numpy.strings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/timeclass/index.html">arkouda.numpy.timeclass</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/util/index.html">arkouda.numpy.util</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/numpy/utils/index.html">arkouda.numpy.utils</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../autoapi/arkouda/pandas/index.html">arkouda.pandas</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of arkouda.pandas</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/pandas/join/index.html">arkouda.pandas.join</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/pandas/row/index.html">arkouda.pandas.row</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/pandas/series/index.html">arkouda.pandas.series</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/plotting/index.html">arkouda.plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/row/index.html">arkouda.row</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../autoapi/arkouda/scipy/index.html">arkouda.scipy</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of arkouda.scipy</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/scipy/special/index.html">arkouda.scipy.special</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../autoapi/arkouda/scipy/stats/index.html">arkouda.scipy.stats</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/security/index.html">arkouda.security</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/series/index.html">arkouda.series</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/sparrayclass/index.html">arkouda.sparrayclass</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/sparsematrix/index.html">arkouda.sparsematrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autoapi/arkouda/testing/index.html">arkouda.testing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../server/index.html">Chapel API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../developer/dev_menu.html">Developer Documentation</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Developer Documentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../developer/TIPS.html">Speeding up Arkouda Compilation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../developer/USER_BUGS.html">Tips for Reproducing User Bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../developer/MEMORY.html">Reducing Memory Usage of Arkouda Builds</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../developer/GASNET.html">GASNet Development</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../developer/RELEASE_PROCESS.html">Release Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../developer/BENCHMARK.html">PyTest Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../developer/ADDING_FEATURES.html">Adding Your First Feature</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <h1>Source code for arkouda.io</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">glob</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">cast</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">warnings</span><span class="w"> </span><span class="kn">import</span> <span class="n">warn</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typeguard</span><span class="w"> </span><span class="kn">import</span> <span class="n">typechecked</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.categorical</span><span class="w"> </span><span class="kn">import</span> <span class="n">Categorical</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.client</span><span class="w"> </span><span class="kn">import</span> <span class="n">generic_msg</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.client_dtypes</span><span class="w"> </span><span class="kn">import</span> <span class="n">IPv4</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.dataframe</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.groupbyclass</span><span class="w"> </span><span class="kn">import</span> <span class="n">GroupBy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.index</span><span class="w"> </span><span class="kn">import</span> <span class="n">Index</span><span class="p">,</span> <span class="n">MultiIndex</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.numpy.dtypes</span><span class="w"> </span><span class="kn">import</span> <span class="n">float32</span><span class="p">,</span> <span class="n">float64</span><span class="p">,</span> <span class="n">int32</span><span class="p">,</span> <span class="n">int64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.numpy.pdarrayclass</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_pdarray</span><span class="p">,</span> <span class="n">pdarray</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.numpy.pdarraycreation</span><span class="w"> </span><span class="kn">import</span> <span class="n">arange</span><span class="p">,</span> <span class="n">array</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.numpy.segarray</span><span class="w"> </span><span class="kn">import</span> <span class="n">SegArray</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.numpy.strings</span><span class="w"> </span><span class="kn">import</span> <span class="n">Strings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.numpy.timeclass</span><span class="w"> </span><span class="kn">import</span> <span class="n">Datetime</span><span class="p">,</span> <span class="n">Timedelta</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;get_filetype&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ls&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ls_csv&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_null_indices&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_datasets&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_columns&quot;</span><span class="p">,</span>
    <span class="s2">&quot;read_hdf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;read_parquet&quot;</span><span class="p">,</span>
    <span class="s2">&quot;read_csv&quot;</span><span class="p">,</span>
    <span class="s2">&quot;read_zarr&quot;</span><span class="p">,</span>
    <span class="s2">&quot;read&quot;</span><span class="p">,</span>
    <span class="s2">&quot;read_tagged_data&quot;</span><span class="p">,</span>
    <span class="s2">&quot;import_data&quot;</span><span class="p">,</span>
    <span class="s2">&quot;export&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_hdf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_parquet&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_csv&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_zarr&quot;</span><span class="p">,</span>
    <span class="s2">&quot;load&quot;</span><span class="p">,</span>
    <span class="s2">&quot;load_all&quot;</span><span class="p">,</span>
    <span class="s2">&quot;update_hdf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;snapshot&quot;</span><span class="p">,</span>
    <span class="s2">&quot;restore&quot;</span><span class="p">,</span>
    <span class="s2">&quot;receive&quot;</span><span class="p">,</span>
    <span class="s2">&quot;receive_dataframe&quot;</span><span class="p">,</span>
    <span class="s2">&quot;save_checkpoint&quot;</span><span class="p">,</span>
    <span class="s2">&quot;load_checkpoint&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">ARKOUDA_HDF5_FILE_METADATA_GROUP</span> <span class="o">=</span> <span class="s2">&quot;_arkouda_metadata&quot;</span>


<div class="viewcode-block" id="get_filetype">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.get_filetype">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_filetype</span><span class="p">(</span><span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the type of a file accessible to the server.</span>

<span class="sd">    Supported file types and possible return strings are &#39;HDF5&#39; and &#39;Parquet&#39;.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames : Union[str, List[str]]</span>
<span class="sd">        A file or list of files visible to the arkouda server</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    str</span>
<span class="sd">        Type of the file returned as a string, either &#39;HDF5&#39;, &#39;Parquet&#39; or &#39;CSV</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if filename is empty or contains only whitespace</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - When list provided, it is assumed that all files are the same type</span>
<span class="sd">    - CSV Files without the Arkouda Header are not supported</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    read_parquet, read_hdf</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">fname</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fname</span> <span class="o">=</span> <span class="n">filenames</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">fname</span> <span class="ow">and</span> <span class="n">fname</span><span class="o">.</span><span class="n">strip</span><span class="p">()):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;filename cannot be an empty string&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">generic_msg</span><span class="p">(</span><span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;getfiletype&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">fname</span><span class="p">}))</span></div>



<div class="viewcode-block" id="ls">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.ls">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">ls</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">col_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="n">read_nested</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    List the contents of an HDF5 or Parquet file on the Arkouda server.</span>

<span class="sd">    This function invokes the HDF5 `h5ls` utility on a file visible to the</span>
<span class="sd">    Arkouda server, or simulates a similar listing for Parquet files. For CSV</span>
<span class="sd">    files without headers, see `ls_csv`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename : str</span>
<span class="sd">        Path to the file on the Arkouda server. Must be a non-empty string.</span>
<span class="sd">    col_delim : str, default=&quot;,&quot;</span>
<span class="sd">        Delimiter to use when interpreting CSV files.</span>
<span class="sd">    read_nested : bool, default=True</span>
<span class="sd">        If True, include nested Parquet columns (e.g., `SegArray`). If False,</span>
<span class="sd">        nested columns are ignored. Only applies to Parquet files.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[str]</span>
<span class="sd">        A list of lines describing each dataset or column in the file.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError</span>
<span class="sd">        If `filename` is not a string.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If `filename` is empty or contains only whitespace.</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        If an error occurs when running `h5ls` or simulating the Parquet listing.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Parquet support is limited and may change in future releases.</span>
<span class="sd">    - Output lines mirror the format of the HDF5 `h5ls` output.</span>
<span class="sd">    - For CSV files lacking headers, use `ls_csv`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ls_csv : List the contents of CSV files without headers.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">filename</span> <span class="ow">and</span> <span class="n">filename</span><span class="o">.</span><span class="n">strip</span><span class="p">()):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;filename cannot be an empty string&quot;</span><span class="p">)</span>

    <span class="n">cmd</span> <span class="o">=</span> <span class="s2">&quot;lsany&quot;</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span>
        <span class="n">cast</span><span class="p">(</span>
            <span class="nb">str</span><span class="p">,</span>
            <span class="n">generic_msg</span><span class="p">(</span>
                <span class="n">cmd</span><span class="o">=</span><span class="n">cmd</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;col_delim&quot;</span><span class="p">:</span> <span class="n">col_delim</span><span class="p">,</span> <span class="s2">&quot;read_nested&quot;</span><span class="p">:</span> <span class="n">read_nested</span><span class="p">},</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="get_null_indices">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.get_null_indices">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_null_indices</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pdarray</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get null indices of a string column in a Parquet file.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames : list or str</span>
<span class="sd">        Either a list of filenames or shell expression</span>
<span class="sd">    datasets : list or str or None</span>
<span class="sd">        (List of) name(s) of dataset(s) to read. Each dataset must be a string</span>
<span class="sd">        column. There is no default value for this function, the datasets to be</span>
<span class="sd">        read must be specified.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    returns a dictionary of Arkouda pdarrays</span>
<span class="sd">        Dictionary of {datasetName: pdarray}</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if one or more of the specified files cannot be opened.</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if we receive an unknown arkouda_type returned from the server</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    get_datasets, ls</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">datasets</span><span class="p">]</span>
    <span class="n">rep_msg</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span>
        <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;getnullparquet&quot;</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;dset_size&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span> <span class="k">if</span> <span class="n">datasets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># if needed for mypy</span>
            <span class="s2">&quot;filename_size&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">),</span>
            <span class="s2">&quot;dsets&quot;</span><span class="p">:</span> <span class="n">datasets</span><span class="p">,</span>
            <span class="s2">&quot;filenames&quot;</span><span class="p">:</span> <span class="n">filenames</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">rep</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">)</span>  <span class="c1"># See GenSymIO._buildReadAllMsgJson for json structure</span>
    <span class="c1"># ignore the type here because we are returning a specific case</span>
    <span class="k">return</span> <span class="n">_build_objects</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span>  <span class="c1"># type: ignore</span></div>



<span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_file_type_to_int</span><span class="p">(</span><span class="n">file_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a string to integer representing the format to save the file in.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    file_type: str (single | distribute)</span>
<span class="sd">        The string representation of the format for saving the file</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    int representing the format</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If mode is not &#39;single&#39; or &#39;distribute&#39;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">file_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;single&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">file_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;distribute&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;File Type expected to be &#39;single&#39; or &#39;distributed&#39;. Got </span><span class="si">{</span><span class="n">file_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_mode_str_to_int</span><span class="p">(</span><span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert string to integer representing the mode to write.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mode: str (truncate | append)</span>
<span class="sd">        The string representation of the write mode to be converted to integer</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    int representing the mode</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If mode is not &#39;truncate&#39; or &#39;append&#39;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;truncate&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;append&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Write Mode expected to be &#39;truncate&#39; or &#39;append&#39;. Got </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="get_datasets">
<a class="viewcode-back" href="../../usage/IO.html#arkouda.get_datasets">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_datasets</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">column_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span>
    <span class="n">read_nested</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the names of the datasets in the provide files.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames: str or List[str]</span>
<span class="sd">        Name of the file/s from which to return datasets</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default: False</span>
<span class="sd">        Whether or not to allow errors while accessing datasets</span>
<span class="sd">    column_delim : str</span>
<span class="sd">        Column delimiter to be used if dataset is CSV. Otherwise, unused.</span>
<span class="sd">    read_nested: bool</span>
<span class="sd">        Default True, when True, SegArray objects will be read from the file. When False,</span>
<span class="sd">        SegArray (or other nested Parquet columns) will be ignored.</span>
<span class="sd">        Only used for Parquet Files.</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[str] of names of the datasets</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        - If no datasets are returned</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - This function currently supports HDF5 and Parquet formats.</span>
<span class="sd">    - Future updates to Parquet will deprecate this functionality on that format,</span>
<span class="sd">    but similar support will be added for Parquet at that time.</span>
<span class="sd">    - If a list of files is provided, only the datasets in the first file will be returned</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ls</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">datasets</span> <span class="o">=</span> <span class="n">ls</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">col_delim</span><span class="o">=</span><span class="n">column_delim</span><span class="p">,</span> <span class="n">read_nested</span><span class="o">=</span><span class="n">read_nested</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">datasets</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">allow_errors</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">datasets</span><span class="p">:</span>  <span class="c1"># empty</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Unable to identify datasets.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">datasets</span></div>



<div class="viewcode-block" id="ls_csv">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.ls_csv">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">ls_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">col_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    List the datasets within a file when a CSV does not have a header.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename : str</span>
<span class="sd">        The name of the file to pass to the server</span>
<span class="sd">    col_delim : str</span>
<span class="sd">        The delimiter used to separate columns if the file is a csv</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    str</span>
<span class="sd">        The string output of the datasets from the server</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ls</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">filename</span> <span class="ow">and</span> <span class="n">filename</span><span class="o">.</span><span class="n">strip</span><span class="p">()):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;filename cannot be an empty string&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span>
        <span class="n">cast</span><span class="p">(</span>
            <span class="nb">str</span><span class="p">,</span>
            <span class="n">generic_msg</span><span class="p">(</span>
                <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;lscsv&quot;</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;col_delim&quot;</span><span class="p">:</span> <span class="n">col_delim</span><span class="p">},</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="get_columns">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.get_columns">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_columns</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">col_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a list of column names from CSV file(s).&quot;&quot;&quot;</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">datasets</span> <span class="o">=</span> <span class="n">ls_csv</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">col_delim</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">datasets</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">allow_errors</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">datasets</span><span class="p">:</span>  <span class="c1"># empty</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Unable to identify datasets.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">datasets</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_prep_datasets</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">read_nested</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prepare a list of datasets to be read.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames: str or List[str]</span>
<span class="sd">        Names of the files for which datasets are being prepped.</span>
<span class="sd">        Used to call get_datasets()</span>
<span class="sd">    datasets: Optional str or List[str]</span>
<span class="sd">        datasets to be accessed</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default: False</span>
<span class="sd">        Whether or not to allow errors during access operations</span>
<span class="sd">    read_nested: bool</span>
<span class="sd">        Default True, when True, SegArray objects will be read from the file. When False,</span>
<span class="sd">        SegArray (or other nested Parquet columns) will be ignored.</span>
<span class="sd">        Only used for Parquet Files</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[str] of dataset names to access</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        - If one or more datasets cannot be found</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">datasets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># get datasets. We know they exist because we pulled from the file</span>
        <span class="n">datasets</span> <span class="o">=</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">,</span> <span class="n">read_nested</span><span class="o">=</span><span class="n">read_nested</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="c1"># TODO - revisit this and enable checks that support things like &quot;strings/values&quot;</span>
            <span class="c1"># old logic did not check existence for single string dataset.</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">datasets</span><span class="p">]</span>
        <span class="c1"># ensure dataset(s) exist</span>
        <span class="c1"># read_nested always true because when user supplies datasets, it is ignored</span>
        <span class="n">nonexistent</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">get_datasets</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">,</span> <span class="n">read_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nonexistent</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset(s) not found: </span><span class="si">{</span><span class="n">nonexistent</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">datasets</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_errors</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse error messages from a read operation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rep_msg</span>
<span class="sd">        The server response from a read operation</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default: False</span>
<span class="sd">        Whether or not errors are to be allowed during read operation</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">file_errors</span> <span class="o">=</span> <span class="n">rep_msg</span><span class="p">[</span><span class="s2">&quot;file_errors&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;file_errors&quot;</span> <span class="ow">in</span> <span class="n">rep_msg</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">allow_errors</span> <span class="ow">and</span> <span class="n">file_errors</span><span class="p">:</span>
        <span class="n">file_error_count</span> <span class="o">=</span> <span class="n">rep_msg</span><span class="p">[</span><span class="s2">&quot;file_error_count&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;file_error_count&quot;</span> <span class="ow">in</span> <span class="n">rep_msg</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;There were </span><span class="si">{</span><span class="n">file_error_count</span><span class="si">}</span><span class="s2"> errors reading files on the server. &quot;</span>
            <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;Sample error messages </span><span class="si">{</span><span class="n">file_errors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="ne">RuntimeWarning</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_obj</span><span class="p">(</span>
    <span class="n">obj</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Strings</span><span class="p">,</span>
    <span class="n">pdarray</span><span class="p">,</span>
    <span class="n">SegArray</span><span class="p">,</span>
    <span class="n">Categorical</span><span class="p">,</span>
    <span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">IPv4</span><span class="p">,</span>
    <span class="n">Datetime</span><span class="p">,</span>
    <span class="n">Timedelta</span><span class="p">,</span>
    <span class="n">Index</span><span class="p">,</span>
    <span class="n">MultiIndex</span><span class="p">,</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an Arkouda object from read response.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obj : Dict</span>
<span class="sd">        The response data used to create an Arkouda object</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Strings, pdarray, SegArray, IPv4, Datetime, Timedelta, Categorical, GroupBy, DataFrame, or Index</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError</span>
<span class="sd">        - If return object is an unsupported type</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">Strings</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">Strings</span><span class="o">.</span><span class="n">from_return_msg</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">SegArray</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">SegArray</span><span class="o">.</span><span class="n">from_return_msg</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">pdarray</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">create_pdarray</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">IPv4</span><span class="o">.</span><span class="n">special_objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">IPv4</span><span class="p">(</span><span class="n">create_pdarray</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">]))</span>
    <span class="k">elif</span> <span class="n">Datetime</span><span class="o">.</span><span class="n">special_objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">Datetime</span><span class="p">(</span><span class="n">create_pdarray</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">]))</span>
    <span class="k">elif</span> <span class="n">Timedelta</span><span class="o">.</span><span class="n">special_objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">Timedelta</span><span class="p">(</span><span class="n">create_pdarray</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">]))</span>
    <span class="k">elif</span> <span class="n">Categorical</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">Categorical</span><span class="o">.</span><span class="n">from_return_msg</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">GroupBy</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">GroupBy</span><span class="o">.</span><span class="n">from_return_msg</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">DataFrame</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">DataFrame</span><span class="o">.</span><span class="n">from_return_msg</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>
    <span class="k">elif</span> <span class="p">(</span>
        <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="n">Index</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="ow">or</span> <span class="n">obj</span><span class="p">[</span><span class="s2">&quot;arkouda_type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="n">MultiIndex</span><span class="o">.</span><span class="n">objType</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="p">):</span>
        <span class="k">return</span> <span class="n">Index</span><span class="o">.</span><span class="n">from_return_msg</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown arkouda type:</span><span class="si">{</span><span class="n">obj</span><span class="p">[</span><span class="s1">&#39;arkouda_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_dict_recombine_segarrays_categoricals</span><span class="p">(</span><span class="n">df_dict</span><span class="p">):</span>
    <span class="c1"># this assumes segments will always have corresponding values.</span>
    <span class="c1"># This should happen due to save config</span>
    <span class="n">seg_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">col</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_segments&quot;</span><span class="p">)]</span>
    <span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">col</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.categories&quot;</span><span class="p">)]</span>
    <span class="n">df_dict_keys</span> <span class="o">=</span> <span class="p">{</span>
        <span class="p">(</span>
            <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">col</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_segments&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_values&quot;</span><span class="p">)</span>
            <span class="k">else</span> <span class="p">(</span>
                <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">col</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;._akNAcode&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.categories&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.codes&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.permutation&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.segments&quot;</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">col</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="c1"># update dict to contain segarrays where applicable if any exist</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">seg_cols</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_cols</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">df_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">col</span><span class="p">:</span> <span class="p">(</span>
                <span class="n">SegArray</span><span class="p">(</span><span class="n">df_dict</span><span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s2">&quot;_segments&quot;</span><span class="p">],</span> <span class="n">df_dict</span><span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s2">&quot;_values&quot;</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">seg_cols</span>
                <span class="k">else</span> <span class="p">(</span>
                    <span class="n">Categorical</span><span class="o">.</span><span class="n">from_codes</span><span class="p">(</span>
                        <span class="n">df_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">.codes&quot;</span><span class="p">],</span>
                        <span class="n">df_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">.categories&quot;</span><span class="p">],</span>
                        <span class="n">permutation</span><span class="o">=</span><span class="p">(</span>
                            <span class="n">df_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">.permutation&quot;</span><span class="p">]</span>
                            <span class="k">if</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">.permutation&quot;</span> <span class="ow">in</span> <span class="n">df_dict_keys</span>
                            <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">),</span>
                        <span class="n">segments</span><span class="o">=</span><span class="p">(</span>
                            <span class="n">df_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">.segments&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">.segments&quot;</span> <span class="ow">in</span> <span class="n">df_dict_keys</span> <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">),</span>
                        <span class="n">_akNAcode</span><span class="o">=</span><span class="n">df_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">._akNAcode&quot;</span><span class="p">],</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cat_cols</span>
                    <span class="k">else</span> <span class="n">df_dict</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_dict_keys</span>
        <span class="p">}</span>
    <span class="k">return</span> <span class="n">df_dict</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_build_objects</span><span class="p">(</span>
    <span class="n">rep_msg</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Mapping</span><span class="p">[</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">Union</span><span class="p">[</span>
            <span class="n">Strings</span><span class="p">,</span>
            <span class="n">pdarray</span><span class="p">,</span>
            <span class="n">SegArray</span><span class="p">,</span>
            <span class="n">Categorical</span><span class="p">,</span>
            <span class="n">DataFrame</span><span class="p">,</span>
            <span class="n">IPv4</span><span class="p">,</span>
            <span class="n">Datetime</span><span class="p">,</span>
            <span class="n">Timedelta</span><span class="p">,</span>
            <span class="n">Index</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create the Arkouda objects from a read operation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rep_msg: Dict</span>
<span class="sd">        rep_msg to create objects from</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dictionary mapping the dataset name to the object</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        - If no objects were returned</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">items</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">[</span><span class="s2">&quot;items&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="s2">&quot;items&quot;</span> <span class="ow">in</span> <span class="n">rep_msg</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_dict_recombine_segarrays_categoricals</span><span class="p">(</span>
            <span class="p">{</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;dataset_name&quot;</span><span class="p">]:</span> <span class="n">_parse_obj</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;No items were returned&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="read_hdf">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.read_hdf">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">read_hdf</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iterative</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">strict_types</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">calc_string_offsets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">tag_data</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Mapping</span><span class="p">[</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">Union</span><span class="p">[</span>
            <span class="n">pdarray</span><span class="p">,</span>
            <span class="n">Strings</span><span class="p">,</span>
            <span class="n">SegArray</span><span class="p">,</span>
            <span class="n">Categorical</span><span class="p">,</span>
            <span class="n">DataFrame</span><span class="p">,</span>
            <span class="n">IPv4</span><span class="p">,</span>
            <span class="n">Datetime</span><span class="p">,</span>
            <span class="n">Timedelta</span><span class="p">,</span>
            <span class="n">Index</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read Arkouda objects from HDF5 file/s.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames : str, List[str]</span>
<span class="sd">        Filename/s to read objects from</span>
<span class="sd">    datasets : Optional str, List[str]</span>
<span class="sd">        datasets to read from the provided files</span>
<span class="sd">    iterative : bool</span>
<span class="sd">        Iterative (True) or Single (False) function call(s) to server</span>
<span class="sd">    strict_types: bool</span>
<span class="sd">        If True (default), require all dtypes of a given dataset to have the</span>
<span class="sd">        same precision and sign. If False, allow dtypes of different</span>
<span class="sd">        precision and sign across different files. For example, if one</span>
<span class="sd">        file contains a uint32 dataset and another contains an int64</span>
<span class="sd">        dataset with the same name, the contents of both will be read</span>
<span class="sd">        into an int64 pdarray.</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default False, if True will allow files with read errors to be skipped</span>
<span class="sd">        instead of failing.  A warning will be included in the return containing</span>
<span class="sd">        the total number of files skipped due to failure and up to 10 filenames.</span>
<span class="sd">    calc_string_offsets: bool</span>
<span class="sd">        Default False, if True this will tell the server to calculate the</span>
<span class="sd">        offsets/segments array on the server versus loading them from HDF5 files.</span>
<span class="sd">        In the future this option may be set to True as the default.</span>
<span class="sd">    tag_data: bool</span>
<span class="sd">        Default False, if True tag the data with the code associated with the filename</span>
<span class="sd">        that the data was pulled from.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Returns a dictionary of Arkouda pdarrays, Arkouda Strings, or Arkouda Segarrays.</span>
<span class="sd">        Dictionary of {datasetName: pdarray, String, SegArray}</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if all datasets are not present in all hdf5 files or if one or</span>
<span class="sd">        more of the specified files do not exist</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if one or more of the specified files cannot be opened.</span>
<span class="sd">        If `allow_errors` is true this may be raised if no values are returned</span>
<span class="sd">        from the server.</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if we receive an unknown arkouda_type returned from the server</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If filenames is a string, it is interpreted as a shell expression</span>
<span class="sd">    (a single filename is a valid expression, so it will work) and is</span>
<span class="sd">    expanded with glob to read all matching files.</span>

<span class="sd">    If iterative == True each dataset name and file names are passed to</span>
<span class="sd">    the server as independent sequential strings while if iterative == False</span>
<span class="sd">    all dataset names and file names are passed to the server in a single</span>
<span class="sd">    string.</span>

<span class="sd">    If datasets is None, infer the names of datasets from the first file</span>
<span class="sd">    and read all of them. Use ``get_datasets`` to show the names of datasets</span>
<span class="sd">    to HDF5 files.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    read_tagged_data</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    # Read with file Extension</span>
<span class="sd">    &gt;&gt;&gt; x = ak.read_hdf(&#39;path/name_prefix.h5&#39;) # load HDF5</span>
<span class="sd">    # Read Glob Expression</span>
<span class="sd">    &gt;&gt;&gt; x = ak.read_hdf(&#39;path/name_prefix*&#39;) # Reads HDF5</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="n">_prep_datasets</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">iterative</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tag_data</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot tag data with iterative read.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">dset</span><span class="p">:</span> <span class="n">read_hdf</span><span class="p">(</span>
                <span class="n">filenames</span><span class="p">,</span>
                <span class="n">datasets</span><span class="o">=</span><span class="n">dset</span><span class="p">,</span>
                <span class="n">strict_types</span><span class="o">=</span><span class="n">strict_types</span><span class="p">,</span>
                <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span><span class="p">,</span>
                <span class="n">calc_string_offsets</span><span class="o">=</span><span class="n">calc_string_offsets</span><span class="p">,</span>
                <span class="n">tag_data</span><span class="o">=</span><span class="n">tag_data</span><span class="p">,</span>
            <span class="p">)[</span><span class="n">dset</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">datasets</span>
        <span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rep_msg</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span>
            <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;readAllHdf&quot;</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;strict_types&quot;</span><span class="p">:</span> <span class="n">strict_types</span><span class="p">,</span>
                <span class="s2">&quot;dset_size&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">),</span>
                <span class="s2">&quot;filename_size&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">),</span>
                <span class="s2">&quot;allow_errors&quot;</span><span class="p">:</span> <span class="n">allow_errors</span><span class="p">,</span>
                <span class="s2">&quot;calc_string_offsets&quot;</span><span class="p">:</span> <span class="n">calc_string_offsets</span><span class="p">,</span>
                <span class="s2">&quot;dsets&quot;</span><span class="p">:</span> <span class="n">datasets</span><span class="p">,</span>
                <span class="s2">&quot;filenames&quot;</span><span class="p">:</span> <span class="n">filenames</span><span class="p">,</span>
                <span class="s2">&quot;tag_data&quot;</span><span class="p">:</span> <span class="n">tag_data</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">)</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">)</span>  <span class="c1"># See GenSymIO._buildReadAllMsgJson for json structure</span>
        <span class="n">_parse_errors</span><span class="p">(</span><span class="n">rep</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_build_objects</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span></div>



<div class="viewcode-block" id="read_parquet">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.read_parquet">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">read_parquet</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iterative</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">strict_types</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">tag_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">read_nested</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">has_non_float_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">fixed_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Mapping</span><span class="p">[</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">Union</span><span class="p">[</span>
            <span class="n">pdarray</span><span class="p">,</span>
            <span class="n">Strings</span><span class="p">,</span>
            <span class="n">SegArray</span><span class="p">,</span>
            <span class="n">Categorical</span><span class="p">,</span>
            <span class="n">DataFrame</span><span class="p">,</span>
            <span class="n">IPv4</span><span class="p">,</span>
            <span class="n">Datetime</span><span class="p">,</span>
            <span class="n">Timedelta</span><span class="p">,</span>
            <span class="n">Index</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read Arkouda objects from Parquet file/s.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames : str, List[str]</span>
<span class="sd">        Filename/s to read objects from</span>
<span class="sd">    datasets : Optional str, List[str]</span>
<span class="sd">        datasets to read from the provided files</span>
<span class="sd">    iterative : bool</span>
<span class="sd">        Iterative (True) or Single (False) function call(s) to server</span>
<span class="sd">    strict_types: bool</span>
<span class="sd">        If True (default), require all dtypes of a given dataset to have the</span>
<span class="sd">        same precision and sign. If False, allow dtypes of different</span>
<span class="sd">        precision and sign across different files. For example, if one</span>
<span class="sd">        file contains a uint32 dataset and another contains an int64</span>
<span class="sd">        dataset with the same name, the contents of both will be read</span>
<span class="sd">        into an int64 pdarray.</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default False, if True will allow files with read errors to be skipped</span>
<span class="sd">        instead of failing.  A warning will be included in the return containing</span>
<span class="sd">        the total number of files skipped due to failure and up to 10 filenames.</span>
<span class="sd">    tag_data: bool</span>
<span class="sd">        Default False, if True tag the data with the code associated with the filename</span>
<span class="sd">        that the data was pulled from.</span>
<span class="sd">    read_nested: bool</span>
<span class="sd">        Default True, when True, SegArray objects will be read from the file. When False,</span>
<span class="sd">        SegArray (or other nested Parquet columns) will be ignored.</span>
<span class="sd">        If datasets is not None, this will be ignored.</span>
<span class="sd">    has_non_float_nulls: bool</span>
<span class="sd">        Default False. This flag must be set to True to read non-float parquet columns</span>
<span class="sd">        that contain null values.</span>
<span class="sd">    fixed_len: int</span>
<span class="sd">        Default -1. This value can be set for reading Parquet string columns when the</span>
<span class="sd">        length of each string is known at runtime. This can allow for skipping byte</span>
<span class="sd">        calculation, which can have an impact on performance.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Returns a dictionary of Arkouda pdarrays, Arkouda Strings, or Arkouda Segarrays.</span>
<span class="sd">        Dictionary of {datasetName: pdarray, String, or SegArray}</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if all datasets are not present in all parquet files or if one or</span>
<span class="sd">        more of the specified files do not exist</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if one or more of the specified files cannot be opened.</span>
<span class="sd">        If `allow_errors` is true this may be raised if no values are returned</span>
<span class="sd">        from the server.</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if we receive an unknown arkouda_type returned from the server</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If filenames is a string, it is interpreted as a shell expression</span>
<span class="sd">    (a single filename is a valid expression, so it will work) and is</span>
<span class="sd">    expanded with glob to read all matching files.</span>

<span class="sd">    If iterative == True each dataset name and file names are passed to</span>
<span class="sd">    the server as independent sequential strings while if iterative == False</span>
<span class="sd">    all dataset names and file names are passed to the server in a single</span>
<span class="sd">    string.</span>

<span class="sd">    If datasets is None, infer the names of datasets from the first file</span>
<span class="sd">    and read all of them. Use ``get_datasets`` to show the names of datasets</span>
<span class="sd">    to Parquet files.</span>

<span class="sd">    Parquet always recomputes offsets at this time</span>
<span class="sd">    This will need to be updated once parquets workflow is updated</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    read_tagged_data</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    Read without file Extension</span>
<span class="sd">    &gt;&gt;&gt; x = ak.read_parquet(&#39;path/name_prefix.parquet&#39;) # load Parquet</span>
<span class="sd">    Read Glob Expression</span>
<span class="sd">    &gt;&gt;&gt; x = ak.read_parquet(&#39;path/name_prefix*&#39;) # Reads Parquet</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="n">_prep_datasets</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">read_nested</span><span class="o">=</span><span class="n">read_nested</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">iterative</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tag_data</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot tag data with iterative read.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">dset</span><span class="p">:</span> <span class="n">read_parquet</span><span class="p">(</span>
                <span class="n">filenames</span><span class="p">,</span>
                <span class="n">datasets</span><span class="o">=</span><span class="n">dset</span><span class="p">,</span>
                <span class="n">strict_types</span><span class="o">=</span><span class="n">strict_types</span><span class="p">,</span>
                <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span><span class="p">,</span>
                <span class="n">tag_data</span><span class="o">=</span><span class="n">tag_data</span><span class="p">,</span>
                <span class="n">read_nested</span><span class="o">=</span><span class="n">read_nested</span><span class="p">,</span>
                <span class="n">has_non_float_nulls</span><span class="o">=</span><span class="n">has_non_float_nulls</span><span class="p">,</span>
                <span class="n">fixed_len</span><span class="o">=</span><span class="n">fixed_len</span><span class="p">,</span>
            <span class="p">)[</span><span class="n">dset</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">datasets</span>
        <span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rep_msg</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span>
            <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;readAllParquet&quot;</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;strict_types&quot;</span><span class="p">:</span> <span class="n">strict_types</span><span class="p">,</span>
                <span class="s2">&quot;dset_size&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">),</span>
                <span class="s2">&quot;filename_size&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">),</span>
                <span class="s2">&quot;allow_errors&quot;</span><span class="p">:</span> <span class="n">allow_errors</span><span class="p">,</span>
                <span class="s2">&quot;dsets&quot;</span><span class="p">:</span> <span class="n">datasets</span><span class="p">,</span>
                <span class="s2">&quot;filenames&quot;</span><span class="p">:</span> <span class="n">filenames</span><span class="p">,</span>
                <span class="s2">&quot;tag_data&quot;</span><span class="p">:</span> <span class="n">tag_data</span><span class="p">,</span>
                <span class="s2">&quot;has_non_float_nulls&quot;</span><span class="p">:</span> <span class="n">has_non_float_nulls</span><span class="p">,</span>
                <span class="s2">&quot;fixed_len&quot;</span><span class="p">:</span> <span class="n">fixed_len</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">)</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">)</span>  <span class="c1"># See GenSymIO._buildReadAllMsgJson for json structure</span>
        <span class="n">_parse_errors</span><span class="p">(</span><span class="n">rep</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_build_objects</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span></div>



<div class="viewcode-block" id="read_csv">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.read_csv">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">read_csv</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">column_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span>
    <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Mapping</span><span class="p">[</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">Union</span><span class="p">[</span>
            <span class="n">pdarray</span><span class="p">,</span>
            <span class="n">Strings</span><span class="p">,</span>
            <span class="n">SegArray</span><span class="p">,</span>
            <span class="n">Categorical</span><span class="p">,</span>
            <span class="n">DataFrame</span><span class="p">,</span>
            <span class="n">IPv4</span><span class="p">,</span>
            <span class="n">Datetime</span><span class="p">,</span>
            <span class="n">Timedelta</span><span class="p">,</span>
            <span class="n">Index</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read CSV file(s) into Arkouda objects.</span>

<span class="sd">    If more than one dataset is found, the objects</span>
<span class="sd">    will be returned in a dictionary mapping the dataset name to the Arkouda object</span>
<span class="sd">    containing the data. If the file contains the appropriately formatted header, typed</span>
<span class="sd">    data will be returned. Otherwise, all data will be returned as a Strings object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames: str or List[str]</span>
<span class="sd">        The filenames to read data from</span>
<span class="sd">    datasets: str or List[str] (Optional)</span>
<span class="sd">        names of the datasets to read. When `None`, all datasets will be read.</span>
<span class="sd">    column_delim: str</span>
<span class="sd">        The delimiter for column names and data. Defaults to &quot;,&quot;.</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default False, if True will allow files with read errors to be skipped</span>
<span class="sd">        instead of failing.  A warning will be included in the return containing</span>
<span class="sd">        the total number of files skipped due to failure and up to 10 filenames.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Returns a dictionary of Arkouda pdarrays, Arkouda Strings, or Arkouda Segarrays.</span>
<span class="sd">        Dictionary of {datasetName: pdarray, String, or SegArray}</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if all datasets are not present in all parquet files or if one or</span>
<span class="sd">        more of the specified files do not exist</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if one or more of the specified files cannot be opened.</span>
<span class="sd">        If `allow_errors` is true this may be raised if no values are returned</span>
<span class="sd">        from the server.</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if we receive an unknown arkouda_type returned from the server</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_csv</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - CSV format is not currently supported by load/load_all operations</span>
<span class="sd">    - The column delimiter is expected to be the same for column names and data</span>
<span class="sd">    - Be sure that column delimiters are not found within your data.</span>
<span class="sd">    - All CSV files must delimit rows using newline (``\\n``) at this time.</span>
<span class="sd">    - Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing</span>
<span class="sd">      bytes as uint(8).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">datasets</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">datasets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">datasets</span> <span class="o">=</span> <span class="n">get_columns</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="n">col_delim</span><span class="o">=</span><span class="n">column_delim</span><span class="p">,</span> <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span><span class="p">)</span>

    <span class="n">rep_msg</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span>
        <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;readcsv&quot;</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;filenames&quot;</span><span class="p">:</span> <span class="n">filenames</span><span class="p">,</span>
            <span class="s2">&quot;nfiles&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">),</span>
            <span class="s2">&quot;datasets&quot;</span><span class="p">:</span> <span class="n">datasets</span><span class="p">,</span>
            <span class="s2">&quot;num_dsets&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">),</span>
            <span class="s2">&quot;col_delim&quot;</span><span class="p">:</span> <span class="n">column_delim</span><span class="p">,</span>
            <span class="s2">&quot;allow_errors&quot;</span><span class="p">:</span> <span class="n">allow_errors</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">rep</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">)</span>  <span class="c1"># See GenSymIO._buildReadAllMsgJson for json structure</span>
    <span class="n">_parse_errors</span><span class="p">(</span><span class="n">rep</span><span class="p">,</span> <span class="n">allow_errors</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_build_objects</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span></div>



<div class="viewcode-block" id="import_data">
<a class="viewcode-back" href="../../usage/IO.html#arkouda.import_data">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">import_data</span><span class="p">(</span>
    <span class="n">read_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">write_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_obj</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Import data from a file saved by Pandas (HDF5/Parquet).</span>

<span class="sd">    Import data from a file saved by Pandas (HDF5/Parquet) to Arkouda object and/or</span>
<span class="sd">    a file formatted to be read by Arkouda.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    read_path: str</span>
<span class="sd">        path to file where pandas data is stored. This can be glob expression for parquet formats.</span>
<span class="sd">    write_file: str, optional</span>
<span class="sd">        path to file to write arkouda formatted data to. Only write file if provided</span>
<span class="sd">    return_obj: bool, optional</span>
<span class="sd">        Default True. When True return the Arkouda DataFrame object, otherwise return None</span>
<span class="sd">    index: bool, optional</span>
<span class="sd">        Default False. When True, maintain the indexes loaded from the pandas file</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeWarning</span>
<span class="sd">        - Export attempted on Parquet file. Arkouda formatted Parquet files are readable by pandas.</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        - Unsupported file type</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pd.DataFrame</span>
<span class="sd">        When `return_obj=True`</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    pandas.DataFrame.to_parquet, pandas.DataFrame.to_hdf,</span>
<span class="sd">    pandas.DataFrame.read_parquet, pandas.DataFrame.read_hdf,</span>
<span class="sd">    ak.export</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Import can only be performed from hdf5 or parquet files written by pandas.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.dataframe</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataFrame</span>

    <span class="c1"># verify file path</span>
    <span class="n">is_glob</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span>
    <span class="n">file_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">file_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid read_path, </span><span class="si">{</span><span class="n">read_path</span><span class="si">}</span><span class="s2">. No files found.&quot;</span><span class="p">)</span>

    <span class="c1"># access the file type - multiple files valid here because parquet supports glob. Check first listed.</span>
    <span class="n">file</span> <span class="o">=</span> <span class="n">read_path</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_glob</span> <span class="k">else</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">read_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">filetype</span> <span class="o">=</span> <span class="n">get_filetype</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="c1"># Note - in the future if we support more than pandas here, we should verify attributes.</span>
    <span class="k">if</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s2">&quot;HDF5&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_glob</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Pandas HDF5 import supports valid file path only. Only supports the local file system,&quot;</span>
                <span class="s2">&quot; remote URLs and file-like objects are not supported.&quot;</span>
            <span class="p">)</span>
        <span class="n">df_def</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s2">&quot;Parquet&quot;</span><span class="p">:</span>
        <span class="c1"># parquet supports glob input in pandas</span>
        <span class="n">df_def</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;File type not supported. Import is only supported for HDF5 and Parquet file formats.&quot;</span>
        <span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">df_def</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">write_file</span><span class="p">:</span>
        <span class="p">(</span>
            <span class="n">df</span><span class="o">.</span><span class="n">to_hdf</span><span class="p">(</span><span class="n">write_file</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s2">&quot;HDF5&quot;</span>
            <span class="k">else</span> <span class="n">df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">write_file</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">return_obj</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">df</span></div>



<div class="viewcode-block" id="export">
<a class="viewcode-back" href="../../usage/IO.html#arkouda.export">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">export</span><span class="p">(</span>
    <span class="n">read_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ak_data&quot;</span><span class="p">,</span>
    <span class="n">write_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_obj</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">index</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Export data from arkouda to pandas.</span>

<span class="sd">    Export data from Arkouda file (Parquet/HDF5)</span>
<span class="sd">    to Pandas object or file formatted to be readable by Pandas.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    read_path: str</span>
<span class="sd">        path to file where arkouda data is stored.</span>
<span class="sd">    dataset_name: str</span>
<span class="sd">        name to store dataset under</span>
<span class="sd">    index: bool</span>
<span class="sd">        Default False. When True, maintain the indexes loaded from the pandas file</span>
<span class="sd">    write_file: str, optional</span>
<span class="sd">        path to file to write pandas formatted data to. Only write the file if this is set</span>
<span class="sd">    return_obj: bool, optional</span>
<span class="sd">        Default True. When True return the Pandas DataFrame object, otherwise return None</span>


<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        - Unsupported file type</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pd.DataFrame</span>
<span class="sd">        When `return_obj=True`</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    pandas.DataFrame.to_parquet, pandas.DataFrame.to_hdf,</span>
<span class="sd">    pandas.DataFrame.read_parquet, pandas.DataFrame.read_hdf,</span>
<span class="sd">    ak.import_data</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - If Arkouda file is exported for pandas, the format will not change. This mean parquet files</span>
<span class="sd">      will remain parquet and hdf5 will remain hdf5.</span>
<span class="sd">    - Export can only be performed from hdf5 or parquet files written by Arkouda. The result will be</span>
<span class="sd">      the same file type, but formatted to be read by Pandas.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.dataframe</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataFrame</span>

    <span class="c1"># get the filetype</span>
    <span class="n">prefix</span><span class="p">,</span> <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span>
    <span class="n">first_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_LOCALE0000</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">filetype</span> <span class="o">=</span> <span class="n">get_filetype</span><span class="p">(</span><span class="n">first_file</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">filetype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;HDF5&quot;</span><span class="p">,</span> <span class="s2">&quot;Parquet&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;File type not supported. Import is only supported for HDF5 and Parquet file formats.&quot;</span>
        <span class="p">)</span>

    <span class="n">akdf</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">read_path</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="n">filetype</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">akdf</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">(</span><span class="n">retain_index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">write_file</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">filetype</span> <span class="o">==</span> <span class="s2">&quot;HDF5&quot;</span><span class="p">:</span>
            <span class="c1"># write to fixed format as this should be the most efficient</span>
            <span class="n">df</span><span class="o">.</span><span class="n">to_hdf</span><span class="p">(</span><span class="n">write_file</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;fixed&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># we know this is parquet because otherwise we would have errored at the type check</span>
            <span class="n">df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">write_file</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_obj</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">df</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_bulk_write_prep</span><span class="p">(</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
        <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
    <span class="p">],</span>
    <span class="n">names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">convert_categoricals</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">datasetNames</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of names does not match number of columns&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">datasetNames</span> <span class="o">=</span> <span class="n">names</span>

    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># init to avoid undefined errors</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">datasetNames</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">columns</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">List</span><span class="p">[</span><span class="n">pdarray</span><span class="p">],</span> <span class="n">columns</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">datasetNames</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">column</span><span class="p">)</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">))]</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;No data was found.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">convert_categoricals</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">Categorical</span><span class="p">):</span>
                <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">categories</span><span class="p">[</span><span class="n">val</span><span class="o">.</span><span class="n">codes</span><span class="p">]</span>

    <span class="n">col_objtypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">objType</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">datasetNames</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">col_objtypes</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_delete_arkouda_files</span><span class="p">(</span><span class="n">prefix_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Delete files of the pattern prefix_path + LOCALE + &lt;local number&gt;.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    prefix_path : str</span>
<span class="sd">        Directory and filename prefix for files to be deleted</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cast</span><span class="p">(</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">generic_msg</span><span class="p">(</span>
            <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;deleteMatchingFilenames&quot;</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;prefix&quot;</span><span class="p">:</span> <span class="n">prefix_path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span>
            <span class="p">},</span>
        <span class="p">),</span>
    <span class="p">)</span>


<div class="viewcode-block" id="to_parquet">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.to_parquet">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">to_parquet</span><span class="p">(</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
        <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
    <span class="p">],</span>
    <span class="n">prefix_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;truncate&quot;</span><span class="p">,</span>
    <span class="n">compression</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">convert_categoricals</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save multiple named pdarrays to Parquet files.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    columns : dict or list of pdarrays</span>
<span class="sd">        Collection of arrays to save</span>
<span class="sd">    prefix_path : str</span>
<span class="sd">        Directory and filename prefix for output files</span>
<span class="sd">    names : list of str</span>
<span class="sd">        Dataset names for the pdarrays</span>
<span class="sd">    mode : {&#39;truncate&#39; | &#39;append&#39;}</span>
<span class="sd">        By default, truncate (overwrite) the output files if they exist.</span>
<span class="sd">        If &#39;append&#39;, attempt to create new dataset in existing files.</span>
<span class="sd">        &#39;append&#39; is deprecated, please use the multi-column write</span>
<span class="sd">    compression : str (Optional)</span>
<span class="sd">            Default None</span>
<span class="sd">            Provide the compression type to use when writing the file.</span>
<span class="sd">            Supported values: snappy, gzip, brotli, zstd, lz4</span>
<span class="sd">        convert_categoricals: bool</span>
<span class="sd">            Defaults to False</span>
<span class="sd">            Parquet requires all columns to be the same size and Categoricals</span>
<span class="sd">            don&#39;t satisfy that requirement.</span>
<span class="sd">            if set, write the equivalent Strings in place of any Categorical columns.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if (1) the lengths of columns and values differ or (2) the mode</span>
<span class="sd">        is not &#39;truncate&#39; or &#39;append&#39;</span>
<span class="sd">    RuntimeError</span>
<span class="sd">            Raised if a server-side error is thrown saving the pdarray</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_hdf, load, load_all, read</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Creates one file per locale containing that locale&#39;s chunk of each pdarray.</span>
<span class="sd">    If columns is a dictionary, the keys are used as the Parquet column names.</span>
<span class="sd">    Otherwise, if no names are supplied, 0-up integers are used. By default,</span>
<span class="sd">    any existing files at path_prefix will be deleted</span>
<span class="sd">    (regardless of whether they would be overwritten), unless the user</span>
<span class="sd">    specifies the &#39;append&#39; mode, in which case arkouda will attempt to add</span>
<span class="sd">    &lt;columns&gt; as new datasets to existing files. If the wrong number of files</span>
<span class="sd">    is present or dataset names already exist, a RuntimeError is raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    &gt;&gt;&gt; a = ak.arange(25)</span>
<span class="sd">    &gt;&gt;&gt; b = ak.arange(25)</span>

<span class="sd">    Save with mapping defining dataset names</span>
<span class="sd">    &gt;&gt;&gt; ak.to_parquet({&#39;a&#39;: a, &#39;b&#39;: b}, &#39;path/name_prefix&#39;)</span>

<span class="sd">    Save using names instead of mapping</span>
<span class="sd">    &gt;&gt;&gt; ak.to_parquet([a, b], &#39;path/name_prefix&#39;, names=[&#39;a&#39;, &#39;b&#39;])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;append&quot;</span><span class="p">,</span> <span class="s2">&quot;truncate&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Allowed modes are &#39;truncate&#39; and &#39;append&#39;&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;append&quot;</span><span class="p">:</span>
        <span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Append has been deprecated when writing Parquet files. &quot;</span>
            <span class="s2">&quot;Please write all columns to the file at once.&quot;</span><span class="p">,</span>
            <span class="ne">DeprecationWarning</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;truncate&quot;</span><span class="p">:</span>
        <span class="n">_delete_arkouda_files</span><span class="p">(</span><span class="n">prefix_path</span><span class="p">)</span>

    <span class="n">datasetNames</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">col_objtypes</span> <span class="o">=</span> <span class="n">_bulk_write_prep</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">convert_categoricals</span><span class="p">)</span>
    <span class="c1"># append or single column use the old logic</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;append&quot;</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">arr</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cast</span><span class="p">(</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">datasetNames</span><span class="p">)):</span>
            <span class="n">arr</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">prefix_path</span><span class="o">=</span><span class="n">prefix_path</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="n">compression</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="n">cast</span><span class="p">(</span>
                <span class="nb">str</span><span class="p">,</span>
                <span class="n">generic_msg</span><span class="p">(</span>
                    <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;toParquet_multi&quot;</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="p">{</span>
                        <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">,</span>
                        <span class="s2">&quot;col_names&quot;</span><span class="p">:</span> <span class="n">datasetNames</span><span class="p">,</span>
                        <span class="s2">&quot;col_objtypes&quot;</span><span class="p">:</span> <span class="n">col_objtypes</span><span class="p">,</span>
                        <span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">prefix_path</span><span class="p">,</span>
                        <span class="s2">&quot;num_cols&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>
                        <span class="s2">&quot;compression&quot;</span><span class="p">:</span> <span class="n">compression</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="to_hdf">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.to_hdf">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">to_hdf</span><span class="p">(</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
        <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
    <span class="p">],</span>
    <span class="n">prefix_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;truncate&quot;</span><span class="p">,</span>
    <span class="n">file_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;distribute&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save multiple named pdarrays to HDF5 files.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    columns : dict or list of pdarrays</span>
<span class="sd">        Collection of arrays to save</span>
<span class="sd">    prefix_path : str</span>
<span class="sd">        Directory and filename prefix for output files</span>
<span class="sd">    names : list of str</span>
<span class="sd">        Dataset names for the pdarrays</span>
<span class="sd">    mode : {&#39;truncate&#39; | &#39;append&#39;}</span>
<span class="sd">        By default, truncate (overwrite) the output files if they exist.</span>
<span class="sd">        If &#39;append&#39;, attempt to create new dataset in existing files.</span>
<span class="sd">    file_type : str (&quot;single&quot; | &quot;distribute&quot;)</span>
<span class="sd">            Default: distribute</span>
<span class="sd">            Single writes the dataset to a single file</span>
<span class="sd">            Distribute writes the dataset to a file per locale</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if (1) the lengths of columns and values differ or (2) the mode</span>
<span class="sd">        is not &#39;truncate&#39; or &#39;append&#39;</span>
<span class="sd">    RuntimeError</span>
<span class="sd">            Raised if a server-side error is thrown saving the pdarray</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_parquet, load, load_all, read</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Creates one file per locale containing that locale&#39;s chunk of each pdarray.</span>
<span class="sd">    If columns is a dictionary, the keys are used as the HDF5 dataset names.</span>
<span class="sd">    Otherwise, if no names are supplied, 0-up integers are used. By default,</span>
<span class="sd">    any existing files at path_prefix will be overwritten, unless the user</span>
<span class="sd">    specifies the &#39;append&#39; mode, in which case arkouda will attempt to add</span>
<span class="sd">    &lt;columns&gt; as new datasets to existing files. If the wrong number of files</span>
<span class="sd">    is present or dataset names already exist, a RuntimeError is raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    &gt;&gt;&gt; a = ak.arange(25)</span>
<span class="sd">    &gt;&gt;&gt; b = ak.arange(25)</span>

<span class="sd">    Save with mapping defining dataset names</span>
<span class="sd">    &gt;&gt;&gt; ak.to_hdf({&#39;a&#39;: a, &#39;b&#39;: b}, &#39;path/name_prefix&#39;)</span>

<span class="sd">    Save using names instead of mapping</span>
<span class="sd">    &gt;&gt;&gt; ak.to_hdf([a, b], &#39;path/name_prefix&#39;, names=[&#39;a&#39;, &#39;b&#39;])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;append&quot;</span><span class="p">,</span> <span class="s2">&quot;truncate&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Allowed modes are &#39;truncate&#39; and &#39;append&#39;&quot;</span><span class="p">)</span>

    <span class="n">datasetNames</span><span class="p">,</span> <span class="n">pdarrays</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_bulk_write_prep</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">arr</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pdarrays</span><span class="p">,</span> <span class="n">cast</span><span class="p">(</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">datasetNames</span><span class="p">)):</span>
        <span class="n">arr</span><span class="o">.</span><span class="n">to_hdf</span><span class="p">(</span>
            <span class="n">prefix_path</span><span class="o">=</span><span class="n">prefix_path</span><span class="p">,</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">file_type</span><span class="o">=</span><span class="n">file_type</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;truncate&quot;</span><span class="p">:</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;append&quot;</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_get_hdf_filetype</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">filename</span> <span class="ow">and</span> <span class="n">filename</span><span class="o">.</span><span class="n">strip</span><span class="p">()):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;filename cannot be an empty string&quot;</span><span class="p">)</span>

    <span class="n">cmd</span> <span class="o">=</span> <span class="s2">&quot;hdffileformat&quot;</span>
    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">generic_msg</span><span class="p">(</span>
            <span class="n">cmd</span><span class="o">=</span><span class="n">cmd</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">filename</span><span class="p">},</span>
        <span class="p">),</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_repack_hdf</span><span class="p">(</span><span class="n">prefix_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Overwrite the existing hdf5 file with a copy that removes any inaccessible datasets.&quot;&quot;&quot;</span>
    <span class="n">file_type</span> <span class="o">=</span> <span class="n">_get_hdf_filetype</span><span class="p">(</span><span class="n">prefix_path</span> <span class="o">+</span> <span class="s2">&quot;*&quot;</span><span class="p">)</span>
    <span class="n">dset_list</span> <span class="o">=</span> <span class="n">ls</span><span class="p">(</span><span class="n">prefix_path</span> <span class="o">+</span> <span class="s2">&quot;*&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dset_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># early out because when overwriting only one value, hdf5 automatically releases memory</span>
        <span class="k">return</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">read_hdf</span><span class="p">(</span><span class="n">prefix_path</span> <span class="o">+</span> <span class="s2">&quot;*&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># handles the case of reading only 1 dataset</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">]</span>  <span class="c1"># type: ignore</span>
    <span class="n">to_hdf</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">prefix_path</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">dset_list</span><span class="p">,</span> <span class="n">file_type</span><span class="o">=</span><span class="n">file_type</span><span class="p">)</span>  <span class="c1"># type: ignore</span>


<div class="viewcode-block" id="update_hdf">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.update_hdf">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">update_hdf</span><span class="p">(</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
        <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">]],</span>
    <span class="p">],</span>
    <span class="n">prefix_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">repack</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overwrite the datasets with name appearing in names or keys in columns if columns is a dictionary.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    columns : dict or list of pdarrays</span>
<span class="sd">        Collection of arrays to save</span>
<span class="sd">    prefix_path : str</span>
<span class="sd">        Directory and filename prefix for output files</span>
<span class="sd">    names : list of str</span>
<span class="sd">        Dataset names for the pdarrays</span>
<span class="sd">    repack: bool</span>
<span class="sd">        Default: True</span>
<span class="sd">        HDF5 does not release memory on delete. When True, the inaccessible</span>
<span class="sd">        data (that was overwritten) is removed. When False, the data remains, but is</span>
<span class="sd">        inaccessible. Setting to false will yield better performance, but will cause</span>
<span class="sd">        file sizes to expand.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if a server-side error is thrown saving the datasets</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - If file does not contain File_Format attribute to indicate how it was saved,</span>
<span class="sd">      the file name is checked for _LOCALE#### to determine if it is distributed.</span>
<span class="sd">    - If the datasets provided do not exist, they will be added</span>
<span class="sd">    - Because HDF5 deletes do not release memory, this will create a copy of the</span>
<span class="sd">      file with the new data</span>
<span class="sd">    - This workflow is slightly different from `to_hdf` to prevent reading and</span>
<span class="sd">      creating a copy of the file for each dataset</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">datasetNames</span><span class="p">,</span> <span class="n">pdarrays</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_bulk_write_prep</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">arr</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pdarrays</span><span class="p">,</span> <span class="n">cast</span><span class="p">(</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">datasetNames</span><span class="p">)):</span>
        <span class="c1"># overwrite the data without repacking. Repack done once at end if set</span>
        <span class="n">arr</span><span class="o">.</span><span class="n">update_hdf</span><span class="p">(</span><span class="n">prefix_path</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">repack</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">repack</span><span class="p">:</span>
        <span class="n">_repack_hdf</span><span class="p">(</span><span class="n">prefix_path</span><span class="p">)</span></div>



<div class="viewcode-block" id="to_csv">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.to_csv">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">to_csv</span><span class="p">(</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">]]],</span>
    <span class="n">prefix_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">col_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Write Arkouda object(s) to CSV file(s).</span>

<span class="sd">    All CSV Files written by Arkouda</span>
<span class="sd">    include a header denoting data types of the columns.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    columns: Mapping[str, pdarray] or List[pdarray]</span>
<span class="sd">        The objects to be written to CSV file. If a mapping is used and `names` is None</span>
<span class="sd">        the keys of the mapping will be used as the dataset names.</span>
<span class="sd">    prefix_path: str</span>
<span class="sd">        The filename prefix to be used for saving files. Files will have _LOCALE#### appended</span>
<span class="sd">        when they are written to disk.</span>
<span class="sd">    names: List[str] (Optional)</span>
<span class="sd">        names of dataset to be written. Order should correspond to the order of data</span>
<span class="sd">        provided in `columns`.</span>
<span class="sd">    col_delim: str</span>
<span class="sd">        Defaults to &quot;,&quot;. Value to be used to separate columns within the file.</span>
<span class="sd">        Please be sure that the value used DOES NOT appear in your dataset.</span>
<span class="sd">    overwrite: bool</span>
<span class="sd">        Defaults to False. If True, any existing files matching your provided prefix_path will</span>
<span class="sd">        be overwritten. If False, an error will be returned if existing files are found.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if any datasets are present in all csv files or if one or</span>
<span class="sd">        more of the specified files do not exist</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if one or more of the specified files cannot be opened.</span>
<span class="sd">        If `allow_errors` is true this may be raised if no values are returned</span>
<span class="sd">        from the server.</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if we receive an unknown arkouda_type returned from the server</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    read_csv</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - CSV format is not currently supported by load/load_all operations</span>
<span class="sd">    - The column delimiter is expected to be the same for column names and data</span>
<span class="sd">    - Be sure that column delimiters are not found within your data.</span>
<span class="sd">    - All CSV files must delimit rows using newline (``\\n``) at this time.</span>
<span class="sd">    - Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing</span>
<span class="sd">      bytes as uint(8).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">datasetNames</span><span class="p">,</span> <span class="n">pdarrays</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_bulk_write_prep</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
    <span class="n">dtypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pdarrays</span><span class="p">]</span>

    <span class="n">generic_msg</span><span class="p">(</span>
        <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;writecsv&quot;</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;datasets&quot;</span><span class="p">:</span> <span class="n">pdarrays</span><span class="p">,</span>
            <span class="s2">&quot;col_names&quot;</span><span class="p">:</span> <span class="n">datasetNames</span><span class="p">,</span>
            <span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">prefix_path</span><span class="p">,</span>
            <span class="s2">&quot;num_dsets&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">pdarrays</span><span class="p">),</span>
            <span class="s2">&quot;col_delim&quot;</span><span class="p">:</span> <span class="n">col_delim</span><span class="p">,</span>
            <span class="s2">&quot;dtypes&quot;</span><span class="p">:</span> <span class="n">dtypes</span><span class="p">,</span>
            <span class="s2">&quot;row_count&quot;</span><span class="p">:</span> <span class="n">pdarrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>  <span class="c1"># all columns should have equal number of entries</span>
            <span class="s2">&quot;overwrite&quot;</span><span class="p">:</span> <span class="n">overwrite</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="to_zarr">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.to_zarr">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">to_zarr</span><span class="p">(</span><span class="n">store_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">arr</span><span class="p">:</span> <span class="n">pdarray</span><span class="p">,</span> <span class="n">chunk_shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Write a pdarray to disk as a Zarr store.</span>

<span class="sd">    Supports multi-dimensional pdarrays of numeric types.</span>
<span class="sd">    To use this function, ensure you have installed the blosc dependency (`make install-blosc`)</span>
<span class="sd">    and have included `ZarrMsg.chpl` in the `ServerModules.cfg` file.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    store_path : str</span>
<span class="sd">        The path at which Zarr store should be written</span>
<span class="sd">    arr : pdarray</span>
<span class="sd">        The pdarray to be written to disk</span>
<span class="sd">    chunk_shape : tuple</span>
<span class="sd">        The shape of the chunks to be used in the Zarr store</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if the number of dimensions in the chunk shape does not match</span>
<span class="sd">        the number of dimensions in the array or if the array is not a 32 or 64 bit numeric type</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk_shape</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The number of dimensions in the chunk shape must match the </span><span class="se">\</span>
<span class="s2">                          number of dimensions in the array&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">int64</span><span class="p">,</span> <span class="n">int32</span><span class="p">,</span> <span class="n">float64</span><span class="p">,</span> <span class="n">float32</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only pdarrays of 64 and 32 bit numeric types are supported&quot;</span><span class="p">)</span>

    <span class="n">generic_msg</span><span class="p">(</span>
        <span class="n">cmd</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;writeAllZarr&lt;</span><span class="si">{</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">ndim</span><span class="si">}</span><span class="s2">&gt;&quot;</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;store_path&quot;</span><span class="p">:</span> <span class="n">store_path</span><span class="p">,</span> <span class="s2">&quot;arr&quot;</span><span class="p">:</span> <span class="n">arr</span><span class="p">,</span> <span class="s2">&quot;chunk_shape&quot;</span><span class="p">:</span> <span class="n">chunk_shape</span><span class="p">},</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="read_zarr">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.read_zarr">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">read_zarr</span><span class="p">(</span><span class="n">store_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read a Zarr store from disk into a pdarray.</span>

<span class="sd">    Supports multi-dimensional pdarrays of numeric types.</span>
<span class="sd">    To use this function, ensure you have installed the blosc dependency (`make install-blosc`)</span>
<span class="sd">    and have included `ZarrMsg.chpl` in the `ServerModules.cfg` file.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    store_path : str</span>
<span class="sd">        The path to the Zarr store. The path must be to a directory that contains a `.zarray`</span>
<span class="sd">        file containing the Zarr store metadata.</span>
<span class="sd">    ndim : int</span>
<span class="sd">        The number of dimensions in the array</span>
<span class="sd">    dtype : str</span>
<span class="sd">        The data type of the array</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pdarray</span>
<span class="sd">        The pdarray read from the Zarr store.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rep_msg</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span><span class="n">cmd</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;readAllZarr&lt;</span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">ndim</span><span class="si">}</span><span class="s2">&gt;&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;store_path&quot;</span><span class="p">:</span> <span class="n">store_path</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">create_pdarray</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">)</span></div>



<div class="viewcode-block" id="load">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.load">[docs]</a>
<span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span>
    <span class="n">path_prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">file_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;INFER&quot;</span><span class="p">,</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;array&quot;</span><span class="p">,</span>
    <span class="n">calc_string_offsets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">column_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Mapping</span><span class="p">[</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">Union</span><span class="p">[</span>
            <span class="n">pdarray</span><span class="p">,</span>
            <span class="n">Strings</span><span class="p">,</span>
            <span class="n">SegArray</span><span class="p">,</span>
            <span class="n">Categorical</span><span class="p">,</span>
            <span class="n">DataFrame</span><span class="p">,</span>
            <span class="n">IPv4</span><span class="p">,</span>
            <span class="n">Datetime</span><span class="p">,</span>
            <span class="n">Timedelta</span><span class="p">,</span>
            <span class="n">Index</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a pdarray previously saved with ``pdarray.save()``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    path_prefix : str</span>
<span class="sd">        Filename prefix used to save the original pdarray</span>
<span class="sd">    file_format : str</span>
<span class="sd">        &#39;INFER&#39;, &#39;HDF5&#39; or &#39;Parquet&#39;. Defaults to &#39;INFER&#39;. Used to indicate the file type being loaded.</span>
<span class="sd">        If INFER, this will be detected during processing</span>
<span class="sd">    dataset : str</span>
<span class="sd">        Dataset name where the pdarray was saved, defaults to &#39;array&#39;</span>
<span class="sd">    calc_string_offsets : bool</span>
<span class="sd">        If True the server will ignore Segmented Strings &#39;offsets&#39; array and derive</span>
<span class="sd">        it from the null-byte terminators.  Defaults to False currently</span>
<span class="sd">    column_delim : str</span>
<span class="sd">        Column delimiter to be used if dataset is CSV. Otherwise, unused.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Mapping[str, Union[pdarray, Strings, SegArray, Categorical]]</span>
<span class="sd">        Dictionary of {datsetName: Union[pdarray, Strings, SegArray, Categorical]}</span>
<span class="sd">        with the previously saved pdarrays, Strings, SegArrays, or Categoricals</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if either path_prefix or dataset is not a str</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if invalid file_format or if the dataset is not present in all hdf5 files or if the</span>
<span class="sd">        path_prefix does not correspond to files accessible to Arkouda</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if the hdf5 files are present but there is an error in opening</span>
<span class="sd">        one or more of them</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_parquet, to_hdf, load_all, read</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If you have a previously saved Parquet file that is raising a FileNotFound error, try loading it</span>
<span class="sd">    with a .parquet appended to the prefix_path.</span>
<span class="sd">    Parquet files were previously ALWAYS stored with a ``.parquet`` extension.</span>

<span class="sd">    ak.load does not support loading a single file.</span>
<span class="sd">    For loading single HDF5 files without the _LOCALE#### suffix please use ak.read().</span>

<span class="sd">    CSV files without the Arkouda Header are not supported.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    Loading from file without extension</span>
<span class="sd">    &gt;&gt;&gt; obj = ak.load(&#39;path/prefix&#39;)</span>
<span class="sd">    Loads the array from numLocales files with the name ``cwd/path/name_prefix_LOCALE####``.</span>
<span class="sd">    The file type is inferred during processing.</span>

<span class="sd">    Loading with an extension (HDF5)</span>
<span class="sd">    &gt;&gt;&gt; obj = ak.load(&#39;path/prefix.test&#39;)</span>
<span class="sd">    Loads the object from numLocales files with the name ``cwd/path/name_prefix_LOCALE####.test`` where</span>
<span class="sd">    #### is replaced by each locale numbers. Because filetype is inferred during processing,</span>
<span class="sd">    the extension is not required to be a specific format.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s2">&quot;*&quot;</span> <span class="ow">in</span> <span class="n">path_prefix</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Glob expressions not supported by ak.load(). &quot;</span>
            <span class="s2">&quot;To read files using a glob expression, please use ak.read()&quot;</span>
        <span class="p">)</span>
    <span class="n">prefix</span><span class="p">,</span> <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">path_prefix</span><span class="p">)</span>
    <span class="n">globstr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_LOCALE*</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">file_format</span> <span class="o">=</span> <span class="n">get_filetype</span><span class="p">(</span><span class="n">globstr</span><span class="p">)</span> <span class="k">if</span> <span class="n">file_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;infer&quot;</span> <span class="k">else</span> <span class="n">file_format</span>
        <span class="k">if</span> <span class="n">file_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;hdf5&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">read_hdf</span><span class="p">(</span><span class="n">globstr</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">calc_string_offsets</span><span class="o">=</span><span class="n">calc_string_offsets</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">file_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;parquet&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">read_parquet</span><span class="p">(</span><span class="n">globstr</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">read_csv</span><span class="p">(</span><span class="n">globstr</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">column_delim</span><span class="o">=</span><span class="n">column_delim</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">re</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;does not exist&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">re</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;There are no files corresponding to the path_prefix </span><span class="si">{</span><span class="n">path_prefix</span><span class="si">}</span><span class="s2"> in&quot;</span>
                <span class="s2">&quot; a location accessible to Arkouda&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">re</span><span class="p">)</span></div>



<div class="viewcode-block" id="load_all">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.load_all">[docs]</a>
<span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_all</span><span class="p">(</span>
    <span class="n">path_prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">file_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;INFER&quot;</span><span class="p">,</span>
    <span class="n">column_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span>
    <span class="n">read_nested</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">,</span> <span class="n">Categorical</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load multiple pdarrays, Strings, SegArrays, or Categoricals previously saved with ``save_all()``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    path_prefix : str</span>
<span class="sd">        Filename prefix used to save the original pdarray</span>
<span class="sd">    file_format: str</span>
<span class="sd">        &#39;INFER&#39;, &#39;HDF5&#39;, &#39;Parquet&#39;, or &#39;CSV&#39;. Defaults to &#39;INFER&#39;. Indicates the format being loaded.</span>
<span class="sd">        When &#39;INFER&#39; the processing will detect the format</span>
<span class="sd">        Defaults to &#39;INFER&#39;</span>
<span class="sd">    column_delim : str</span>
<span class="sd">        Column delimiter to be used if dataset is CSV. Otherwise, unused.</span>
<span class="sd">    read_nested: bool</span>
<span class="sd">        Default True, when True, SegArray objects will be read from the file. When False,</span>
<span class="sd">        SegArray (or other nested Parquet columns) will be ignored.</span>
<span class="sd">        Parquet files only</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Mapping[str, Union[pdarray, Strings, SegArray, Categorical]]</span>
<span class="sd">        Dictionary of {datsetName: Union[pdarray, Strings, SegArray, Categorical]}</span>
<span class="sd">        with the previously saved pdarrays, Strings, SegArrays, or Categoricals</span>


<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if path_prefix is not a str</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if file_format/extension is encountered that is not hdf5 or parquet or</span>
<span class="sd">        if all datasets are not present in all hdf5/parquet files or if the</span>
<span class="sd">        path_prefix does not correspond to files accessible to Arkouda</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        Raised if the hdf5 files are present but there is an error in opening</span>
<span class="sd">        one or more of them</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_parquet, to_hdf, load, read</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function has been updated to determine the file extension based on the file format variable</span>

<span class="sd">    This function will be deprecated when glob flags are added to read_* methods</span>

<span class="sd">    CSV files without the Arkouda Header are not supported.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prefix</span><span class="p">,</span> <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">path_prefix</span><span class="p">)</span>
    <span class="n">firstname</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_LOCALE0000</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">firstname</span><span class="p">,</span> <span class="n">column_delim</span><span class="o">=</span><span class="n">column_delim</span><span class="p">,</span> <span class="n">read_nested</span><span class="o">=</span><span class="n">read_nested</span><span class="p">):</span>
            <span class="n">result</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="n">file_format</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">)[</span><span class="n">dataset</span><span class="p">]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">_dict_recombine_segarrays_categoricals</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="c1"># Check for Categoricals and remove if necessary</span>
        <span class="n">removal_names</span><span class="p">,</span> <span class="n">categoricals</span> <span class="o">=</span> <span class="n">Categorical</span><span class="o">.</span><span class="n">_parse_hdf_categoricals</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">removal_names</span><span class="p">:</span>
            <span class="n">result</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">categoricals</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">removal_names</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">re</span><span class="p">:</span>
        <span class="c1"># enables backwards compatibility with previous naming convention</span>
        <span class="k">if</span> <span class="s2">&quot;does not exist&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">re</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">firstname</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_LOCALE0</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">return</span> <span class="p">{</span><span class="n">dataset</span><span class="p">:</span> <span class="n">load</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">firstname</span><span class="p">)}</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">re</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;does not exist&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">re</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;There are no files corresponding to the path_prefix </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> and &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;file_format </span><span class="si">{</span><span class="n">file_format</span><span class="si">}</span><span class="s2"> in location accessible to Arkouda&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">re</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not open one or more files with path_prefix </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;file_format </span><span class="si">{</span><span class="n">file_format</span><span class="si">}</span><span class="s2"> in location accessible to Arkouda&quot;</span>
            <span class="p">)</span></div>



<div class="viewcode-block" id="read">
<a class="viewcode-back" href="../../usage/IO.html#arkouda.read">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">read</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iterative</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">strictTypes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">calc_string_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">column_delim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span>
    <span class="n">read_nested</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">has_non_float_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">fixed_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Mapping</span><span class="p">[</span>
        <span class="nb">str</span><span class="p">,</span>
        <span class="n">Union</span><span class="p">[</span>
            <span class="n">pdarray</span><span class="p">,</span>
            <span class="n">Strings</span><span class="p">,</span>
            <span class="n">SegArray</span><span class="p">,</span>
            <span class="n">Categorical</span><span class="p">,</span>
            <span class="n">DataFrame</span><span class="p">,</span>
            <span class="n">IPv4</span><span class="p">,</span>
            <span class="n">Datetime</span><span class="p">,</span>
            <span class="n">Timedelta</span><span class="p">,</span>
            <span class="n">Index</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read datasets from files.</span>

<span class="sd">    File Type is determined automatically.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames : list or str</span>
<span class="sd">        Either a list of filenames or shell expression</span>
<span class="sd">    datasets : list or str or None</span>
<span class="sd">        (List of) name(s) of dataset(s) to read (default: all available)</span>
<span class="sd">    iterative : bool</span>
<span class="sd">        Iterative (True) or Single (False) function call(s) to server</span>
<span class="sd">    strictTypes: bool</span>
<span class="sd">        If True (default), require all dtypes of a given dataset to have the</span>
<span class="sd">        same precision and sign. If False, allow dtypes of different</span>
<span class="sd">        precision and sign across different files. For example, if one</span>
<span class="sd">        file contains a uint32 dataset and another contains an int64</span>
<span class="sd">        dataset with the same name, the contents of both will be read</span>
<span class="sd">        into an int64 pdarray.</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default False, if True will allow files with read errors to be skipped</span>
<span class="sd">        instead of failing.  A warning will be included in the return containing</span>
<span class="sd">        the total number of files skipped due to failure and up to 10 filenames.</span>
<span class="sd">    calc_string_offsets: bool</span>
<span class="sd">        Default False, if True this will tell the server to calculate the</span>
<span class="sd">        offsets/segments array on the server versus loading them from HDF5 files.</span>
<span class="sd">        In the future this option may be set to True as the default.</span>
<span class="sd">    column_delim : str</span>
<span class="sd">        Column delimiter to be used if dataset is CSV. Otherwise, unused.</span>
<span class="sd">    read_nested: bool</span>
<span class="sd">        Default True, when True, SegArray objects will be read from the file. When False,</span>
<span class="sd">        SegArray (or other nested Parquet columns) will be ignored.</span>
<span class="sd">        Ignored if datasets is not None</span>
<span class="sd">        Parquet Files only.</span>
<span class="sd">    has_non_float_nulls: bool</span>
<span class="sd">        Default False. This flag must be set to True to read non-float parquet columns</span>
<span class="sd">        that contain null values.</span>
<span class="sd">    fixed_len: int</span>
<span class="sd">        Default -1. This value can be set for reading Parquet string columns when the</span>
<span class="sd">        length of each string is known at runtime. This can allow for skipping byte</span>
<span class="sd">        calculation, which can have an impact on performance.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Returns a dictionary of Arkouda pdarrays, Arkouda Strings, or Arkouda Segarrays.</span>
<span class="sd">        Dictionary of {datasetName: pdarray, String, or SegArray}</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        If invalid filetype is detected</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    get_datasets, ls, read_parquet, read_hdf</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If filenames is a string, it is interpreted as a shell expression</span>
<span class="sd">    (a single filename is a valid expression, so it will work) and is</span>
<span class="sd">    expanded with glob to read all matching files.</span>

<span class="sd">    If iterative == True each dataset name and file names are passed to</span>
<span class="sd">    the server as independent sequential strings while if iterative == False</span>
<span class="sd">    all dataset names and file names are passed to the server in a single</span>
<span class="sd">    string.</span>

<span class="sd">    If datasets is None, infer the names of datasets from the first file</span>
<span class="sd">    and read all of them. Use ``get_datasets`` to show the names of datasets</span>
<span class="sd">    to HDF5/Parquet files.</span>

<span class="sd">    CSV files without the Arkouda Header are not supported.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    Read with file Extension</span>
<span class="sd">    &gt;&gt;&gt; x = ak.read(&#39;path/name_prefix.h5&#39;) # load HDF5 - processing determines file type not extension</span>
<span class="sd">    Read without file Extension</span>
<span class="sd">    &gt;&gt;&gt; x = ak.read(&#39;path/name_prefix.parquet&#39;) # load Parquet</span>
<span class="sd">    Read Glob Expression</span>
<span class="sd">    &gt;&gt;&gt; x = ak.read(&#39;path/name_prefix*&#39;) # Reads HDF5</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>

    <span class="n">ftype</span> <span class="o">=</span> <span class="n">get_filetype</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ftype</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;hdf5&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">read_hdf</span><span class="p">(</span>
            <span class="n">filenames</span><span class="p">,</span>
            <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
            <span class="n">iterative</span><span class="o">=</span><span class="n">iterative</span><span class="p">,</span>
            <span class="n">strict_types</span><span class="o">=</span><span class="n">strictTypes</span><span class="p">,</span>
            <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span><span class="p">,</span>
            <span class="n">calc_string_offsets</span><span class="o">=</span><span class="n">calc_string_offsets</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">ftype</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;parquet&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">read_parquet</span><span class="p">(</span>
            <span class="n">filenames</span><span class="p">,</span>
            <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
            <span class="n">iterative</span><span class="o">=</span><span class="n">iterative</span><span class="p">,</span>
            <span class="n">strict_types</span><span class="o">=</span><span class="n">strictTypes</span><span class="p">,</span>
            <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span><span class="p">,</span>
            <span class="n">read_nested</span><span class="o">=</span><span class="n">read_nested</span><span class="p">,</span>
            <span class="n">has_non_float_nulls</span><span class="o">=</span><span class="n">has_non_float_nulls</span><span class="p">,</span>
            <span class="n">fixed_len</span><span class="o">=</span><span class="n">fixed_len</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">ftype</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;csv&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">read_csv</span><span class="p">(</span>
            <span class="n">filenames</span><span class="p">,</span> <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span> <span class="n">column_delim</span><span class="o">=</span><span class="n">column_delim</span><span class="p">,</span> <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid File Type detected, </span><span class="si">{</span><span class="n">ftype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="save_checkpoint">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.save_checkpoint">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;.akdata&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;overwrite&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save the server&#39;s state.</span>

<span class="sd">    Records some metadata about the server, and saves</span>
<span class="sd">    all pdarrays into parquet files.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name: str</span>
<span class="sd">        Name of the checkpoint. The default will be the server session ID, which</span>
<span class="sd">        is typically in format ``id_&lt;hash&gt;_``. A directory will be created in</span>
<span class="sd">        ``path`` with this name.</span>
<span class="sd">    path: str</span>
<span class="sd">        The directory to save the checkpoint. If the directory doesn&#39;t exist, it</span>
<span class="sd">        will be created. If it exists, a new directory for the checkpoint</span>
<span class="sd">        instance will be created inside this directory.</span>
<span class="sd">    mode : {&#39;overwrite&#39; | &#39;preserve_previous&#39; | &#39;error&#39;}</span>
<span class="sd">        By default, overwrite the checkpoint files if they exist.</span>
<span class="sd">        If &#39;preserve_previous&#39;, an existing checkpoint with &#39;name&#39; will be</span>
<span class="sd">        renamed to &#39;name.prev&#39;, overwriting &#39;name.prev&#39; if it existed,</span>
<span class="sd">        before creating a new checkpoint with &#39;name&#39;.</span>
<span class="sd">        If &#39;error&#39;, an error will be raised if a checkpoint with the same name</span>
<span class="sd">        exists.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Only ``pdarray``s are saved. Other data structures will not be recorded. We</span>
<span class="sd">    expect to expand the coverage in the future.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    str</span>
<span class="sd">        The checkpoint name, which will be the same as the ``name`` argument if</span>
<span class="sd">        it was passed.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    &gt;&gt;&gt; arr = ak.zeros(10, int)</span>
<span class="sd">    &gt;&gt;&gt; arr[2] = 2</span>
<span class="sd">    &gt;&gt;&gt; arr[2]</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; cp_name = ak.save_checkpoint()</span>
<span class="sd">    &gt;&gt;&gt; arr[2] = 3</span>
<span class="sd">    &gt;&gt;&gt; arr[2]</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; ak.load_checkpoint(cp_name)</span>
<span class="sd">    &gt;&gt;&gt; arr[2]</span>
<span class="sd">    2</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    load_checkpoint</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;mode can be &#39;overwrite&#39; or &#39;error&#39; not </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">generic_msg</span><span class="p">(</span><span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;save_checkpoint&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="n">path</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="n">mode</span><span class="p">}))</span></div>



<div class="viewcode-block" id="load_checkpoint">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.load_checkpoint">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;.akdata&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load server&#39;s state.</span>

<span class="sd">    The server metadata must match the current</span>
<span class="sd">    configuration (e.g. same number of locales must be used).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name: str</span>
<span class="sd">        Name of the checkpoint. ``&lt;path&gt;/&lt;name&gt;`` must be a directory.</span>
<span class="sd">    path: str</span>
<span class="sd">        The directory to save the checkpoint.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    str</span>
<span class="sd">        The checkpoint name, which will be the same as the ``name`` argument.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    &gt;&gt;&gt; arr = ak.zeros(10, int)</span>
<span class="sd">    &gt;&gt;&gt; arr[2] = 2</span>
<span class="sd">    &gt;&gt;&gt; arr[2]</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; cp_name = ak.save_checkpoint()</span>
<span class="sd">    &gt;&gt;&gt; arr[2] = 3</span>
<span class="sd">    &gt;&gt;&gt; arr[2]</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; ak.load_checkpoint(cp_name)</span>
<span class="sd">    &gt;&gt;&gt; arr[2]</span>
<span class="sd">    2</span>


<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    save_checkpoint</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Right now, we don&#39;t need to build objects on the client side.</span>
    <span class="c1"># Checkpointing is only for the server state. But if we do, we&#39;ll need to</span>
    <span class="c1"># return objects from the server and build them:</span>
    <span class="c1">#</span>
    <span class="c1"># rep = json.loads(rep_msg)</span>
    <span class="c1"># ret = _build_objects(rep)</span>
    <span class="k">return</span> <span class="n">generic_msg</span><span class="p">(</span><span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;load_checkpoint&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="n">path</span><span class="p">})</span></div>



<div class="viewcode-block" id="read_tagged_data">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.read_tagged_data">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">read_tagged_data</span><span class="p">(</span>
    <span class="n">filenames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">strictTypes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">allow_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">calc_string_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">read_nested</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">has_non_float_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read datasets from files and tag each record to the file it was read from.</span>

<span class="sd">    File Type is determined automatically.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filenames : list or str</span>
<span class="sd">        Either a list of filenames or shell expression</span>
<span class="sd">    datasets : list or str or None</span>
<span class="sd">        (List of) name(s) of dataset(s) to read (default: all available)</span>
<span class="sd">    strictTypes: bool</span>
<span class="sd">        If True (default), require all dtypes of a given dataset to have the</span>
<span class="sd">        same precision and sign. If False, allow dtypes of different</span>
<span class="sd">        precision and sign across different files. For example, if one</span>
<span class="sd">        file contains a uint32 dataset and another contains an int64</span>
<span class="sd">        dataset with the same name, the contents of both will be read</span>
<span class="sd">        into an int64 pdarray.</span>
<span class="sd">    allow_errors: bool</span>
<span class="sd">        Default False, if True will allow files with read errors to be skipped</span>
<span class="sd">        instead of failing.  A warning will be included in the return containing</span>
<span class="sd">        the total number of files skipped due to failure and up to 10 filenames.</span>
<span class="sd">    calc_string_offsets: bool</span>
<span class="sd">        Default False, if True this will tell the server to calculate the</span>
<span class="sd">        offsets/segments array on the server versus loading them from HDF5 files.</span>
<span class="sd">        In the future this option may be set to True as the default.</span>
<span class="sd">    read_nested: bool</span>
<span class="sd">        Default True, when True, SegArray objects will be read from the file. When False,</span>
<span class="sd">        SegArray (or other nested Parquet columns) will be ignored.</span>
<span class="sd">        Ignored if datasets is not `None`</span>
<span class="sd">        Parquet Files only.</span>
<span class="sd">    has_non_float_nulls: bool</span>
<span class="sd">        Default False. This flag must be set to True to read non-float parquet columns</span>
<span class="sd">        that contain null values.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Not currently supported for Categorical or GroupBy datasets</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import arkouda as ak</span>
<span class="sd">    Read files and return data with tagging corresponding to the Categorical returned</span>
<span class="sd">    cat.codes will link the codes in data to the filename. Data will contain the code `Filename_Codes`</span>
<span class="sd">    &gt;&gt;&gt; data, cat = ak.read_tagged_data(&#39;path/name&#39;)</span>
<span class="sd">    &gt;&gt;&gt; data</span>
<span class="sd">    {&#39;Filname_Codes&#39;: array([0 3 6 9 12]), &#39;col_name&#39;: array([0 0 0 1])}</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filenames</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">filenames</span><span class="p">]</span>

    <span class="c1"># handle glob expansion</span>
    <span class="n">j_str</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span>
        <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;globExpansion&quot;</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;file_count&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">),</span> <span class="s2">&quot;filenames&quot;</span><span class="p">:</span> <span class="n">filenames</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">file_list</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">j_str</span><span class="p">))</span>
    <span class="n">file_cat</span> <span class="o">=</span> <span class="n">Categorical</span><span class="o">.</span><span class="n">from_codes</span><span class="p">(</span>
        <span class="n">arange</span><span class="p">(</span><span class="n">file_list</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">file_list</span>
    <span class="p">)</span>  <span class="c1"># create a categorical from the ak.Strings representation of the file list</span>

    <span class="n">ftype</span> <span class="o">=</span> <span class="n">get_filetype</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ftype</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;hdf5&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">read_hdf</span><span class="p">(</span>
                <span class="n">filenames</span><span class="p">,</span>
                <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
                <span class="n">iterative</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">strict_types</span><span class="o">=</span><span class="n">strictTypes</span><span class="p">,</span>
                <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span><span class="p">,</span>
                <span class="n">calc_string_offsets</span><span class="o">=</span><span class="n">calc_string_offsets</span><span class="p">,</span>
                <span class="n">tag_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">file_cat</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">ftype</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;parquet&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">read_parquet</span><span class="p">(</span>
                <span class="n">filenames</span><span class="p">,</span>
                <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
                <span class="n">iterative</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># hard-coded because iterative not supported</span>
                <span class="n">strict_types</span><span class="o">=</span><span class="n">strictTypes</span><span class="p">,</span>
                <span class="n">allow_errors</span><span class="o">=</span><span class="n">allow_errors</span><span class="p">,</span>
                <span class="n">tag_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">read_nested</span><span class="o">=</span><span class="n">read_nested</span><span class="p">,</span>
                <span class="n">has_non_float_nulls</span><span class="o">=</span><span class="n">has_non_float_nulls</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">file_cat</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">ftype</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;csv&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;CSV does not support tagging data with file name associated.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid File Type detected, </span><span class="si">{</span><span class="n">ftype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="snapshot">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.snapshot">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">snapshot</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a snapshot of the current Arkouda namespace.</span>

<span class="sd">    All currently accessible variables containing</span>
<span class="sd">    Arkouda objects will be written to an HDF5 file.</span>

<span class="sd">    Unlike other save/load functions, this maintains the integrity of dataframes.</span>

<span class="sd">    Current Variable names are used as the dataset name when saving.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename: str</span>
<span class="sd">        Name to use when storing file</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ak.restore</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">types</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModuleType</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.dataframe</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataFrame</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">arkouda.numpy.segarray</span><span class="w"> </span><span class="kn">import</span> <span class="n">SegArray</span>

    <span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;_SNAPSHOT&quot;</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;TRUNCATE&quot;</span>
    <span class="n">callers_local_vars</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">currentframe</span><span class="p">()</span><span class="o">.</span><span class="n">f_back</span><span class="o">.</span><span class="n">f_locals</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">callers_local_vars</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">n</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ModuleType</span><span class="p">)</span>
    <span class="p">]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">pdarray</span><span class="p">,</span> <span class="n">Categorical</span><span class="p">,</span> <span class="n">SegArray</span><span class="p">,</span> <span class="n">Strings</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">GroupBy</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">):</span>
                <span class="n">val</span><span class="o">.</span><span class="n">_to_hdf_snapshot</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">val</span><span class="o">.</span><span class="n">to_hdf</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;APPEND&quot;</span></div>



<div class="viewcode-block" id="restore">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.restore">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">restore</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return data saved using `ak.snapshot`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename: str</span>
<span class="sd">        Name used to create snapshot to be read</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dict</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Unlike other save/load methods using snapshot restore will save DataFrames alongside other</span>
<span class="sd">    objects in HDF5. Thus, they are returned within the dictionary as a dataframe.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">restore_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">_SNAPSHOT_LOCALE*&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_hdf</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">restore_files</span><span class="p">))</span></div>



<div class="viewcode-block" id="receive">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.receive">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">receive</span><span class="p">(</span><span class="n">hostname</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">port</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Receive a pdarray sent by `pdarray.transfer()`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    hostname : str</span>
<span class="sd">        The hostname of the pdarray that sent the array</span>
<span class="sd">    port : int_scalars</span>
<span class="sd">        The port to send the array over. This needs to be an</span>
<span class="sd">        open port (i.e., not one that the Arkouda server is</span>
<span class="sd">        running on). This will open up `numLocales` ports,</span>
<span class="sd">        each of which in succession, so will use ports of the</span>
<span class="sd">        range {port..(port+numLocales)} (e.g., running an</span>
<span class="sd">        Arkouda server of 4 nodes, port 1234 is passed as</span>
<span class="sd">        `port`, Arkouda will use ports 1234, 1235, 1236,</span>
<span class="sd">        and 1237 to send the array data).</span>
<span class="sd">        This port much match the port passed to the call to</span>
<span class="sd">        `pdarray.transfer()`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pdarray</span>
<span class="sd">        The pdarray sent from the sending server to the current</span>
<span class="sd">        receiving server.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if the op is not within the pdarray.BinOps set</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if other is not a pdarray or the pdarray.dtype is not</span>
<span class="sd">        a supported dtype</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rep_msg</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span><span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;receiveArray&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;hostname&quot;</span><span class="p">:</span> <span class="n">hostname</span><span class="p">,</span> <span class="s2">&quot;port&quot;</span><span class="p">:</span> <span class="n">port</span><span class="p">})</span>
    <span class="n">rep</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_build_objects</span><span class="p">(</span><span class="n">rep</span><span class="p">)</span></div>



<div class="viewcode-block" id="receive_dataframe">
<a class="viewcode-back" href="../../autoapi/arkouda/io/index.html#arkouda.receive_dataframe">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">receive_dataframe</span><span class="p">(</span><span class="n">hostname</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">port</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Receive a pdarray sent by `dataframe.transfer()`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    hostname : str</span>
<span class="sd">        The hostname of the dataframe that sent the array</span>
<span class="sd">    port : int_scalars</span>
<span class="sd">        The port to send the dataframe over. This needs to be an</span>
<span class="sd">        open port (i.e., not one that the Arkouda server is</span>
<span class="sd">        running on). This will open up `numLocales` ports,</span>
<span class="sd">        each of which in succession, so will use ports of the</span>
<span class="sd">        range {port..(port+numLocales)} (e.g., running an</span>
<span class="sd">        Arkouda server of 4 nodes, port 1234 is passed as</span>
<span class="sd">        `port`, Arkouda will use ports 1234, 1235, 1236,</span>
<span class="sd">        and 1237 to send the array data).</span>
<span class="sd">        This port much match the port passed to the call to</span>
<span class="sd">        `pdarray.send_array()`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pdarray</span>
<span class="sd">        The dataframe sent from the sending server to the</span>
<span class="sd">        current receiving server.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised if the op is not within the pdarray.BinOps set</span>
<span class="sd">    TypeError</span>
<span class="sd">        Raised if other is not a pdarray or the pdarray.dtype is not</span>
<span class="sd">        a supported dtype</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rep_msg</span> <span class="o">=</span> <span class="n">generic_msg</span><span class="p">(</span><span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;receiveDataframe&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;hostname&quot;</span><span class="p">:</span> <span class="n">hostname</span><span class="p">,</span> <span class="s2">&quot;port&quot;</span><span class="p">:</span> <span class="n">port</span><span class="p">})</span>
    <span class="n">rep</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rep_msg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">_build_objects</span><span class="p">(</span><span class="n">rep</span><span class="p">))</span></div>

</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2020, Michael Merrill and William Reus
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>